{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import over\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from Vocab import Vocab\n",
    "from LanguageModel import LanguageModel\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print('import over')\n",
    "\n",
    "copy_thres=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_words2sentence(words_list):\n",
    "    return [' '.join(words) for words in words_list]\n",
    "def batch_tokens2words(tokens_list, vocab):\n",
    "    ##    para: tokens_list is list[list] type\n",
    "    ##    return: words_list corresponding to tokens\n",
    "    return [[vocab.token2word[token] for token in tokens] for tokens in tokens_list]\n",
    "\n",
    "def batch_tokens_remove_eos(tokens_list, vocab):\n",
    "    ##    para: tokens_list is list[list] type\n",
    "    ##    return pure tokens_list removed eos symbol\n",
    "    result=[]\n",
    "    for tokens in tokens_list:\n",
    "        tokens_filtered=[]\n",
    "        for token in tokens:\n",
    "            if token == vocab.word2token['<eos>']:\n",
    "#                 tokens_filtered.append(token)\n",
    "                break\n",
    "            else:\n",
    "                tokens_filtered.append(token)\n",
    "        result.append(tokens_filtered)\n",
    "    return result\n",
    "\n",
    "def batch_tokens_bleu(references, candidates, smooth_epsilon=0.001):\n",
    "    ##    para: references and candidates are list[list] type\n",
    "    ##    return: list of BLEU for every sample\n",
    "    ##\n",
    "    bleu_scores=[]\n",
    "    for ref, candidate in zip(references, candidates):\n",
    "        if min(len(ref), len(candidate))<4:\n",
    "            bleu_scores.append(0)\n",
    "        else:\n",
    "            bleu_scores.append(sentence_bleu([ref], candidate, smoothing_function = SmoothingFunction(epsilon=smooth_epsilon).method1))\n",
    "    return bleu_scores\n",
    "\n",
    "with open('data_set/vocab.pk', 'rb') as f:\n",
    "    vocab=pickle.load(f)\n",
    "\n",
    "    \n",
    "def seqs_split(seqs, vocab):\n",
    "    seqs = batch_tokens_remove_eos(seqs, vocab)\n",
    "    simple_sent1s=[]\n",
    "    simple_sent2s=[]\n",
    "    for seq in seqs:\n",
    "        simple_sent1=[]\n",
    "        simple_sent2=[]\n",
    "        sent=simple_sent1\n",
    "        for token in seq:\n",
    "            if token==vocab.word2token['<split>']:\n",
    "                sent=simple_sent2\n",
    "            else:\n",
    "                sent.append(token)\n",
    "        simple_sent1s.append(simple_sent1)\n",
    "        simple_sent2s.append(simple_sent2)\n",
    "        \n",
    "    return simple_sent1s, simple_sent2s\n",
    "\n",
    "def simple_sents_concat(simple_sent1s, simple_sent2s, vocab, max_length):\n",
    "    simple_sent_lens=[]\n",
    "    simple_sents=simple_sent1s\n",
    "    for i, sent in enumerate(simple_sent2s):\n",
    "        simple_sents[i].append(vocab.word2token['<split>'])\n",
    "        for token in sent:\n",
    "            simple_sents[i].append(token)\n",
    "\n",
    "        #if there is no <split> in simple_sent1s and simple_sent2s, then the length of sents_concat will be longer than max_length\n",
    "        if len(simple_sents[i])>max_length:\n",
    "            simple_sents[i] = simple_sents[i][:max_length]\n",
    "            \n",
    "        simple_sent_lens.append(len(simple_sents[i]))\n",
    "            \n",
    "        while(len(simple_sents[i])<max_length):\n",
    "            simple_sents[i].append(vocab.word2token['<padding>'])\n",
    "            \n",
    "    return simple_sents, simple_sent_lens\n",
    "\n",
    "\n",
    "def get_lm_inputs_and_labels(sents, vocab, max_length):\n",
    "    lm_inputs=copy.deepcopy(sents)\n",
    "    lm_labels=copy.deepcopy(sents)\n",
    "    lm_input_lens=[]\n",
    "    \n",
    "    for sent in lm_inputs:\n",
    "        if len(sent)>=max_length:\n",
    "            sent=sent[:max_length-1]\n",
    "        sent.insert(0, vocab.word2token['<sos>'])\n",
    "        lm_input_lens.append(len(sent))\n",
    "        while(len(sent)<max_length):\n",
    "            sent.append(vocab.word2token['<padding>'])\n",
    "\n",
    "    for sent in lm_labels:\n",
    "        if len(sent)>=max_length:\n",
    "            sent = sent[:max_length-1]\n",
    "        sent.append(vocab.word2token['<eos>'])\n",
    "        while(len(sent)<max_length):\n",
    "            sent.append(vocab.word2token['<padding>'])\n",
    "        \n",
    "    return lm_inputs, lm_input_lens, lm_labels\n",
    "\n",
    "\n",
    "def duplicate_reconstruct_labels(sents, topk):\n",
    "    return [x for x in sents for ii in range(topk)]\n",
    "\n",
    "\n",
    "def batch_tokens_bleu_split_version(references, candidates, vocab, smooth_epsilon=0.001):\n",
    "    # needn't remove '<sos>' token before calling this function, which is different from the 'batch_token_bleu()' version\n",
    "    #\n",
    "    ref1, ref2 = seqs_split(references, vocab)\n",
    "    cand1, cand2 = seqs_split(candidates, vocab)\n",
    "    bleu_simple_sent1s = batch_tokens_bleu(ref1, cand1)\n",
    "    bleu_simple_sent2s = batch_tokens_bleu(ref2, cand2)\n",
    "#     print(bleu_simple_sent1s)\n",
    "#     print(bleu_simple_sent2s)\n",
    "    bleu=[]\n",
    "    for idx in range(len(bleu_simple_sent1s)):\n",
    "        bleu.append((bleu_simple_sent1s[idx]+bleu_simple_sent2s[idx])/2)\n",
    "    return bleu\n",
    "\n",
    "\n",
    "def set_model_grad(model, is_grad):\n",
    "    for param in model.parameters():\n",
    "         param.requires_grad = is_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 9, 90], [], [8], [8, 9, 90], [8, 9, 90]]\n",
      "[[3], [8, 9, 90, 3], [], [3], []]\n",
      "[[0, 8, 9, 90, 1, 1], [0, 1, 1, 1, 1, 1], [0, 8, 1, 1, 1, 1], [0, 8, 9, 90, 1, 1], [0, 8, 9, 90, 1, 1]]\n",
      "[4, 1, 2, 4, 4]\n",
      "[[8, 9, 90, 2, 1, 1], [2, 1, 1, 1, 1, 1], [8, 2, 1, 1, 1, 1], [8, 9, 90, 2, 1, 1], [8, 9, 90, 2, 1, 1]]\n",
      "[[0, 3, 1, 1, 1, 1], [0, 8, 9, 90, 3, 1], [0, 1, 1, 1, 1, 1], [0, 3, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1]]\n",
      "[2, 5, 1, 2, 1]\n",
      "[[3, 2, 1, 1, 1, 1], [8, 9, 90, 3, 2, 1], [2, 1, 1, 1, 1, 1], [3, 2, 1, 1, 1, 1], [2, 1, 1, 1, 1, 1]]\n",
      "[[8, 9, 90], [5, 8, 9], [8, 5, 1], [8, 9, 90], [8, 9, 90]]\n",
      "[3, 3, 2, 3, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.021744100219015735]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs=[[8,9,90,5,3,2,1], [5,8,9,90,5,3,2,1], [8,2,9,40,5,3,2,2,1], [8,9,90,5,3,2,1], [8,9,90]]\n",
    "a,b = seqs_split(seqs, vocab)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "lm_in, lm_in_lens, lm_labels=get_lm_inputs_and_labels(a,vocab, max_length=6)\n",
    "print(lm_in)\n",
    "print(lm_in_lens)\n",
    "print(lm_labels)\n",
    "lm_in, lm_in_lens, lm_labels=get_lm_inputs_and_labels(b,vocab, max_length=6)\n",
    "print(lm_in)\n",
    "print(lm_in_lens)\n",
    "print(lm_labels)\n",
    "\n",
    "c,d=simple_sents_concat(a,b,vocab, 3)\n",
    "print(c)\n",
    "print(d)\n",
    "\n",
    "\n",
    "batch_tokens_bleu([[1,2,3,4,5,6]], [[2,3,1,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fusion data set\n",
    "\n",
    "with open('./data_set2/fusion_data_set/train_pseudo_simple_sents.pk', 'rb') as f:\n",
    "    fusion_pseudo_train_set_inputs = pickle.load(f)\n",
    "with open('./data_set2/fusion_data_set/train_pseudo_simple_sent_lens.pk', 'rb') as f:\n",
    "    fusion_pseudo_train_set_input_lens = pickle.load(f)\n",
    "with open('./data_set2/fusion_data_set/train_pseudo_labels.pk', 'rb') as f:\n",
    "    fusion_pseudo_train_set_labels = pickle.load(f)\n",
    "with open('./data_set2/fusion_data_set/train_simple_sents_supervised.pk', 'rb') as f:\n",
    "    fusion_train_set_inputs_supervised = pickle.load(f)\n",
    "with open('./data_set2/fusion_data_set/train_simple_sent_lens_supervised.pk', 'rb') as f:\n",
    "    fusion_train_set_input_lens_supervised = pickle.load(f)\n",
    "with open('./data_set2/fusion_data_set/train_labels_supervised.pk', 'rb') as f:\n",
    "    fusion_train_set_labels_supervised = pickle.load(f)\n",
    "    \n",
    "    \n",
    "with open('./data_set2/fusion_data_set/validation_simple_sents.pk', 'rb') as f:\n",
    "    fusion_pseudo_valid_set_inputs = pickle.load(f)\n",
    "with open('./data_set2/fusion_data_set/validation_simple_sent_lens.pk', 'rb') as f:\n",
    "    fusion_pseudo_valid_set_input_lens = pickle.load(f)\n",
    "with open('./data_set2/fusion_data_set/validation_labels.pk', 'rb') as f:\n",
    "    fusion_pseudo_valid_set_labels = pickle.load(f)\n",
    "    \n",
    "    \n",
    "#split data set\n",
    "\n",
    "with open('./data_set2/split_data_set/train_complex_sents.pk', 'rb') as f:\n",
    "    split_train_set_inputs = pickle.load(f)\n",
    "with open('./data_set2/split_data_set/train_complex_sent_lens.pk', 'rb') as f:\n",
    "    split_train_set_input_lens = pickle.load(f)\n",
    "with open('./data_set2/split_data_set/train_pseudo_labels.pk', 'rb') as f:\n",
    "    split_pseudo_train_set_labels = pickle.load(f)\n",
    "with open('./data_set2/split_data_set/train_complex_sents_supervised.pk', 'rb') as f:\n",
    "    split_train_set_inputs_supervised = pickle.load(f)\n",
    "with open('./data_set2/split_data_set/train_complex_sent_lens_supervised.pk', 'rb') as f:\n",
    "    split_train_set_input_lens_supervised = pickle.load(f)\n",
    "with open('./data_set2/split_data_set/train_labels_supervised.pk', 'rb') as f:\n",
    "    split_train_set_labels_supervised = pickle.load(f)\n",
    "    \n",
    "    \n",
    "with open('./data_set2/split_data_set/validation_complex_sents.pk', 'rb') as f:\n",
    "    split_valid_set_inputs = pickle.load(f)\n",
    "with open('./data_set2/split_data_set/validation_complex_sent_lens.pk', 'rb') as f:\n",
    "    split_valid_set_input_lens = pickle.load(f)\n",
    "with open('./data_set2/split_data_set/validation_labels.pk', 'rb') as f:\n",
    "    split_pseudo_valid_set_labels = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791956 791956 791956\n",
      "791956 791956 791956\n",
      "197988 197988 197988\n",
      "197988 197988 197988\n"
     ]
    }
   ],
   "source": [
    "print(len(split_train_set_inputs), len(split_train_set_input_lens), len(split_pseudo_train_set_labels))\n",
    "print(len(fusion_pseudo_train_set_inputs), len(fusion_pseudo_train_set_input_lens), len(fusion_pseudo_train_set_labels))\n",
    "\n",
    "print(len(split_train_set_inputs_supervised), len(split_train_set_input_lens_supervised), len(split_train_set_labels_supervised))\n",
    "print(len(fusion_train_set_inputs_supervised), len(fusion_train_set_input_lens_supervised), len(fusion_train_set_labels_supervised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, use_cuda, hidden_dim, input_dim, vocab):#, pre_train_weight, is_fix_word_vector = 1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.input_dim=input_dim\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.lstm=torch.nn.LSTM(input_size=self.input_dim, \n",
    "                                hidden_size= self.hidden_dim, \n",
    "                                bidirectional=True,\n",
    "                                batch_first=True\n",
    "                               )\n",
    "        \n",
    "        #embedding\n",
    "        self.embed=nn.Embedding(len(self.vocab.word2token), input_dim)\n",
    "        #loading pre trained word embedding\n",
    "        with open('data_set/pre_trained_token_embedding.pk', 'rb') as f:\n",
    "            pre_train_word_embedding = pickle.load(f)\n",
    "            \n",
    "        self.embed.weight.data.copy_(torch.FloatTensor(pre_train_word_embedding))\n",
    "#         self.embed.weight.requires_grad = False\n",
    "        \n",
    "    def order(self, inputs, inputs_len):    #inputs: tensor, inputs_len: 1D tensor\n",
    "        inputs_len, sort_ids = torch.sort(inputs_len, dim=0, descending=True)\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            inputs = inputs.index_select(0, Variable(sort_ids).cuda())\n",
    "        else:\n",
    "            inputs = inputs.index_select(0, Variable(sort_ids))\n",
    "        \n",
    "        _, true_order_ids = torch.sort(sort_ids, dim=0, descending=False)\n",
    "        \n",
    "        return inputs, inputs_len, true_order_ids\n",
    "    #\n",
    "    def forward(self, inputs, inputs_len):\n",
    "        inputs = Variable(inputs)\n",
    "        if self.use_cuda:\n",
    "            inputs=inputs.cuda()\n",
    "            \n",
    "        inputs, sort_len, true_order_ids = self.order(inputs, inputs_len)\n",
    "\n",
    "        in_vecs=self.embed(inputs)\n",
    "\n",
    "        packed = rnn_utils.pack_padded_sequence(input=in_vecs, lengths=list(sort_len), batch_first =True)\n",
    "        \n",
    "        outputs, (hn,cn) = self.lstm(packed)\n",
    "        outputs, sent_lens = rnn_utils.pad_packed_sequence(outputs)\n",
    "        \n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        outputs = outputs.transpose(0,1)  #transpose is necessary\n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        \n",
    "        #warnning: outputs, hn and cn have been sorted by sentences length so the order is wrong, now to sort them\n",
    "        if self.use_cuda:\n",
    "            outputs = outputs.index_select(0, Variable(true_order_ids).cuda())\n",
    "        else:\n",
    "            outputs = outputs.index_select(0, Variable(true_order_ids))\n",
    "        \n",
    "        hn = torch.cat((hn[0], hn[1]), dim=1)\n",
    "        cn = torch.cat((cn[0], cn[1]), dim=1)\n",
    "        #print('hn size and cn size: ', hn.size(), cn.size())\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            hn = hn.index_select(0, Variable(true_order_ids).cuda())\n",
    "            cn = cn.index_select(0, Variable(true_order_ids).cuda())\n",
    "        else:\n",
    "            hn = hn.index_select(0, Variable(true_order_ids))\n",
    "            cn = cn.index_select(0, Variable(true_order_ids))\n",
    "            \n",
    "        return outputs, (hn,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _inflate(tensor, times, dim):\n",
    "    \"\"\"\n",
    "    Examples::\n",
    "        >> a = torch.LongTensor([[1, 2], [3, 4]])\n",
    "        >> a\n",
    "        1   2\n",
    "        3   4\n",
    "        [torch.LongTensor of size 2x2]\n",
    "        >> b = ._inflate(a, 2, dim=1)\n",
    "        >> b\n",
    "        1   2   1   2\n",
    "        3   4   3   4\n",
    "        [torch.LongTensor of size 2x4]\n",
    "    \"\"\"\n",
    "    repeat_dims = [1] * tensor.dim()\n",
    "    repeat_dims[dim] = times\n",
    "    return tensor.repeat(*repeat_dims)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, use_cuda, encoder, hidden_dim, max_length=25):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.input_dim = encoder.input_dim\n",
    "        self.max_length = max_length\n",
    "        self.vocab = encoder.vocab\n",
    "        self.weight = [1]*len(self.vocab.word2token)\n",
    "        self.weight[self.vocab.word2token['<padding>']]=0\n",
    "        #self.weight[self.vocab.word2token['<eos>']]=1.01\n",
    "        #self.weight[self.vocab.word2token['<split>']]=1.01\n",
    "        \n",
    "        self.hidden_size = self.hidden_dim\n",
    "        self.V = len(self.vocab.word2token)\n",
    "        self.SOS = self.vocab.word2token['<sos>']\n",
    "        self.EOS = self.vocab.word2token['<eos>']\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.lstmcell = torch.nn.LSTMCell(input_size=self.input_dim, hidden_size=self.hidden_dim*2, bias=True)\n",
    "        \n",
    "        #embedding\n",
    "        self.embed=encoder.embed# reference share\n",
    "        #fcnn: projection for crossentroy loss\n",
    "        self.fcnn = nn.Linear(in_features = self.hidden_dim*2, out_features = len(self.vocab.word2token))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.cost_func = nn.CrossEntropyLoss(weight=torch.Tensor(self.weight), reduce=False)\n",
    "        self.nll_loss = nn.NLLLoss(weight=torch.Tensor(self.weight), reduce=False)\n",
    "\n",
    "        print('init lookup embedding matrix size: ', self.embed.weight.data.size())\n",
    "        \n",
    "        #copy\n",
    "        out_features_dim=self.hidden_dim\n",
    "        self.attent_wh = nn.Linear(in_features = self.hidden_dim*2, out_features = out_features_dim, bias = 0)\n",
    "        self.attent_ws = nn.Linear(in_features = self.hidden_dim*2, out_features = out_features_dim, bias = 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.attent_vt = nn.Linear(in_features = out_features_dim, out_features = 1, bias=0)\n",
    "        \n",
    "        self.prob_wh = nn.Linear(in_features = self.hidden_dim*2, out_features = 1, bias=0)\n",
    "        self.prob_ws = nn.Linear(in_features = self.hidden_dim*2, out_features = 1, bias=0)\n",
    "        self.prob_wx = nn.Linear(in_features = self.input_dim, out_features = 1, bias=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def copy_mechanism(self, enc_outputs, this_timestep_input, dec_state, inputs_one_hot):\n",
    "        batch_size = enc_outputs.size(dim = 0)\n",
    "        \n",
    "        wh = self.attent_wh(enc_outputs)\n",
    "        ws = self.attent_ws(dec_state).unsqueeze(dim=1)\n",
    "#         print('wh, ws size: ', wh.size(), ws.size())\n",
    "        ws = ws.expand(ws.size(0), wh.size(1), ws.size(2))\n",
    "#         print('ws size: ', ws.size())\n",
    "        weight = self.attent_vt(self.tanh(wh+ws))\n",
    "#         print('weight size: ', weight.size())\n",
    "        weight = self.softmax(weight.squeeze(dim=2))\n",
    "#         print('weight size: ', weight.size())\n",
    "        context_v = torch.bmm(weight.unsqueeze(dim=1), enc_outputs)\n",
    "#         print('context_v size: ', context_v.size())\n",
    "        context_v = context_v.squeeze(dim=1)\n",
    "        \n",
    "        p_wh = self.prob_wh(context_v)\n",
    "        p_ws = self.prob_ws(dec_state)\n",
    "        p_wx = self.prob_wx(this_timestep_input)\n",
    "        if_copy = self.sigmoid(p_wh+p_ws+p_wx)\n",
    "#         if_copy = 0.3*if_copy\n",
    "#         if_copy = self._tocuda(Variable(torch.ones(batch_size, 1), requires_grad=0))\n",
    "#         print('if_copy size: ', if_copy.size())\n",
    "        \n",
    "        prob_copy = torch.bmm(inputs_one_hot, weight.unsqueeze(dim=2))\n",
    "        prob_copy = prob_copy.squeeze(dim=2)\n",
    "#         prob_copy = self._tocuda(Variable(torch.rand(batch_size, len(self.vocab.word2token)), requires_grad=0))\n",
    "#         prob_copy = self.softmax(prob_copy)\n",
    "\n",
    "#         print('prob_copy size: ', prob_copy.size())\n",
    "#         print(torch.sum(prob_copy, dim=1))\n",
    "#         print(torch.mean(if_copy))\n",
    "        \n",
    "#         if random.random()<0.005:\n",
    "#             print('if_copy mean: ', torch.mean(if_copy))\n",
    "#             _, max_ids = torch.max(prob_copy, dim=1)\n",
    "#             print(self.vocab.token2word[max_ids.data[0]], self.vocab.token2word[max_ids.data[1]], self.vocab.token2word[max_ids.data[2]])\n",
    "            \n",
    "            \n",
    "        return if_copy, prob_copy\n",
    "\n",
    "    def forward(self, enc_outputs, sent_lens, h0_and_c0, labels, inputs, teaching_rate=0.6, is_train=1):\n",
    "        labels = Variable(labels)\n",
    "        if self.use_cuda:\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        all_loss = 0\n",
    "        predicts = []\n",
    "        max_probs=[]\n",
    "        batch_size = enc_outputs.size(dim = 0)\n",
    "        final_hidden_states = h0_and_c0[0]\n",
    "#         print('enc_outputs size:', enc_outputs.size())\n",
    "\n",
    "        sents_len = enc_outputs.size(1)\n",
    "        inputs = inputs[:,:sents_len].unsqueeze(dim=2)\n",
    "        one_hot = torch.FloatTensor(batch_size, sents_len, len(self.vocab.word2token)).zero_()\n",
    "        one_hot.scatter_(2, inputs, 1)\n",
    "        one_hot = one_hot.transpose(1,2)\n",
    "        one_hot = self._tocuda(Variable(one_hot, requires_grad = 0))\n",
    "#         print('one_hot size: ', one_hot.size())\n",
    "        \n",
    "        for ii in range(self.max_length):\n",
    "            if ii==0:\n",
    "                zero_timestep_input = Variable(torch.LongTensor([self.vocab.word2token['<sos>']]*batch_size))\n",
    "                if self.use_cuda:\n",
    "                    zero_timestep_input = zero_timestep_input.cuda()\n",
    "                    \n",
    "                zero_timestep_input = self.embed(zero_timestep_input)#size: batch_size * self.input_dim\n",
    "\n",
    "                last_timestep_hidden_state,cx = self.lstmcell(zero_timestep_input, h0_and_c0)\n",
    "                #print('last_timestep_hidden_state: ', last_timestep_hidden_state.size(), cx.size())\n",
    "                \n",
    "                \n",
    "                logits = self.fcnn(last_timestep_hidden_state)\n",
    "                \n",
    "                #copy or not\n",
    "                copy_control=random.random()\n",
    "                if copy_control<copy_thres:\n",
    "                    if_copy, prob_copy = self.copy_mechanism(enc_outputs=enc_outputs, this_timestep_input=zero_timestep_input, \n",
    "                                                            dec_state = last_timestep_hidden_state, inputs_one_hot = one_hot)\n",
    "                    score = (1-if_copy)*self.softmax(logits)+if_copy*prob_copy\n",
    "                    score = torch.clamp(score, min=10**(-30), max=1)\n",
    "                \n",
    "                #for saving time: no training, no loss calculating\n",
    "                if is_train:\n",
    "                    if copy_control<copy_thres:\n",
    "                        loss = self.nll_loss(torch.log(score), labels[:,0])\n",
    "                    else:\n",
    "                        loss = self.cost_func(logits, labels[:,0])\n",
    "                    all_loss+=loss\n",
    "                \n",
    "                #get predicts\n",
    "                if copy_control<copy_thres:\n",
    "                    _, max_idxs = torch.max(score, dim=1)\n",
    "                else:\n",
    "                    _, max_idxs = torch.max(logits, dim=1)\n",
    "                predicts.append(torch.unsqueeze(max_idxs, dim=0))\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if is_train:\n",
    "                    rand = random.random()\n",
    "                    if rand<teaching_rate:\n",
    "                        this_timestep_input = self.embed(labels[:,ii-1])#label teaching, lookup embedding\n",
    "                    else:\n",
    "                        this_timestep_input = self.embed(max_idxs)#last_timestep output, and then look up word embedding\n",
    "                else:\n",
    "                    this_timestep_input = self.embed(max_idxs)#last_timestep output, and then look up word embedding\n",
    "                    \n",
    "                last_timestep_hidden_state ,cx = self.lstmcell(this_timestep_input, (last_timestep_hidden_state,cx))\n",
    "                \n",
    "                \n",
    "                logits = self.fcnn(last_timestep_hidden_state)\n",
    "                \n",
    "                #copy or not\n",
    "                copy_control=random.random()\n",
    "                if copy_control<copy_thres:\n",
    "                    if_copy, prob_copy = self.copy_mechanism(enc_outputs=enc_outputs, this_timestep_input=this_timestep_input, \n",
    "                                                            dec_state = last_timestep_hidden_state, inputs_one_hot = one_hot)\n",
    "                    score = (1-if_copy)*self.softmax(logits)+if_copy*prob_copy\n",
    "                    score = torch.clamp(score, min=10**(-30), max=1)\n",
    "                \n",
    "                #for saving time: no training, no loss calculating\n",
    "                if is_train:\n",
    "                    if copy_control<copy_thres:\n",
    "                        loss = self.nll_loss(torch.log(score), labels[:,ii])\n",
    "                    else:\n",
    "                        loss = self.cost_func(logits, labels[:,ii])\n",
    "                    all_loss+=loss\n",
    "                \n",
    "                #get predicts\n",
    "                if copy_control<copy_thres:\n",
    "                    _, max_idxs = torch.max(score, dim=1)\n",
    "                else:\n",
    "                    _, max_idxs = torch.max(logits, dim=1)\n",
    "                predicts.append(torch.unsqueeze(max_idxs, dim=0))\n",
    "                \n",
    "        predicts = torch.cat(predicts, dim=0)\n",
    "        predicts = torch.transpose(predicts, 0, 1)\n",
    "    \n",
    "        if is_train:  #training\n",
    "#             all_loss = torch.cat(all_loss, dim=1)\n",
    "#             all_loss = torch.mean(all_loss, dim=1)\n",
    "#             loss = torch.mean(all_loss)\n",
    "            loss = all_loss/self.max_length\n",
    "    \n",
    "            #print('loss size: ', loss.size())\n",
    "            #torch.cuda.empty_cache()\n",
    "            if self.use_cuda:\n",
    "                return loss, predicts.data.cpu().tolist()\n",
    "            else:\n",
    "                return loss, predicts.data.tolist()\n",
    "        else:   #testing\n",
    "            if self.use_cuda:\n",
    "                return predicts.data.cpu().tolist()\n",
    "            else:\n",
    "                return predicts.data.tolist()\n",
    "#         if is_train:  #training\n",
    "#             if self.use_cuda:\n",
    "#                 return all_loss/(self.max_length+1), predicts.data.cpu().numpy()\n",
    "#             else:\n",
    "#                 return all_loss/(self.max_length+1), predicts.data.numpy()\n",
    "#         else:   #testing\n",
    "#             if self.use_cuda:\n",
    "#                 return predicts.data.cpu().numpy()\n",
    "#             else:\n",
    "#                 return predicts.data.numpy()\n",
    "    \n",
    "    \n",
    "    def decode_topk_seqs(self, encoder, inputs, input_lens, topk=3):\n",
    "        enc_outputs, (enc_hn, enc_cn) = encoder(inputs, input_lens)\n",
    "        batch_size = enc_outputs.size(dim = 0)\n",
    "        \n",
    "        #one hot of inputs\n",
    "        sents_len = enc_outputs.size(1)\n",
    "        inputs = inputs[:,:sents_len].unsqueeze(dim=2)\n",
    "        one_hot = torch.FloatTensor(batch_size, sents_len, len(self.vocab.word2token)).zero_()\n",
    "        one_hot.scatter_(2, inputs, 1)\n",
    "        one_hot = one_hot.transpose(1,2)\n",
    "        one_hot = self._tocuda(Variable(one_hot, requires_grad = 0))\n",
    "        \n",
    "        metadata = self.decode_by_beamsearch(encoder_hidden=(enc_hn, enc_cn), encoder_outputs=enc_outputs, inputs_one_hot=one_hot,topk = topk)\n",
    "        results = metadata['topk_sequence']\n",
    "        results =torch.cat(results, dim = 2)\n",
    "        results=results.view(batch_size*topk, -1)\n",
    "        if self.use_cuda:\n",
    "            results = results.data.cpu().tolist()\n",
    "        else:\n",
    "            results = results.data.tolist()\n",
    "#         results=batch_tokens_remove_eos(results, self.vocab)\n",
    "\n",
    "#         labels = [x for x in labels for ii in range(topk)]\n",
    "#         labels = batch_tokens_remove_eos(labels, self.vocab)\n",
    "#         bleu_scores = batch_tokens_bleu(references=labels, candidates=results, smooth_epsilon=0.01)\n",
    "        \n",
    "#         bleu_scores = torch.FloatTensor(bleu_scores).view(batch_size, topk)\n",
    "#         bleu_max, _ = torch.max(bleu_scores, dim=1)\n",
    "        \n",
    "#         bleu_mean = torch.mean(bleu_scores, dim=1).unsqueeze(dim=1)\n",
    "#         bleu_scores = bleu_scores-bleu_mean\n",
    "#         bleu_scores = bleu_scores.view(-1)\n",
    "        \n",
    "#         bleu_scores = self._tocuda(Variable(bleu_scores, requires_grad = 0))\n",
    "#         log_probs = metadata['score']\n",
    "#         log_probs = log_probs.view(batch_size*topk)\n",
    "#         loss = -torch.dot(log_probs, bleu_scores)/batch_size/topk\n",
    "#         return loss, results, torch.mean(bleu_mean.squeeze()), torch.mean(bleu_max)\n",
    "\n",
    "        log_probs = metadata['score']\n",
    "        log_probs = log_probs.view(batch_size*topk)\n",
    "        \n",
    "        return results, log_probs\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _tocuda(self, var):\n",
    "        if self.use_cuda:\n",
    "            return var.cuda()\n",
    "        else:\n",
    "            return var\n",
    "    def decode_by_beamsearch(self, encoder_hidden=None, encoder_outputs=None, inputs_one_hot=None, topk = 10):\n",
    "        self.k = topk\n",
    "        batch_size = encoder_outputs.size(dim=0)\n",
    "        \n",
    "        self.pos_index = self._tocuda(Variable(torch.LongTensor(range(batch_size)) * self.k).view(-1, 1))\n",
    "\n",
    "        hidden = tuple([_inflate(h, self.k, 1).view(batch_size*self.k, -1) for h in encoder_hidden])\n",
    "        #print('hidden0 size: (%s, %s)'%(hidden[0].size(), hidden[1].size()))\n",
    "\n",
    "        encoder_outputs = _inflate(encoder_outputs, self.k, 1).view(batch_size*self.k, encoder_outputs.size(1), encoder_outputs.size(2))\n",
    "        inputs_one_hot = _inflate(inputs_one_hot, self.k, 1).view(batch_size*self.k, inputs_one_hot.size(1), inputs_one_hot.size(2))\n",
    "        \n",
    "        # Initialize the scores; for the first step,\n",
    "        # ignore the inflated copies to avoid duplicate entries in the top k\n",
    "        sequence_scores = torch.Tensor(batch_size * self.k, 1)\n",
    "        sequence_scores.fill_(-float('Inf'))\n",
    "        sequence_scores.index_fill_(0, torch.LongTensor([i * self.k for i in range(0, batch_size)]), 0.0)\n",
    "        sequence_scores = self._tocuda(Variable(sequence_scores))\n",
    "\n",
    "        # Initialize the input vector\n",
    "        input_var = self._tocuda(Variable(torch.LongTensor([self.SOS] * batch_size * self.k)))\n",
    "\n",
    "        # Store decisions for backtracking\n",
    "        stored_outputs = list()\n",
    "        stored_scores = list()\n",
    "        stored_predecessors = list()\n",
    "        stored_emitted_symbols = list()\n",
    "        stored_hidden = list()\n",
    "\n",
    "        for ii in range(0, self.max_length):\n",
    "            # Run the RNN one step forward\n",
    "            #print('setp: %s'%ii)\n",
    "            input_vec = self.embed(input_var)\n",
    "            #print('input_var and input_vec size: ', input_var.size(), input_vec.size())\n",
    "            hidden = self.lstmcell(input_vec, hidden)\n",
    "            #print('hidden size: (%s, %s)'%(hidden[0].size(), hidden[1].size()))\n",
    "            \n",
    "            #log_softmax_output = self.log_softmax(self.fcnn(hidden[0]))\n",
    "            \n",
    "            logits = self.fcnn(hidden[0])\n",
    "#             print('logits size', logits.size())\n",
    "#             print(encoder_outputs.size())\n",
    "#             print(input_vec.size())\n",
    "#             print(hidden[0].size())\n",
    "#             print(inputs_one_hot.size())\n",
    "            if_copy, prob_copy = self.copy_mechanism(enc_outputs=encoder_outputs, this_timestep_input=input_vec.squeeze(dim=1), \n",
    "                                                            dec_state = hidden[0], inputs_one_hot = inputs_one_hot)\n",
    "#             print('if_copy size', if_copy.size(), 'prob_copy size', prob_copy.size())\n",
    "            \n",
    "            score = (1-if_copy)*self.softmax(logits)+if_copy*prob_copy\n",
    "            score = torch.clamp(score, min=10**(-30), max=1)\n",
    "#             print('score size: ', score.size())\n",
    "\n",
    "            # To get the full sequence scores for the new candidates, add the local scores for t_i to the predecessor scores for t_(i-1)\n",
    "            sequence_scores = _inflate(sequence_scores, self.V, 1)\n",
    "            sequence_scores += torch.log(score).squeeze(1)\n",
    "            scores, candidates = sequence_scores.view(batch_size, -1).topk(self.k, dim=1)\n",
    "\n",
    "            # Reshape input = (bk, 1) and sequence_scores = (bk, 1)\n",
    "            input_var = (candidates % self.V).view(batch_size * self.k, 1)\n",
    "            sequence_scores = scores.view(batch_size * self.k, 1)\n",
    "\n",
    "            # Update fields for next timestep\n",
    "            predecessors = (candidates / self.V + self.pos_index.expand_as(candidates)).view(batch_size * self.k, 1)\n",
    "            if isinstance(hidden, tuple):\n",
    "                hidden = tuple([h.index_select(0, predecessors.squeeze()) for h in hidden])\n",
    "            else:\n",
    "                hidden = hidden.index_select(0, predecessors.squeeze())\n",
    "\n",
    "            # Update sequence scores and erase scores for end-of-sentence symbol so that they aren't expanded\n",
    "            stored_scores.append(sequence_scores.clone())\n",
    "            eos_indices = input_var.data.eq(self.EOS)\n",
    "            if eos_indices.nonzero().dim() > 0:\n",
    "                sequence_scores.data.masked_fill_(eos_indices, -float('inf'))\n",
    "\n",
    "            # Cache results for backtracking\n",
    "            stored_predecessors.append(predecessors)\n",
    "            stored_emitted_symbols.append(input_var)\n",
    "#             stored_hidden.append(hidden)\n",
    "\n",
    "        # Do backtracking to return the optimal values\n",
    "        output, h_t, h_n, s, l, p = self._backtrack(hidden,\n",
    "                                                    stored_predecessors, stored_emitted_symbols,\n",
    "                                                    stored_scores, batch_size, self.hidden_size)\n",
    "\n",
    "        metadata = {}\n",
    "\n",
    "        metadata['score'] = s\n",
    "        metadata['topk_length'] = l\n",
    "        metadata['topk_sequence'] = p\n",
    "        metadata['length'] = [seq_len[0] for seq_len in l]\n",
    "        metadata['sequence'] = [seq[0] for seq in p]\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "    def _backtrack(self, hidden, predecessors, symbols, scores, b, hidden_size):\n",
    "        \"\"\"Backtracks over batch to generate optimal k-sequences.\n",
    "\n",
    "        Args:\n",
    "            nw_output [(batch*k, vocab_size)] * sequence_length: A Tensor of outputs from network\n",
    "            nw_hidden [(num_layers, batch*k, hidden_size)] * sequence_length: A Tensor of hidden states from network\n",
    "            predecessors [(batch*k)] * sequence_length: A Tensor of predecessors\n",
    "            symbols [(batch*k)] * sequence_length: A Tensor of predicted tokens\n",
    "            scores [(batch*k)] * sequence_length: A Tensor containing sequence scores for every token t = [0, ... , seq_len - 1]\n",
    "            b: Size of the batch\n",
    "            hidden_size: Size of the hidden state\n",
    "\n",
    "        Returns:\n",
    "            output [(batch, k, vocab_size)] * sequence_length: A list of the output probabilities (p_n)\n",
    "            from the last layer of the RNN, for every n = [0, ... , seq_len - 1]\n",
    "\n",
    "            h_t [(batch, k, hidden_size)] * sequence_length: A list containing the output features (h_n)\n",
    "            from the last layer of the RNN, for every n = [0, ... , seq_len - 1]\n",
    "\n",
    "            h_n(batch, k, hidden_size): A Tensor containing the last hidden state for all top-k sequences.\n",
    "\n",
    "            score [batch, k]: A list containing the final scores for all top-k sequences\n",
    "\n",
    "            length [batch, k]: A list specifying the length of each sequence in the top-k candidates\n",
    "\n",
    "            p (batch, k, sequence_len): A Tensor containing predicted sequence\n",
    "        \"\"\"\n",
    "\n",
    "        lstm = isinstance(hidden, tuple)\n",
    "\n",
    "        # initialize return variables given different types\n",
    "        output = list()\n",
    "        h_t = list()\n",
    "        p = list()\n",
    "        # Placeholder for last hidden state of top-k sequences.\n",
    "        # If a (top-k) sequence ends early in decoding, `h_n` contains\n",
    "        # its hidden state when it sees EOS.  Otherwise, `h_n` contains\n",
    "        # the last hidden state of decoding.\n",
    "        if lstm:\n",
    "            state_size = hidden[0].size()\n",
    "            h_n = tuple([torch.zeros(state_size), torch.zeros(state_size)])\n",
    "        else:\n",
    "            h_n = torch.zeros(nw_hidden[0].size())\n",
    "        l = [[self.max_length] * self.k for _ in range(b)]  # Placeholder for lengths of top-k sequences\n",
    "                                                                # Similar to `h_n`\n",
    "\n",
    "        # the last step output of the beams are not sorted\n",
    "        # thus they are sorted here\n",
    "        sorted_score, sorted_idx = scores[-1].view(b, self.k).topk(self.k)\n",
    "        # initialize the sequence scores with the sorted last step beam scores\n",
    "        s = sorted_score.clone()\n",
    "\n",
    "        batch_eos_found = [0] * b   # the number of EOS found\n",
    "                                    # in the backward loop below for each batch\n",
    "\n",
    "        t = self.max_length - 1\n",
    "        # initialize the back pointer with the sorted order of the last step beams.\n",
    "        # add self.pos_index for indexing variable with b*k as the first dimension.\n",
    "        t_predecessors = (sorted_idx + self.pos_index.expand_as(sorted_idx)).view(b * self.k)\n",
    "        while t >= 0:\n",
    "            # Re-order the variables with the back pointer\n",
    "            current_symbol = symbols[t].index_select(0, t_predecessors)\n",
    "            # Re-order the back pointer of the previous step with the back pointer of\n",
    "            # the current step\n",
    "            t_predecessors = predecessors[t].index_select(0, t_predecessors).squeeze()\n",
    "\n",
    "            # This tricky block handles dropped sequences that see EOS earlier.\n",
    "            # The basic idea is summarized below:\n",
    "            #\n",
    "            #   Terms:\n",
    "            #       Ended sequences = sequences that see EOS early and dropped\n",
    "            #       Survived sequences = sequences in the last step of the beams\n",
    "            #\n",
    "            #       Although the ended sequences are dropped during decoding,\n",
    "            #   their generated symbols and complete backtracking information are still\n",
    "            #   in the backtracking variables.\n",
    "            #   For each batch, everytime we see an EOS in the backtracking process,\n",
    "            #       1. If there is survived sequences in the return variables, replace\n",
    "            #       the one with the lowest survived sequence score with the new ended\n",
    "            #       sequences\n",
    "            #       2. Otherwise, replace the ended sequence with the lowest sequence\n",
    "            #       score with the new ended sequence\n",
    "            #\n",
    "            eos_indices = symbols[t].data.squeeze(1).eq(self.EOS).nonzero()\n",
    "            if eos_indices.dim() > 0:\n",
    "                for i in range(eos_indices.size(0)-1, -1, -1):\n",
    "                    # Indices of the EOS symbol for both variables\n",
    "                    # with b*k as the first dimension, and b, k for\n",
    "                    # the first two dimensions\n",
    "                    idx = eos_indices[i]\n",
    "                    b_idx = int(idx[0] / self.k)\n",
    "                    # The indices of the replacing position\n",
    "                    # according to the replacement strategy noted above\n",
    "                    res_k_idx = self.k - (batch_eos_found[b_idx] % self.k) - 1\n",
    "                    batch_eos_found[b_idx] += 1\n",
    "                    res_idx = b_idx * self.k + res_k_idx\n",
    "\n",
    "                    # Replace the old information in return variables\n",
    "                    # with the new ended sequence information\n",
    "                    t_predecessors[res_idx] = predecessors[t][idx[0]]\n",
    "\n",
    "                    current_symbol[res_idx, :] = symbols[t][idx[0]]\n",
    "                    s[b_idx, res_k_idx] = scores[t][idx[0]]\n",
    "                    l[b_idx][res_k_idx] = t + 1\n",
    "\n",
    "            # record the back tracked results\n",
    "            p.append(current_symbol)\n",
    "            t -= 1\n",
    "\n",
    "        # Sort and re-order again as the added ended sequences may change\n",
    "        # the order (very unlikely)\n",
    "        s, re_sorted_idx = s.topk(self.k)\n",
    "        for b_idx in range(b):\n",
    "            l[b_idx] = [l[b_idx][k_idx.data[0]] for k_idx in re_sorted_idx[b_idx,:]]\n",
    "\n",
    "        re_sorted_idx = (re_sorted_idx + self.pos_index.expand_as(re_sorted_idx)).view(b * self.k)\n",
    "\n",
    "        # Reverse the sequences and re-order at the same time\n",
    "        # It is reversed because the backtracking happens in reverse time order\n",
    "#         output = [step.index_select(0, re_sorted_idx).view(b, self.k, -1) for step in reversed(output)]\n",
    "        p = [step.index_select(0, re_sorted_idx).view(b, self.k, -1) for step in reversed(p)]\n",
    "        #    --- fake output ---\n",
    "        output = None\n",
    "        #    --- fake ---\n",
    "        return output, h_t, h_n, s, l, p\n",
    "\n",
    "    def _mask_symbol_scores(self, score, idx, masking_score=-float('inf')):\n",
    "            score[idx] = masking_score\n",
    "\n",
    "    def _mask(self, tensor, idx, dim=0, masking_score=-float('inf')):\n",
    "        if len(idx.size()) > 0:\n",
    "            indices = idx[:, 0]\n",
    "            tensor.index_fill_(dim, indices, masking_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, use_cuda, input_dim, hidden_dim, vocab, max_length = 25):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.enc = Encoder(use_cuda=use_cuda, hidden_dim=hidden_dim, input_dim=input_dim, vocab=vocab)\n",
    "        self.dec = Decoder(use_cuda=use_cuda, encoder=self.enc, hidden_dim=hidden_dim, max_length=max_length)\n",
    "        if use_cuda:\n",
    "            self.enc = self.enc.cuda()\n",
    "            self.dec = self.dec.cuda()\n",
    "    def forward(self, inputs, input_lens, labels, is_train=1, teaching_rate=1):\n",
    "        enc_outputs, (enc_hn, enc_cn) = self.enc(torch.LongTensor(inputs), torch.LongTensor(input_lens))\n",
    "        if is_train:\n",
    "            loss, predicts = self.dec(enc_outputs = enc_outputs, \n",
    "                                    h0_and_c0=(enc_hn, enc_cn), \n",
    "                                    sent_lens=input_lens,\n",
    "                                    labels=torch.LongTensor(labels), \n",
    "                                    is_train=1, \n",
    "                                    teaching_rate = 1,\n",
    "                                    inputs = inputs\n",
    "                                    )\n",
    "            return loss, predicts\n",
    "        else:\n",
    "            predicts = self.dec(enc_outputs = enc_outputs, \n",
    "                                h0_and_c0=(enc_hn, enc_cn), \n",
    "                                sent_lens=input_lens,\n",
    "                                labels=torch.LongTensor(labels), \n",
    "                                is_train=0, \n",
    "                                teaching_rate = 1,\n",
    "                                inputs = inputs\n",
    "                                )\n",
    "            return predicts\n",
    "#     def train_using_rl(self, inputs, input_lens, labels, is_train=1, teaching_rate=1):\n",
    "#         enc_outputs, (enc_hn, enc_cn) = self.enc(torch.LongTensor(inputs), torch.LongTensor(input_lens))\n",
    "#         loss, predicts, bleu_mean = self.dec.train_using_rl_2(enc_outputs = enc_outputs, \n",
    "#                                                 h0_and_c0=(enc_hn, enc_cn), \n",
    "#                                                 sent_lens=input_lens,\n",
    "#                                                 labels=labels,\n",
    "#                                                 is_train=1, \n",
    "#                                                 teaching_rate = 1\n",
    "#                                                 )\n",
    "#         return loss, predicts, bleu_mean\n",
    "\n",
    "    def tocuda(self, x):\n",
    "        if self.use_cuda:\n",
    "            return x.cuda()\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def train_using_reward(self, inputs, input_lens, reconstruct_labels, reconstruct_model, language_model, topk=3, loss_ratio=0.5):\n",
    "        dec_seqs, log_probs = self.dec.decode_topk_seqs(self.enc, inputs, input_lens, topk=topk)\n",
    "#         enc_outputs, (enc_hn, enc_cn) = self.enc(torch.LongTensor(inputs), torch.LongTensor(input_lens))\n",
    "#         results = self.dec.decode_no_labels(enc_outputs=enc_outputs, h0_and_c0=(enc_hn, enc_cn), topk=topk)\n",
    "        simple_sent1s, simple_sent2s = seqs_split(dec_seqs, self.enc.vocab)\n",
    "        \n",
    "        lm_input1s, lm_input1_lens, lm_label1s = get_lm_inputs_and_labels(simple_sent1s, self.enc.vocab, self.dec.max_length)\n",
    "        simple_sent1s_ppl = language_model.get_sentences_ppl(torch.LongTensor(lm_input1s), \n",
    "                                                      torch.LongTensor(lm_input1_lens), \n",
    "                                                      torch.LongTensor(lm_label1s)\n",
    "                                                    )\n",
    "        lm_input2s, lm_input2_lens, lm_label2s = get_lm_inputs_and_labels(simple_sent2s, self.enc.vocab, self.dec.max_length)\n",
    "        simple_sent2s_ppl = language_model.get_sentences_ppl(torch.LongTensor(lm_input2s), \n",
    "                                                      torch.LongTensor(lm_input2_lens), \n",
    "                                                      torch.LongTensor(lm_label2s)\n",
    "                                                    )\n",
    "        \n",
    "        simple_inputs, simple_input_lens = simple_sents_concat(simple_sent1s, simple_sent2s, self.enc.vocab, self.dec.max_length)\n",
    "        #reconstruct labels\n",
    "        reconstruct_loss, predicts = reconstruct_model.forward(torch.LongTensor(simple_inputs), \n",
    "                                     torch.LongTensor(simple_input_lens), \n",
    "                                     labels=reconstruct_labels, \n",
    "                                     is_train=1, teaching_rate=1)\n",
    "        \n",
    "        #rm_rewards: reconstruct model rewards\n",
    "        #lm_rewards: language model rewards\n",
    "        rm_rewards=-reconstruct_loss.data\n",
    "        lm_rewards=self.tocuda(-(torch.Tensor(simple_sent1s_ppl)+torch.Tensor(simple_sent2s_ppl))/2)\n",
    "        \n",
    "        rm_rewards_mean = torch.mean(rm_rewards.view(-1, topk), dim=1)\n",
    "        lm_rewards_mean = torch.mean(lm_rewards.view(-1, topk), dim=1)\n",
    "        rm_rewards = rm_rewards.view(-1, topk) - rm_rewards_mean.unsqueeze(dim=1)\n",
    "        lm_rewards = lm_rewards.view(-1, topk) - lm_rewards_mean.unsqueeze(dim=1)\n",
    "        \n",
    "        rm_rewards = rm_rewards.view(-1)\n",
    "        lm_rewards = lm_rewards.view(-1)\n",
    "        \n",
    "        #sum both rewards up\n",
    "        rewards = loss_ratio*rm_rewards+(1-loss_ratio)*lm_rewards\n",
    "        rewards = Variable(rewards, requires_grad=0)\n",
    "        \n",
    "        #regarding rewards as weights of every seq\n",
    "        loss = -torch.dot(log_probs, rewards)/log_probs.size(0)\n",
    "        \n",
    "#         labels = [x for x in labels for ii in range(topk)]\n",
    "#         labels = batch_tokens_remove_eos(labels, self.vocab)\n",
    "#         bleu_scores = batch_tokens_bleu(references=labels, candidates=results, smooth_epsilon=0.01)\n",
    "        \n",
    "#         bleu_scores = torch.FloatTensor(bleu_scores).view(batch_size, topk)\n",
    "#         bleu_max, _ = torch.max(bleu_scores, dim=1)\n",
    "        \n",
    "#         bleu_mean = torch.mean(bleu_scores, dim=1).unsqueeze(dim=1)\n",
    "#         bleu_scores = bleu_scores-bleu_mean\n",
    "#         bleu_scores = bleu_scores.view(-1)\n",
    "        \n",
    "#         bleu_scores = self._tocuda(Variable(bleu_scores, requires_grad = 0))\n",
    "        \n",
    "#         log_probs = metadata['score']\n",
    "#         log_probs = log_probs.view(batch_size*topk)\n",
    "    \n",
    "#         loss = -torch.dot(log_probs, bleu_scores)/batch_size/topk\n",
    "        \n",
    "        return loss, reconstruct_loss, torch.mean(rm_rewards_mean), torch.mean(lm_rewards_mean)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading pre-train weight for language model.\n",
      "init lookup embedding matrix size:  torch.Size([44380, 100])\n",
      "init lookup embedding matrix size:  torch.Size([44380, 100])\n"
     ]
    }
   ],
   "source": [
    "lm_hidden_dim=1024\n",
    "lm_input_dim=300\n",
    "use_cuda=1\n",
    "\n",
    "language_model = LanguageModel(use_cuda = use_cuda, input_dim = lm_input_dim, hidden_dim = lm_hidden_dim, vocab = vocab)\n",
    "#512\n",
    "model_path = './models_language_model/time-[2019-02-26-11-27-36]-info=[language_model]-loss=3.414012194-bleu=-1.0000-hidden_dim=512-input_dim=300-epoch=21-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050'\n",
    "#2048\n",
    "model_path = './models_language_model/time-[2019-02-28-07-04-08]-info=[language_model]-loss=3.475848675-bleu=-1.0000-hidden_dim=2048-input_dim=300-epoch=4-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050'\n",
    "#1024\n",
    "model_path = './models_language_model/time-[2019-02-27-21-58-23]-info=[language_model]-loss=4.111208439-bleu=-1.0000-hidden_dim=1024-input_dim=300-epoch=6-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050'\n",
    "\n",
    "pre_train = torch.load(model_path, map_location='cpu')\n",
    "language_model.load_state_dict(pre_train)\n",
    "\n",
    "if use_cuda:\n",
    "    language_model = language_model.cuda()\n",
    "    \n",
    "language_model.eval()\n",
    "\n",
    "print('finish loading pre-train weight for language model.')\n",
    "\n",
    "\n",
    "\n",
    "use_cuda = 1\n",
    "hidden_dim = 256\n",
    "input_dim = 100\n",
    "lr=0.005\n",
    "\n",
    "split_model = Seq2Seq(use_cuda = use_cuda, input_dim = input_dim, hidden_dim = hidden_dim, \n",
    "                          vocab = vocab, max_length = 61)\n",
    "\n",
    "fusion_model = Seq2Seq(use_cuda = use_cuda, input_dim = input_dim, hidden_dim = hidden_dim, \n",
    "                          vocab = vocab, max_length = 51)\n",
    "#pre train para\n",
    "pre_train = torch.load('./models_saved/time-[2019-03-03-01-10-08]-info=[split_model]-loss=0.796790183-bleu=0.7053-hidden_dim=256-input_dim=100-epoch=3-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050', map_location='cpu')\n",
    "split_model.load_state_dict(pre_train)\n",
    "pre_train = torch.load('./models_saved/time-[2019-03-03-01-10-09]-info=[fusion_model]-loss=0.491095543-bleu=0.7543-hidden_dim=256-input_dim=100-epoch=3-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050', map_location='cpu')\n",
    "fusion_model.load_state_dict(pre_train)\n",
    "\n",
    "if use_cuda:\n",
    "    split_model = split_model.cuda()\n",
    "    fusion_model = fusion_model.cuda()\n",
    "    \n",
    "split_optimizer = optim.Adam(filter(lambda p: p.requires_grad, split_model.parameters()), lr=lr)\n",
    "fusion_optimizer = optim.Adam(filter(lambda p: p.requires_grad, fusion_model.parameters()), lr=lr)\n",
    "\n",
    "# set_model_grad(fusion_model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --->  starting time-[2019-03-08-20-24-47]-\n",
      "time-[2019-03-08-20-25-18]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  vanessa de luca was born in philadelphia , pennsylvania . her parents , from italy <split> she was was visiting family in the united states when she was born .\n",
      " 2---->  vanessa de luca was born in philadelphia , pennsylvania , her parents , from . <split> italy , where visiting family in the united states when she was born .\n",
      "\n",
      "\n",
      " 1---->  vanessa fox ( born 1972 ) is a search engine optimization consultant , writer and consultant <split> she , for her work creating google <low_freq> central and as a google spokesperson .\n",
      " 2---->  vanessa fox ( born 1972 ) is a search engine optimization consultant , writer and . <split> consultant known for her work creating google <low_freq> central and as a google spokesperson .\n",
      "\n",
      "\n",
      " 1---->  vanessa <low_freq> is princess carolyn 's rival . is <split> she shares her office when their agencies merge .\n",
      " 2---->  vanessa <low_freq> is princess carolyn 's rival who . <split> temporarily shares her office when their agencies merge .\n",
      "\n",
      "\n",
      " 1---->  vanessa <low_freq> ( born 7 june 1980 ) is an italian figure skater . is <split> she italy at the 2002 winter olympics in salt lake city , utah .\n",
      " 2---->  vanessa <low_freq> ( born 7 june 1980 ) is an italian figure skater who . <split> represented italy at the 2002 winter olympics in salt lake city , utah .\n",
      "\n",
      "\n",
      " 1---->  vanessa jackson ( born 1953 <low_freq> , surrey ) is a british artist <split> she was was elected to the royal academy of arts in 2015 .\n",
      " 2---->  vanessa jackson ( born 1953 <low_freq> , surrey ) is a british . <split> artist who was elected to the royal academy of arts in 2015 .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-5.098831177-rec_loss=0.207428202-lm_rewards=-131.5752-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[1-[of]-15839]-lr=0.0050\n",
      "info=[split_model]-total_loss=-5.098831177-rec_loss=0.207428202-lm_rewards=-131.5752-bleu=0.7659-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[1-[of]-15839]-lr=0.0050-loss_ratio=0.9000 0.7659456779369015\n",
      " --->  starting time-[2019-03-08-20-25-19]-\n",
      "time-[2019-03-08-20-25-24]-\n",
      " --->  starting time-[2019-03-08-20-25-24]-\n",
      "time-[2019-03-08-20-25-56]-\n",
      " --->  starting time-[2019-03-08-20-25-56]-\n",
      "time-[2019-03-08-20-26-00]-\n",
      " --->  starting time-[2019-03-08-20-26-00]-\n",
      "time-[2019-03-08-20-26-33]-\n",
      " --->  starting time-[2019-03-08-20-26-33]-\n",
      "time-[2019-03-08-20-26-38]-\n",
      " --->  starting time-[2019-03-08-20-26-38]-\n",
      "time-[2019-03-08-20-27-09]-\n",
      " --->  starting time-[2019-03-08-20-27-09]-\n",
      "time-[2019-03-08-20-27-13]-\n",
      " --->  starting time-[2019-03-08-20-27-13]-\n",
      "time-[2019-03-08-20-27-44]-\n",
      " --->  starting time-[2019-03-08-20-27-44]-\n",
      "time-[2019-03-08-20-27-49]-\n",
      " --->  starting time-[2019-03-08-20-27-49]-\n",
      "time-[2019-03-08-20-28-22]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  marcel <low_freq> , whose father was an educator in paris studied classically at the . where continued his studies in <split> he 1909 , he his <low_freq> in law in 1909 , a judiciary career path he quickly abandoned .\n",
      " 2---->  marcel <low_freq> , whose father was an educator in paris studied classically at douai , then continued his studies . <split> in paris , receiving his <low_freq> in law in 1909 , a judiciary career path he quickly abandoned .\n",
      "\n",
      "\n",
      " 1---->  marcel <low_freq> ( b. brussels , 22 march 1906 ; d. 2 july 2011 ) , was , <low_freq> and <low_freq> of the belgian wartime <split> he resistance , lived from 1935 to at 51 rue du commerce , lived , and is also where he set up his studio .\n",
      " 2---->  marcel <low_freq> ( b. brussels , 22 march 1906 ; d. 2 july 2011 ) , artist , <low_freq> and member of the belgian . <split> wartime resistance , lived from 1935 onwards at 51 rue du commerce , brussels , which is also where he set up his studio .\n",
      "\n",
      "\n",
      " 1---->  marcel <low_freq> ( born 27 july 1992 ) is a german football midfielder <split> he <low_freq> for nk <low_freq> 1961 in the croatian first league .\n",
      " 2---->  marcel <low_freq> ( born 27 july 1992 ) is a german football . <split> midfielder <low_freq> for nk <low_freq> 1961 in the croatian first league .\n",
      "\n",
      "\n",
      " 1---->  marcel <low_freq> ( may 14 , 1904 - june 16 , 1961 ) was a swiss doctor . a <split> he of the most accomplished field delegates in the history of the international committee of the red cross .\n",
      " 2---->  marcel <low_freq> ( may 14 , 1904 - june 16 , 1961 ) was a swiss doctor and . <split> one of the most accomplished field delegates in the history of the international committee of the red cross .\n",
      "\n",
      "\n",
      " 1---->  marcel <low_freq> ( born april 14 , 1991 ) is a <split> he german footballer who is currently a free agent .\n",
      " 2---->  marcel <low_freq> ( born april 14 , 1991 ) is . <split> a german footballer who is currently a free agent .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=0.054153670-rec_loss=0.465374857-lm_rewards=-88.6284-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[11-[of]-15839]-lr=0.0050\n",
      " --->  starting time-[2019-03-08-20-28-22]-\n",
      "time-[2019-03-08-20-28-27]-\n",
      " --->  starting time-[2019-03-08-20-28-27]-\n",
      "time-[2019-03-08-20-28-58]-\n",
      " --->  starting time-[2019-03-08-20-28-58]-\n",
      "time-[2019-03-08-20-29-02]-\n",
      " --->  starting time-[2019-03-08-20-29-02]-\n",
      "time-[2019-03-08-20-29-34]-\n",
      " --->  starting time-[2019-03-08-20-29-34]-\n",
      "time-[2019-03-08-20-29-38]-\n",
      " --->  starting time-[2019-03-08-20-29-38]-\n",
      "time-[2019-03-08-20-30-11]-\n",
      " --->  starting time-[2019-03-08-20-30-11]-\n",
      "time-[2019-03-08-20-30-15]-\n",
      " --->  starting time-[2019-03-08-20-30-15]-\n",
      "time-[2019-03-08-20-30-46]-\n",
      " --->  starting time-[2019-03-08-20-30-46]-\n",
      "time-[2019-03-08-20-30-51]-\n",
      " --->  starting time-[2019-03-08-20-30-51]-\n",
      "time-[2019-03-08-20-31-22]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  the river thames flowed further north than it does today before converging with the ancient <low_freq> river . while the ancient of a large part <split> the of modern - day norfolk and suffolk consisted of a series of clay ridges and <low_freq> known as the east anglian crag basin .\n",
      " 2---->  the river thames flowed further north than it does today before converging with the ancient <low_freq> river , while the landscape of a large . <split> part of modern - day norfolk and suffolk consisted of a series of clay ridges and <low_freq> known as the east anglian crag basin .\n",
      "\n",
      "\n",
      " 1---->  the river <low_freq> is a small stream running through bristol , a city in the <split> it stream of england , which flows into the river avon at sea mills .\n",
      " 2---->  the river <low_freq> is a small stream running through bristol , a city in . <split> the southwest of england , which flows into the river avon at sea mills .\n",
      "\n",
      "\n",
      " 1---->  the river tweed , or tweed water , ( , ) is long and flows primarily through the scenic borders region of scotland <split> it is and eastwards from the settlements on opposing banks of <low_freq> and <low_freq> forms the historic boundary between scotland and england .\n",
      " 2---->  the river tweed , or tweed water , ( , ) is long and flows primarily through the scenic borders region of . <split> scotland , and eastwards from the settlements on opposing banks of <low_freq> and <low_freq> forms the historic boundary between scotland and england .\n",
      "\n",
      "\n",
      " 1---->  the river ure runs along the south side of the grounds <split> it are the have extensive herbaceous borders and woodland walks .\n",
      " 2---->  the river ure runs along the south side of the . <split> grounds , which have extensive herbaceous borders and woodland walks .\n",
      "\n",
      "\n",
      " 1---->  the river view observer is a monthly newspaper , published in hudson county , new jersey . <split> it it owned by ad vantage publishing inc. , which also publishes the bayonne observer newspaper .\n",
      " 2---->  the river view observer is a monthly newspaper , published in hudson county , new jersey . <split> , and owned by ad vantage publishing inc. , which also publishes the bayonne observer newspaper .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.175881952-rec_loss=0.228676572-lm_rewards=-114.4590-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[21-[of]-15839]-lr=0.0050\n",
      "info=[split_model]-total_loss=-0.175881952-rec_loss=0.228676572-lm_rewards=-114.4590-bleu=0.7312-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[21-[of]-15839]-lr=0.0050-loss_ratio=0.9000 0.7312425754293278\n",
      " --->  starting time-[2019-03-08-20-31-23]-\n",
      "time-[2019-03-08-20-31-28]-\n",
      " --->  starting time-[2019-03-08-20-31-28]-\n",
      "time-[2019-03-08-20-32-01]-\n",
      " --->  starting time-[2019-03-08-20-32-01]-\n",
      "time-[2019-03-08-20-32-06]-\n",
      " --->  starting time-[2019-03-08-20-32-06]-\n",
      "time-[2019-03-08-20-32-37]-\n",
      " --->  starting time-[2019-03-08-20-32-37]-\n",
      "time-[2019-03-08-20-32-42]-\n",
      " --->  starting time-[2019-03-08-20-32-42]-\n",
      "time-[2019-03-08-20-33-13]-\n",
      " --->  starting time-[2019-03-08-20-33-13]-\n",
      "time-[2019-03-08-20-33-18]-\n",
      " --->  starting time-[2019-03-08-20-33-18]-\n",
      "time-[2019-03-08-20-33-51]-\n",
      " --->  starting time-[2019-03-08-20-33-51]-\n",
      "time-[2019-03-08-20-33-56]-\n",
      " --->  starting time-[2019-03-08-20-33-56]-\n",
      "time-[2019-03-08-20-34-27]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  cory <low_freq> ( born 2 december 1986 in <low_freq> , victoria ) is an australian international motorcycle speedway rider who rides for the <split> rides international rebels in the british premier <low_freq> is also a member of the swindon robins squad in the elite league .\n",
      " 2---->  cory <low_freq> ( born 2 december 1986 in <low_freq> , victoria ) is an australian international motorcycle speedway rider who rides for . <split> the somerset rebels in the british premier <low_freq> is also a member of the swindon robins squad in the elite league .\n",
      "\n",
      "\n",
      " 1---->  cory jermaine carr ( born december 5 1975 in <low_freq> , arkansas ) is a american basketball player . formerly of the chicago bulls <split> during and texas tech. during his career at texas tech , he has scored <low_freq> career points , and grabbed 411 rebounds .\n",
      " 2---->  cory jermaine carr ( born december 5 1975 in <low_freq> , arkansas ) is a american basketball player , formerly of the chicago . <split> bulls and texas tech. during his career at texas tech , he has scored <low_freq> career points , and grabbed 411 rebounds .\n",
      "\n",
      "\n",
      " 1---->  cory mason is a democratic party member of the wisconsin state assembly . <split> he representing the 62nd assembly district since his election in 2006 .\n",
      " 2---->  cory mason is a democratic party member of the wisconsin state assembly . <split> , representing the 62nd assembly district since his election in 2006 .\n",
      "\n",
      "\n",
      " 1---->  cory morgan ( born 1971 , in red deer , alberta ) founded the alberta independence party in 2000 . led the <split> he party led an election later that year , offering himself as a candidate in the riding of banff - cochrane .\n",
      " 2---->  cory morgan ( born 1971 , in red deer , alberta ) founded the alberta independence party in 2000 and led . <split> the party into an election later that year , offering himself as a candidate in the riding of banff - cochrane .\n",
      "\n",
      "\n",
      " 1---->  cory <low_freq> ( born august 16 , 1978 ) is a canadian professional ice hockey defenceman of croatian ancestry <split> he is currently plays for the colorado avalanche organization of the national hockey league ( nhl ) .\n",
      " 2---->  cory <low_freq> ( born august 16 , 1978 ) is a canadian professional ice hockey defenceman of croatian . <split> ancestry who currently plays for the colorado avalanche organization of the national hockey league ( nhl ) .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.229287326-rec_loss=0.138032913-lm_rewards=-59.3801-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[31-[of]-15839]-lr=0.0050\n",
      " --->  starting time-[2019-03-08-20-34-27]-\n",
      "time-[2019-03-08-20-34-32]-\n",
      " --->  starting time-[2019-03-08-20-34-32]-\n",
      "time-[2019-03-08-20-35-05]-\n",
      " --->  starting time-[2019-03-08-20-35-05]-\n",
      "time-[2019-03-08-20-35-10]-\n",
      " --->  starting time-[2019-03-08-20-35-10]-\n",
      "time-[2019-03-08-20-35-42]-\n",
      " --->  starting time-[2019-03-08-20-35-42]-\n",
      "time-[2019-03-08-20-35-47]-\n",
      " --->  starting time-[2019-03-08-20-35-47]-\n",
      "time-[2019-03-08-20-36-18]-\n",
      " --->  starting time-[2019-03-08-20-36-18]-\n",
      "time-[2019-03-08-20-36-22]-\n",
      " --->  starting time-[2019-03-08-20-36-22]-\n",
      "time-[2019-03-08-20-36-56]-\n",
      " --->  starting time-[2019-03-08-20-36-56]-\n",
      "time-[2019-03-08-20-37-01]-\n",
      " --->  starting time-[2019-03-08-20-37-01]-\n",
      "time-[2019-03-08-20-37-32]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  <low_freq> met with resistance at pitcher 's brook , primarily from the guns directed by <split> primarily the , but john sent reinforcements and the british stormed across the bridge .\n",
      " 2---->  <low_freq> met with resistance at pitcher 's brook , primarily from the guns directed . <split> by lewis , but john sent reinforcements and the british stormed across the bridge .\n",
      "\n",
      "\n",
      " 1---->  skirt dancing , which was a huge craze from the 1880s to around 1910 , fused the grace of <split> the the with the <low_freq> of step - dancing , which was considered common and lacking in grace .\n",
      " 2---->  skirt dancing , which was a huge craze from the 1880s to around 1910 , fused the grace . <split> of ballet with the <low_freq> of step - dancing , which was considered common and lacking in grace .\n",
      "\n",
      "\n",
      " 1---->  <low_freq> the little belt mountains by driving southeast , he crossed arrow creek , he south through the judith gap ( the big snowy <split> the mountains to the east , the little belts to the west , , and crossed several tributaries of the judith river .\n",
      " 2---->  <low_freq> the little belt mountains by driving southeast , he crossed arrow creek , passed south through the judith gap ( the big . <split> snowy mountains to the east , the little belts to the west ) , and crossed several tributaries of the judith river .\n",
      "\n",
      "\n",
      " 1---->  skirts with back <low_freq> continue to be commonplace . and are likely to remain commonplace after other garments <split> the are back closures lose popularity because they allow for a woman to easily dress herself .\n",
      " 2---->  skirts with back <low_freq> continue to be commonplace , and are likely to remain long after other . <split> garments with back closures lose popularity because they allow for a woman to easily dress herself .\n",
      "\n",
      "\n",
      " 1---->  skis are 30 % longer than those used in slalom , for more stability at high <split> for speed and often have rounded , low - profile tips rather than pointed tips .\n",
      " 2---->  skis are 30 % longer than those used in slalom , for more stability at . <split> high speed and often have rounded , low - profile tips rather than pointed tips .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.008834000-rec_loss=0.214305148-lm_rewards=-66.9313-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[41-[of]-15839]-lr=0.0050\n",
      "info=[split_model]-total_loss=-0.008834000-rec_loss=0.214305148-lm_rewards=-66.9313-bleu=0.6819-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[41-[of]-15839]-lr=0.0050-loss_ratio=0.9000 0.6819485306823048\n",
      " --->  starting time-[2019-03-08-20-37-33]-\n",
      "time-[2019-03-08-20-37-38]-\n",
      " --->  starting time-[2019-03-08-20-37-38]-\n",
      "time-[2019-03-08-20-38-09]-\n",
      " --->  starting time-[2019-03-08-20-38-09]-\n",
      "time-[2019-03-08-20-38-13]-\n",
      " --->  starting time-[2019-03-08-20-38-13]-\n",
      "time-[2019-03-08-20-38-46]-\n",
      " --->  starting time-[2019-03-08-20-38-46]-\n",
      "time-[2019-03-08-20-38-51]-\n",
      " --->  starting time-[2019-03-08-20-38-51]-\n",
      "time-[2019-03-08-20-39-22]-\n",
      " --->  starting time-[2019-03-08-20-39-22]-\n",
      "time-[2019-03-08-20-39-26]-\n",
      " --->  starting time-[2019-03-08-20-39-26]-\n",
      "time-[2019-03-08-20-39-57]-\n",
      " --->  starting time-[2019-03-08-20-39-57]-\n",
      "time-[2019-03-08-20-40-03]-\n",
      " --->  starting time-[2019-03-08-20-40-03]-\n",
      "time-[2019-03-08-20-40-36]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  alternative names for it are <low_freq> , while it is a as '' <split> it <low_freq> '' is italian and as '' <low_freq> '' in italian .\n",
      " 2---->  alternative names for it are <low_freq> , while it is known as . <split> '' <low_freq> '' in italian and as '' <low_freq> '' in turkish .\n",
      "\n",
      "\n",
      " 1---->  alternative names for the iris <low_freq> is '' iris <low_freq> '' and '' iris <low_freq> '' and '' '' known commonly <split> the , '' shallow - flower iris '' , it yan zi hua '' , '' yan zi hua '' .\n",
      " 2---->  alternative names for the iris <low_freq> is '' iris <low_freq> '' and '' iris <low_freq> '' and is sometimes known . <split> commonly as '' shallow - flower iris '' , '' yan zi hua '' or '' yan zi hua '' .\n",
      "\n",
      "\n",
      " 1---->  alternative rock band kings of leon 's '' only by the night '' had the longest run among the releases that have reached peak <split> the position in 2008 , spending 13 non-consecutive weeks beginning with the chart dated september 29 and continuing into the 2009 chart year .\n",
      " 2---->  alternative rock band kings of leon 's '' only by the night '' had the longest run among the releases that have reached . <split> peak position in 2008 , spending 13 non-consecutive weeks beginning with the chart dated september 29 and continuing into the 2009 chart year .\n",
      "\n",
      "\n",
      " 1---->  alternative rock band the foo fighters has a track titled '' <low_freq> '' on their 2011 release '' wasting light <split> the '' , front man ( and <low_freq> drummer ) dave grohl lived in alexandria during his childhood .\n",
      " 2---->  alternative rock band the foo fighters has a track titled '' <low_freq> '' on their 2011 release '' wasting . <split> light '' ; front man ( and <low_freq> drummer ) dave grohl lived in alexandria during his childhood .\n",
      "\n",
      "\n",
      " 1---->  alternative routes run at peak hours , and the middle two do not run during late evenings <split> the , the route 1 listed above is also extended to epsom and epsom downs .\n",
      " 2---->  alternative routes run at peak hours , and the middle two do not run during late . <split> evenings , when route 1 listed above is also extended to epsom and epsom downs .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=0.192816928-rec_loss=0.198042259-lm_rewards=-54.7722-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[51-[of]-15839]-lr=0.0050\n",
      " --->  starting time-[2019-03-08-20-40-36]-\n",
      "time-[2019-03-08-20-40-41]-\n",
      " --->  starting time-[2019-03-08-20-40-41]-\n",
      "time-[2019-03-08-20-41-12]-\n",
      " --->  starting time-[2019-03-08-20-41-12]-\n",
      "time-[2019-03-08-20-41-17]-\n",
      " --->  starting time-[2019-03-08-20-41-17]-\n",
      "time-[2019-03-08-20-41-49]-\n",
      " --->  starting time-[2019-03-08-20-41-49]-\n",
      "time-[2019-03-08-20-41-53]-\n",
      " --->  starting time-[2019-03-08-20-41-53]-\n",
      "time-[2019-03-08-20-42-27]-\n",
      " --->  starting time-[2019-03-08-20-42-27]-\n",
      "time-[2019-03-08-20-42-32]-\n",
      " --->  starting time-[2019-03-08-20-42-32]-\n",
      "time-[2019-03-08-20-43-03]-\n",
      " --->  starting time-[2019-03-08-20-43-03]-\n",
      "time-[2019-03-08-20-43-08]-\n",
      " --->  starting time-[2019-03-08-20-43-08]-\n",
      "time-[2019-03-08-20-43-39]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  in addition , the short '' o '' is usually promoted to a long '' o '' in israeli writing for the sake <split> the of disambiguation as well , the short '' o '' and long '' a '' have the same '' <low_freq> '' .\n",
      " 2---->  in addition , the short '' o '' is usually promoted to a long '' o '' in israeli writing for the . <split> sake of disambiguation as well , the short '' o '' and long '' a '' have the same '' <low_freq> '' .\n",
      "\n",
      "\n",
      " 1---->  in addition , the simultaneous operation of <low_freq> and <low_freq> ( see below ) made montreal less <split> the attractive to international airlines who responded by shifting their routes to toronto pearson airport .\n",
      " 2---->  in addition , the simultaneous operation of <low_freq> and <low_freq> ( see below ) made montreal . <split> less attractive to international airlines who responded by shifting their routes to toronto pearson airport .\n",
      "\n",
      "\n",
      " 1---->  in addition , the site has undertaken a <low_freq> campaign against the notion that vocabulary patterns within a language have deep psychological significance for the <split> the <low_freq> speaks speaks that language -- their constant <low_freq> of the original <low_freq> mentioned above has been rather effective in this regard .\n",
      " 2---->  in addition , the site has undertaken a <low_freq> campaign against the notion that vocabulary patterns within a language have deep psychological significance for . <split> the culture that speaks that language -- their constant <low_freq> of the original <low_freq> mentioned above has been rather effective in this regard .\n",
      "\n",
      "\n",
      " 1---->  in addition , the song '' eyes '' was featured in the movie '' just friends '' and in episodes <split> the of '' heroes '' , '' friday night lights '' , '' scrubs '' and '' chuck '' .\n",
      " 2---->  in addition , the song '' eyes '' was featured in the movie '' just friends '' and in . <split> episodes of '' heroes '' , '' friday night lights '' , '' scrubs '' and '' chuck '' .\n",
      "\n",
      "\n",
      " 1---->  in addition , the song '' red rock '' by the <low_freq> ' <low_freq> is about lane . and <split> the he is also mentioned at the end of korn 's '' hold on '' music video .\n",
      " 2---->  in addition , the song '' red rock '' by the <low_freq> ' <low_freq> is about lane , . <split> and he is also mentioned at the end of korn 's '' hold on '' music video .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-2436828758016.000000000-rec_loss=0.181215063-lm_rewards=-9605027463168.0000-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[61-[of]-15839]-lr=0.0050\n",
      "info=[split_model]-total_loss=-2436828758016.000000000-rec_loss=0.181215063-lm_rewards=-9605027463168.0000-bleu=0.7100-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[61-[of]-15839]-lr=0.0050-loss_ratio=0.9000 0.7100408244204565\n",
      " --->  starting time-[2019-03-08-20-43-40]-\n",
      "time-[2019-03-08-20-43-45]-\n",
      " --->  starting time-[2019-03-08-20-43-45]-\n",
      "time-[2019-03-08-20-44-18]-\n",
      " --->  starting time-[2019-03-08-20-44-18]-\n",
      "time-[2019-03-08-20-44-23]-\n",
      " --->  starting time-[2019-03-08-20-44-23]-\n",
      "time-[2019-03-08-20-44-56]-\n",
      " --->  starting time-[2019-03-08-20-44-56]-\n",
      "time-[2019-03-08-20-45-00]-\n",
      " --->  starting time-[2019-03-08-20-45-00]-\n",
      "time-[2019-03-08-20-45-31]-\n",
      " --->  starting time-[2019-03-08-20-45-31]-\n",
      "time-[2019-03-08-20-45-36]-\n",
      " --->  starting time-[2019-03-08-20-45-36]-\n",
      "time-[2019-03-08-20-46-09]-\n",
      " --->  starting time-[2019-03-08-20-46-09]-\n",
      "time-[2019-03-08-20-46-14]-\n",
      " --->  starting time-[2019-03-08-20-46-14]-\n",
      "time-[2019-03-08-20-46-46]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  the declaration was requested on april 1 by the <low_freq> <low_freq> a said that the the families needed help <split> the of the to other needs , and the estimated that financial losses had been $ 10 million .\n",
      " 2---->  the declaration was requested on april 1 by governor <low_freq> , who said that about 30 families needed . <split> help with housing and other needs , and who estimated that financial losses had reached $ 10 million .\n",
      "\n",
      "\n",
      " 1---->  the decline from this peak signaled the beginning of the dot - com . . <split> the from <low_freq> the uses <low_freq> , is <low_freq> opposed to the ) .\n",
      " 2---->  the decline from this peak signaled the beginning of the dot - com bubble . <split> burst , if one uses <low_freq> , ( as opposed to <low_freq> ) .\n",
      "\n",
      "\n",
      " 1---->  the decline in prairie has has been impacted many of the other animals . are in the <low_freq> grass <split> the - , <low_freq> the <low_freq> <low_freq> ) <low_freq> ) ) , is diet relies on the whose .\n",
      " 2---->  the decline in prairie dogs has significantly impacted many of the other animals that reside in the short . <split> grass prairie , including the ( black - footed <low_freq> ) , whose diet relies on prairie dogs .\n",
      "\n",
      "\n",
      " 1---->  the decline in the price of the and near the simultaneous failure of the downtown anchors the the central business district into recession <split> the , the 1980s , the the <low_freq> was also again , various initiatives , including the second <low_freq> project in 1992 .\n",
      " 2---->  the decline in the price of petroleum and near - simultaneous failure of several downtown anchors placed the central business district into . <split> recession in the 1980s , and the downtown was <low_freq> again through various initiatives , including its second <low_freq> project in 1992 .\n",
      "\n",
      "\n",
      " 1---->  the decline in the tea industry has been the poverty and unemployment in the . <split> the <low_freq> are most of the employment opportunities apart from the tea gardens .\n",
      " 2---->  the decline in the tea industry has increased the poverty and unemployment in the . <split> neighbouring areas provides most of the employment opportunities apart from the tea gardens .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.117181391-rec_loss=1.382281780-lm_rewards=-92.1296-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[71-[of]-15839]-lr=0.0050\n",
      " --->  starting time-[2019-03-08-20-46-46]-\n",
      "time-[2019-03-08-20-46-51]-\n",
      " --->  starting time-[2019-03-08-20-46-51]-\n",
      "time-[2019-03-08-20-47-22]-\n",
      " --->  starting time-[2019-03-08-20-47-22]-\n",
      "time-[2019-03-08-20-47-27]-\n",
      " --->  starting time-[2019-03-08-20-47-27]-\n",
      "time-[2019-03-08-20-48-00]-\n",
      " --->  starting time-[2019-03-08-20-48-00]-\n",
      "time-[2019-03-08-20-48-05]-\n",
      " --->  starting time-[2019-03-08-20-48-05]-\n",
      "time-[2019-03-08-20-48-36]-\n",
      " --->  starting time-[2019-03-08-20-48-36]-\n",
      "time-[2019-03-08-20-48-41]-\n",
      " --->  starting time-[2019-03-08-20-48-41]-\n",
      "time-[2019-03-08-20-49-14]-\n",
      " --->  starting time-[2019-03-08-20-49-14]-\n",
      "time-[2019-03-08-20-49-19]-\n",
      " --->  starting time-[2019-03-08-20-49-19]-\n",
      "time-[2019-03-08-20-49-50]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  on march 8 , , , the was the . was arrived . the <low_freq> of the <split> the <low_freq> river the was sent an <low_freq> to led by the singh to kabul .\n",
      " 2---->  on march 8 , 1581 , akbar reached <low_freq> and soon arrived on the banks of . <split> river indus , he then sent an advance force led by man singh to kabul .\n",
      "\n",
      "\n",
      " 1---->  on march 8 , , , the is to , and a <low_freq> . . the time declared his own . was a the <split> the also be the career in a result of to be a first eagle scout award from the boy scouts of america .\n",
      " 2---->  on march 8 , 1991 , <low_freq> went public , holding a press conference at which he discussed his condition and declared that . <split> he would use his illness as a leadership project to earn the coveted eagle scout award from the boy scouts of america .\n",
      "\n",
      "\n",
      " 1---->  on march 8 , , , the song his <low_freq> alternative investment . for the equity . which <low_freq> . <low_freq> <low_freq> <split> the - <low_freq> <low_freq> ) be ) ) , <low_freq> is released of the most 's leading retail brands by funds that\n",
      " 2---->  on march 8 , 1996 , baha launched his first alternative investment product for private investors , the <low_freq> q - . <split> ag ( now closed to new investors ) , which was one of the world 's first retail managed futures funds .\n",
      "\n",
      "\n",
      " 1---->  on march 8 , the , the of <low_freq> first was were <low_freq> were converted from the <split> the , , was in of the three well - known , and in the uk .\n",
      " 2---->  on march 8 , 2006 , all mcrae 's and <low_freq> 's stores were converted into . <split> belk stores which ended two of the most well - known retailing names in the south .\n",
      "\n",
      "\n",
      " 1---->  on march 8 , , , the song have a . <split> the the <low_freq> 1 million years the - year - with\n",
      " 2---->  on march 8 , 2007 , the cardinals signed holt . <split> to a $ 15 million , 5 - year contract .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.118031159-rec_loss=2.808565378-lm_rewards=-45.6384-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[81-[of]-15839]-lr=0.0050\n",
      "info=[split_model]-total_loss=-0.118031159-rec_loss=2.808565378-lm_rewards=-45.6384-bleu=0.2055-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[81-[of]-15839]-lr=0.0050-loss_ratio=0.9000 0.20550719988191862\n",
      " --->  starting time-[2019-03-08-20-49-51]-\n",
      "time-[2019-03-08-20-49-56]-\n",
      " --->  starting time-[2019-03-08-20-49-56]-\n",
      "time-[2019-03-08-20-50-27]-\n",
      " --->  starting time-[2019-03-08-20-50-27]-\n",
      "time-[2019-03-08-20-50-32]-\n",
      " --->  starting time-[2019-03-08-20-50-32]-\n",
      "time-[2019-03-08-20-51-05]-\n",
      " --->  starting time-[2019-03-08-20-51-05]-\n",
      "time-[2019-03-08-20-51-10]-\n",
      " --->  starting time-[2019-03-08-20-51-10]-\n",
      "time-[2019-03-08-20-51-41]-\n",
      " --->  starting time-[2019-03-08-20-51-41]-\n",
      "time-[2019-03-08-20-51-46]-\n",
      " --->  starting time-[2019-03-08-20-51-46]-\n",
      "time-[2019-03-08-20-52-18]-\n",
      " --->  starting time-[2019-03-08-20-52-18]-\n",
      "time-[2019-03-08-20-52-23]-\n",
      " --->  starting time-[2019-03-08-20-52-23]-\n",
      "time-[2019-03-08-20-52-56]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  george britton ( 19 october 1910 -- june august 1991 ) was a american bass singer rock . was <split> <low_freq> a instrumental performing career , the , the , released was , the song through the 1960s .\n",
      " 2---->  george britton ( 19 october 1910 - 16 august 1991 ) was an american bass - baritone who . <split> had an active performing career in operas , concerts , and musicals during the 1930s through the 1960s .\n",
      "\n",
      "\n",
      " 1---->  george brock ( born 7 november 1951 ) is a former of the at of the at <split> <low_freq> the 's the , the times , the christi college , he , 1973 ,\n",
      " 2---->  george brock ( born 7 november 1951 ) is a professor of journalism department of journalism . <split> at master of arts in modern history from corpus christi college , oxford in 1973 .\n",
      "\n",
      "\n",
      " 1---->  george broughton jr. is a professional rugby league footballer who played in the united , and is . and <split> the as the , the , he the , the well result he , of , 5 .\n",
      " 2---->  george broughton jr. is a professional rugby league footballer who played in the 1940s , and 1950s , . <split> playing at club for castleford , and leeds , as a , i.e. number 2 or 5 .\n",
      "\n",
      "\n",
      " 1---->  george brown is a former rugby league footballer who played in the united <split> he , he was , he as the , , the .\n",
      " 2---->  george brown is a professional rugby league footballer who played in the . <split> 1950s , and 1960s , playing at club level for castleford .\n",
      "\n",
      "\n",
      " 1---->  george brown was persuaded to be the bodies . and was was not <split> the the <low_freq> of the other , the , , the ,\n",
      " 2---->  george brown was persuaded to <low_freq> the bodies , which he did . <split> with the help of several villagers on march 17 , 1892 .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.034475785-rec_loss=2.575711012-lm_rewards=-48.0380-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[91-[of]-15839]-lr=0.0050\n",
      " --->  starting time-[2019-03-08-20-52-57]-\n",
      "time-[2019-03-08-20-53-02]-\n",
      " --->  starting time-[2019-03-08-20-53-02]-\n",
      "time-[2019-03-08-20-53-33]-\n",
      " --->  starting time-[2019-03-08-20-53-33]-\n",
      "time-[2019-03-08-20-53-38]-\n",
      " --->  starting time-[2019-03-08-20-53-38]-\n",
      "time-[2019-03-08-20-54-09]-\n",
      " --->  starting time-[2019-03-08-20-54-09]-\n",
      "time-[2019-03-08-20-54-14]-\n",
      " --->  starting time-[2019-03-08-20-54-14]-\n",
      "time-[2019-03-08-20-54-48]-\n",
      " --->  starting time-[2019-03-08-20-54-48]-\n",
      "time-[2019-03-08-20-54-53]-\n",
      " --->  starting time-[2019-03-08-20-54-53]-\n",
      "time-[2019-03-08-20-55-24]-\n",
      " --->  starting time-[2019-03-08-20-55-24]-\n",
      "time-[2019-03-08-20-55-29]-\n",
      " --->  starting time-[2019-03-08-20-55-29]-\n",
      "time-[2019-03-08-20-56-00]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  the original reason for this long dispute is a . and , do know of the of the songs . . the <low_freq> between . <split> the also the , , , the of the most characters was to , the every , the , and , and , , .\n",
      " 2---->  the original reason for this long dispute is unknown , however we do know of some of the affairs that kept the feud alive . <split> and becoming ever more intense : one of the main factors was jealousy about nearly everything : titles , wealth , women and land .\n",
      "\n",
      "\n",
      " 1---->  the original recipe also advised to soak the <low_freq> in water . . the is - . . a <split> the vary the <low_freq> - <low_freq> bit '' , the is <low_freq> need have the the variety treatment ,\n",
      " 2---->  the original recipe also advised to soak the oats in water overnight ; this long soaking time is . <split> unnecessary with modern rolled '' quick oats '' , which the manufacturers already soften through a steam treatment .\n",
      "\n",
      "\n",
      " 1---->  the original recording of the the memory is a song to <low_freq> . a alternative of the <split> the song the records , the such were the band the time , the 28 1965 .\n",
      " 2---->  the original recording of in loving memory is a tribute to <low_freq> as an expression of . <split> love from motown stars in songs who paid tribute at her funeral on july 29th 1965 .\n",
      "\n",
      "\n",
      " 1---->  the original recording runs for the minutes , was . . and highest single notes . the <split> the <low_freq> '' is be have the 's debut - , the , his fifth symphony ,\n",
      " 2---->  the original recording runs for 6 minutes and 34 seconds , the first six notes of . <split> '' <low_freq> '' may well demonstrate anderson 's clear interest in beethoven and his fifth symphony .\n",
      "\n",
      "\n",
      " 1---->  the original recordings are not known as be been . and song album 's <low_freq> , the <low_freq> <split> the , song released by <low_freq> <low_freq> , the , the single drawing from the <low_freq> ,\n",
      " 2---->  the original recordings are not known to have survived , the 1964 master - script by <low_freq> . <split> <low_freq> ' , published by <low_freq> productions in 1977 with a cover drawing by <low_freq> <low_freq> .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.044238739-rec_loss=2.718401432-lm_rewards=-35.8312-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[101-[of]-15839]-lr=0.0050\n",
      "info=[split_model]-total_loss=-0.044238739-rec_loss=2.718401432-lm_rewards=-35.8312-bleu=0.1178-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[101-[of]-15839]-lr=0.0050-loss_ratio=0.9000 0.11781965711240228\n",
      " --->  starting time-[2019-03-08-20-56-02]-\n",
      "time-[2019-03-08-20-56-07]-\n",
      " --->  starting time-[2019-03-08-20-56-07]-\n",
      "time-[2019-03-08-20-56-40]-\n",
      " --->  starting time-[2019-03-08-20-56-40]-\n",
      "time-[2019-03-08-20-56-45]-\n",
      " --->  starting time-[2019-03-08-20-56-45]-\n",
      "time-[2019-03-08-20-57-16]-\n",
      " --->  starting time-[2019-03-08-20-57-16]-\n",
      "time-[2019-03-08-20-57-21]-\n",
      " --->  starting time-[2019-03-08-20-57-21]-\n",
      "time-[2019-03-08-20-57-52]-\n",
      " --->  starting time-[2019-03-08-20-57-52]-\n",
      "time-[2019-03-08-20-57-57]-\n",
      " --->  starting time-[2019-03-08-20-57-57]-\n",
      "time-[2019-03-08-20-58-31]-\n",
      " --->  starting time-[2019-03-08-20-58-31]-\n",
      "time-[2019-03-08-20-58-35]-\n",
      " --->  starting time-[2019-03-08-20-58-35]-\n",
      "time-[2019-03-08-20-59-06]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  there are several types of the allocation of based on the . . including tolerance and <split> the <low_freq> , are digital are <low_freq> partnerships infrastructure , provision a instrumentation <low_freq> healthcare\n",
      " 2---->  there are several types of asset allocation strategies based on investment goals , risk tolerance . <split> , time frames and diversification : strategic , tactical , and core - satellite .\n",
      "\n",
      "\n",
      " 1---->  there are several types of the , the . . <split> the the are the '' , and and the .\n",
      " 2---->  there are several types of flags within the game . <split> , they include : normal , public and private .\n",
      "\n",
      "\n",
      " 1---->  there are several types of the treatment . . which with which is <split> the be the to the <low_freq> , more the to treat <low_freq> .\n",
      " 2---->  there are several types of passive treatment systems , each of which . <split> may be used on their own or in combination to treat <low_freq> .\n",
      "\n",
      "\n",
      " 1---->  there are several types of the that are often . to the with the . . <low_freq> . <split> the the to the <low_freq> of <low_freq> are are also , those who types of transformation .\n",
      " 2---->  there are several types of transformations that are <low_freq> considered when dealing with invariant <low_freq> : each . <split> gives rise to a class of <low_freq> which are invariant to those particular types of transformation .\n",
      "\n",
      "\n",
      " 1---->  there are several unofficial applications that are the <low_freq> . . the website network . which the <low_freq> '' a '' . and . '' <split> the , digital <low_freq> '' , an <low_freq> '' , '' <low_freq> '' '' , '' <low_freq> app. , as is '' <low_freq> '' (\n",
      " 2---->  there are several unofficial applications that use the reddit api on the google play , including '' reddit is fun '' , '' <low_freq> . <split> '' , '' f5 '' , '' <low_freq> '' , '' reddit sync '' and an android tablet specific application called '' <low_freq> '' .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.029296035-rec_loss=2.694491386-lm_rewards=-35.8161-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[111-[of]-15839]-lr=0.0050\n",
      " --->  starting time-[2019-03-08-20-59-07]-\n",
      "time-[2019-03-08-20-59-12]-\n",
      " --->  starting time-[2019-03-08-20-59-12]-\n",
      "time-[2019-03-08-20-59-43]-\n",
      " --->  starting time-[2019-03-08-20-59-43]-\n",
      "time-[2019-03-08-20-59-48]-\n",
      " --->  starting time-[2019-03-08-20-59-48]-\n",
      "time-[2019-03-08-21-00-21]-\n",
      " --->  starting time-[2019-03-08-21-00-21]-\n",
      "time-[2019-03-08-21-00-26]-\n",
      " --->  starting time-[2019-03-08-21-00-26]-\n",
      "time-[2019-03-08-21-00-56]-\n",
      " --->  starting time-[2019-03-08-21-00-56]-\n",
      "time-[2019-03-08-21-01-01]-\n",
      " --->  starting time-[2019-03-08-21-01-01]-\n",
      "time-[2019-03-08-21-01-33]-\n",
      " --->  starting time-[2019-03-08-21-01-33]-\n",
      "time-[2019-03-08-21-01-37]-\n",
      " --->  starting time-[2019-03-08-21-01-37]-\n",
      "time-[2019-03-08-21-02-11]-\n",
      "--------split model training sampling display--------\n",
      " 1---->  <low_freq> , '' a '' '' the <low_freq> , , album , '' the to <split> the song song released released been released as the artists such the , ,\n",
      " 2---->  <low_freq> , '' a track from the band 's debut album , is considered . <split> a classic and has since been reworked by other artists including system 7 .\n",
      "\n",
      "\n",
      " 1---->  halloween addiction '' is a song ep , the . . released is <split> the a songs released , the , '' , '' song track is\n",
      " 2---->  halloween addiction '' is a halloween ep by <low_freq> <low_freq> , and . <split> contains two previously released '' halloween singles '' and one new track .\n",
      "\n",
      "\n",
      " 1---->  hand springs '' was a as a single . the band <split> the song , the , <low_freq> below ) the ) was\n",
      " 2---->  hand springs '' was released as a single by the . <split> white stripes in 1999 ( see 1999 in music ) .\n",
      "\n",
      "\n",
      " 1---->  <low_freq> '' is a <low_freq> by the . released song was released on a <split> the song single released the song album '' '' <low_freq> '' '' '' ,\n",
      " 2---->  <low_freq> '' is a song by <low_freq> , the song was released as . <split> the first single from their debut album , '' fight with tools '' .\n",
      "\n",
      "\n",
      " 1---->  hang on in there is is is a song written by the <low_freq> . released released by <low_freq> <split> the pop - songwriter , <low_freq> , the debut album album '' '' <low_freq> road '' ,\n",
      " 2---->  hang on in there baby '' is a song written by johnny bristol , and recorded by . <split> british singer - songwriter gary barlow for his debut solo album , '' open road '' .\n",
      "\n",
      "\n",
      "info=[split_model]-total_loss=-0.017839814-rec_loss=2.547251463-lm_rewards=-38.3235-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[121-[of]-15839]-lr=0.0050\n",
      "info=[split_model]-total_loss=-0.017839814-rec_loss=2.547251463-lm_rewards=-38.3235-bleu=0.1185-hidden_dim=256-input_dim=100-epoch=0-batch_size=50-batch_id=[121-[of]-15839]-lr=0.0050-loss_ratio=0.9000 0.11849178773165671\n",
      " --->  starting time-[2019-03-08-21-02-12]-\n",
      "time-[2019-03-08-21-02-17]-\n",
      " --->  starting time-[2019-03-08-21-02-17]-\n",
      "time-[2019-03-08-21-02-49]-\n",
      " --->  starting time-[2019-03-08-21-02-49]-\n",
      "time-[2019-03-08-21-02-54]-\n",
      " --->  starting time-[2019-03-08-21-02-54]-\n",
      "time-[2019-03-08-21-03-25]-\n",
      " --->  starting time-[2019-03-08-21-03-25]-\n",
      "time-[2019-03-08-21-03-30]-\n",
      " --->  starting time-[2019-03-08-21-03-30]-\n",
      "time-[2019-03-08-21-04-03]-\n",
      " --->  starting time-[2019-03-08-21-04-03]-\n",
      "time-[2019-03-08-21-04-08]-\n",
      " --->  starting time-[2019-03-08-21-04-08]-\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-de71b88bed8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_train_set_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running time: %.2f mins'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-de71b88bed8b>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(epoch, batch_size, train_set_size)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                    topk=topk, loss_ratio=loss_ratio)\n\u001b[1;32m     61\u001b[0m             \u001b[0mreconstruct_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruct_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0msplit_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=50\n",
    "split_train_set_size=int(len(split_train_set_inputs)/1)\n",
    "epochs=10000\n",
    "train_bleu_mean=-1\n",
    "train_bleu_max=-1\n",
    "topk=2\n",
    "loss_ratio=0.999\n",
    "\n",
    "sup_bsize=50\n",
    "dataset_times = int(split_train_set_size/len(split_train_set_inputs_supervised))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def model_train(epoch, batch_size, train_set_size):\n",
    "    batch_id = 0\n",
    "    valid_bleu = 0\n",
    "    for start_idx in range(0, train_set_size-batch_size+1, batch_size):\n",
    "        now = int(round(time.time()*1000))\n",
    "        time_stamp = time.strftime(' --->  starting time-[%Y-%m-%d-%H-%M-%S]-',time.localtime(now/1000))\n",
    "        print(time_stamp)\n",
    "        \n",
    "        #supervised learning\n",
    "        if batch_id%2==0:\n",
    "            set_model_grad(split_model, True)\n",
    "            set_model_grad(fusion_model, False)\n",
    "            split_optimizer.zero_grad()#clear  \n",
    "            sup_idx = (batch_id*sup_bsize)%(len(split_train_set_inputs_supervised)-1-sup_bsize)\n",
    "            split_loss, predicts = split_model.forward(torch.LongTensor(split_train_set_inputs_supervised[sup_idx:sup_idx+sup_bsize]), \n",
    "                                         torch.LongTensor(split_train_set_input_lens_supervised[sup_idx:sup_idx+sup_bsize]), \n",
    "                                         labels=torch.LongTensor(split_train_set_labels_supervised[sup_idx:sup_idx+sup_bsize]), \n",
    "                                         is_train=1, teaching_rate=1)\n",
    "            split_loss=torch.mean(split_loss)\n",
    "            split_loss.backward()#retain_graph=True)\n",
    "            split_optimizer.step()\n",
    "\n",
    "        if batch_id%2==1:\n",
    "            set_model_grad(fusion_model, True)\n",
    "            set_model_grad(split_model, False)\n",
    "            fusion_optimizer.zero_grad()#clear\n",
    "            sup_idx = (batch_id*sup_bsize)%(len(split_train_set_inputs_supervised)-1-sup_bsize)\n",
    "            fusion_loss, predicts = fusion_model.forward(torch.LongTensor(fusion_train_set_inputs_supervised[sup_idx:sup_idx+sup_bsize]), \n",
    "                                         torch.LongTensor(fusion_train_set_input_lens_supervised[sup_idx:sup_idx+sup_bsize]), \n",
    "                                         labels=torch.LongTensor(fusion_train_set_labels_supervised[sup_idx:sup_idx+sup_bsize]), \n",
    "                                         is_train=1, teaching_rate=1)\n",
    "            fusion_loss = torch.mean(fusion_loss)\n",
    "            fusion_loss.backward()#retain_graph=True)\n",
    "            fusion_optimizer.step()\n",
    "        \n",
    "        \n",
    "        #unsupervised learning\n",
    "        if batch_id%2==0:\n",
    "            end_idx = start_idx + batch_size\n",
    "            split_optimizer.zero_grad()#clear\n",
    "            total_loss, reconstruct_loss, rm_rewards, lm_rewards=split_model.train_using_reward(inputs=torch.LongTensor(split_train_set_inputs[start_idx:end_idx]), \n",
    "                                   input_lens=torch.LongTensor(split_train_set_input_lens[start_idx:end_idx]), \n",
    "                                   reconstruct_labels=torch.LongTensor(duplicate_reconstruct_labels(fusion_pseudo_train_set_labels[start_idx:end_idx],topk)), \n",
    "                                   reconstruct_model=fusion_model, \n",
    "                                   language_model=language_model, \n",
    "                                   topk=topk, loss_ratio=loss_ratio)\n",
    "            reconstruct_loss = torch.mean(reconstruct_loss)\n",
    "            total_loss.backward()#retain_graph=True)\n",
    "            split_optimizer.step()\n",
    "        \n",
    "        if batch_id%2==1: \n",
    "            end_idx = start_idx + batch_size\n",
    "            fusion_optimizer.zero_grad()#clear\n",
    "            total_loss, reconstruct_loss, rm_rewards, lm_rewards=split_model.train_using_reward(inputs=torch.LongTensor(split_train_set_inputs[start_idx:end_idx]), \n",
    "                                   input_lens=torch.LongTensor(split_train_set_input_lens[start_idx:end_idx]), \n",
    "                                   reconstruct_labels=torch.LongTensor(duplicate_reconstruct_labels(fusion_pseudo_train_set_labels[start_idx:end_idx],topk)), \n",
    "                                   reconstruct_model=fusion_model, \n",
    "                                   language_model=language_model, \n",
    "                                   topk=topk, loss_ratio=loss_ratio)\n",
    "            reconstruct_loss = torch.mean(reconstruct_loss)\n",
    "            reconstruct_loss.backward()#retain_graph=True)\n",
    "            fusion_optimizer.step()\n",
    "    \n",
    "        #update batch_id\n",
    "        batch_id+=1\n",
    "        #timestamp\n",
    "        now = int(round(time.time()*1000))\n",
    "        time_stamp = time.strftime('time-[%Y-%m-%d-%H-%M-%S]-',time.localtime(now/1000))\n",
    "        print(time_stamp)\n",
    "        #\n",
    "        if batch_id%10==1:\n",
    "            split_model.eval()\n",
    "            fusion_model.eval()\n",
    "            \n",
    "            sample_num = 5\n",
    "            rand_idx = random.randint(0, train_set_size-sample_num-1)\n",
    "            \n",
    "            print('--------split model training sampling display--------')\n",
    "            #teaching forcing\n",
    "            loss_, predicts = split_model.forward(torch.LongTensor(split_train_set_inputs[rand_idx:rand_idx+sample_num]), \n",
    "                                             torch.LongTensor(split_train_set_input_lens[rand_idx:rand_idx+sample_num]), \n",
    "                                             labels=torch.LongTensor(split_pseudo_train_set_labels[rand_idx:rand_idx+sample_num]), \n",
    "                                             is_train=1, teaching_rate=1)\n",
    "            del loss_\n",
    "            \n",
    "            predicts = batch_tokens_remove_eos(predicts, vocab)\n",
    "            labels = batch_tokens_remove_eos(split_pseudo_train_set_labels[rand_idx:rand_idx+sample_num], vocab)\n",
    "            \n",
    "            predicts = batch_tokens2words(predicts, vocab)\n",
    "            labels = batch_tokens2words(labels, vocab)\n",
    "            \n",
    "            predicts_sents = batch_words2sentence(predicts)\n",
    "            labels_sents = batch_words2sentence(labels)\n",
    "            \n",
    "            for (predict_sent, label_sent) in zip(predicts_sents, labels_sents):\n",
    "                print(' 1----> ', predict_sent)\n",
    "                print(' 2----> ', label_sent)\n",
    "                print('\\n')\n",
    "            \n",
    "            info_stamp = 'info=[{:s}]-total_loss={:2.9f}-rec_loss={:2.9f}-lm_rewards={:5.4f}-hidden_dim={:n}-input_dim={:n}-epoch={:n}-batch_size={:n}-batch_id=[{:n}-[of]-{:n}]-lr={:1.4f}'.format(\n",
    "                              'split_model', total_loss.data[0], reconstruct_loss.data[0], lm_rewards, \n",
    "                            hidden_dim, input_dim, epoch, batch_size, batch_id, int(train_set_size/batch_size), lr)\n",
    "            print(info_stamp)\n",
    "            \n",
    "            if batch_id%20==1:\n",
    "                rand_idx=random.randint(0, len(split_valid_set_inputs)-batch_size-1-1)\n",
    "                predicts = split_model.forward(torch.LongTensor(split_valid_set_inputs[rand_idx:rand_idx+batch_size]), \n",
    "                                                 torch.LongTensor(split_valid_set_input_lens[rand_idx:rand_idx+batch_size]), \n",
    "                                                 labels=[],#torch.LongTensor(valid_set_labels[rand_idx:rand_idx+batch_size]), \n",
    "                                                 is_train=0, teaching_rate=1)\n",
    "#                 predicts = batch_tokens_remove_eos(predicts, vocab)\n",
    "#                 labels = batch_tokens_remove_eos(split_pseudo_valid_set_labels[rand_idx:rand_idx+batch_size], vocab)\n",
    "                \n",
    "#                 bleu_scores = batch_tokens_bleu(references=labels, candidates=predicts, smooth_epsilon=0.001)\n",
    "                #split version\n",
    "                bleu_scores = batch_tokens_bleu_split_version(references=split_pseudo_valid_set_labels[rand_idx:rand_idx+batch_size], \n",
    "                                                              candidates=predicts, smooth_epsilon=0.001, vocab=vocab)\n",
    "\n",
    "                valid_bleu = 0\n",
    "                for x in bleu_scores:\n",
    "                    valid_bleu+=x\n",
    "                valid_bleu/=len(bleu_scores)\n",
    "                       \n",
    "                info_stamp = 'info=[{:s}]-total_loss={:2.9f}-rec_loss={:2.9f}-lm_rewards={:5.4f}-bleu={:1.4f}-hidden_dim={:n}-input_dim={:n}-epoch={:n}-batch_size={:n}-batch_id=[{:n}-[of]-{:n}]-lr={:1.4f}-loss_ratio={:1.4f}'.format(\n",
    "                              'split_model-semi', total_loss.data[0], reconstruct_loss.data[0], lm_rewards, valid_bleu, \n",
    "                            hidden_dim, input_dim, epoch, batch_size, batch_id, int(train_set_size/batch_size), lr, loss_ratio)\n",
    "                \n",
    "                print(info_stamp, valid_bleu)\n",
    "                \n",
    "                now = int(round(time.time()*1000))\n",
    "                time_stamp = time.strftime('time-[%Y-%m-%d-%H-%M-%S]-',time.localtime(now/1000))\n",
    "                torch.save(split_model.state_dict(), ''.join(['./models_saved/', time_stamp, info_stamp]))\n",
    "                torch.save(fusion_model.state_dict(), ''.join(['./models_saved/', time_stamp, 'info=[fusion_model-semi]']))\n",
    "            split_model.train()\n",
    "            fusion_model.train()\n",
    "            \n",
    "for epoch in range(epochs):\n",
    "    model_train(epoch, batch_size, split_train_set_size)\n",
    "    \n",
    "print('running time: %.2f mins'%((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-30d9529ff51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_num=2\n",
    "topk=20\n",
    "\n",
    "predicts, log_probs=split_model.dec.decode_topk_seqs(split_model.enc, inputs=torch.LongTensor(split_train_set_inputs[0:sample_num]), \n",
    "                             input_lens=torch.LongTensor(split_train_set_input_lens[0:sample_num]), \n",
    "                             topk=topk)\n",
    "\n",
    "predicts = batch_tokens_remove_eos(predicts, vocab)\n",
    "labels = batch_tokens_remove_eos(split_pseudo_train_set_labels[0:sample_num], vocab)\n",
    "\n",
    "predicts = batch_tokens2words(predicts, vocab)\n",
    "labels = batch_tokens2words(labels, vocab)\n",
    "\n",
    "predicts_sents = batch_words2sentence(predicts)\n",
    "labels_sents = batch_words2sentence(labels)\n",
    "\n",
    "for idx, sent in enumerate(predicts_sents):\n",
    "    print(' 1----> ', sent)\n",
    "    if idx%topk==(topk-1):\n",
    "        print(' 2----> ', labels_sents[int(idx/topk)])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copy_thres=1.0\n",
    "# split_loss, predicts = split_model.forward(torch.LongTensor(split_train_set_inputs[0:sample_num]), \n",
    "#                                      torch.LongTensor(split_train_set_input_lens[0:sample_num]), \n",
    "#                                      labels=torch.LongTensor(split_pseudo_train_set_labels[0:sample_num]), \n",
    "#                                      is_train=1, teaching_rate=1)\n",
    "\n",
    "# predicts = batch_tokens_remove_eos(predicts, vocab)\n",
    "# labels = batch_tokens_remove_eos(split_pseudo_train_set_labels[0:sample_num], vocab)\n",
    "\n",
    "# predicts = batch_tokens2words(predicts, vocab)\n",
    "# labels = batch_tokens2words(labels, vocab)\n",
    "\n",
    "# predicts_sents = batch_words2sentence(predicts)\n",
    "# labels_sents = batch_words2sentence(labels)\n",
    "\n",
    "# for (predict_sent, label_sent) in zip(predicts_sents, labels_sents):\n",
    "#     print(' 1----> ', predict_sent)\n",
    "#     print(' 2----> ', label_sent)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
