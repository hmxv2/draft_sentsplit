{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import over\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import time\n",
    "\n",
    "from Vocab import Vocab\n",
    "from LanguageModel import LanguageModel\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print('import over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n",
      "torch.Size([2, 4, 6])\n",
      "\n",
      " 0  0  0  1  1  0\n",
      " 0  0  1  1  2  0\n",
      "[torch.LongTensor of size 2x6]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  1  1  1  0  0  1\n",
      "  0  0  0  1  1  0\n",
      "  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1  1  0  0  0  1\n",
      "  0  0  1  1  0  0\n",
      "  0  0  0  0  1  0\n",
      "  0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 2x4x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert index to one-hot\n",
    "#support batch\n",
    "batch_size=2\n",
    "vocab_size = 4\n",
    "sents_len=6\n",
    "\n",
    "a=torch.LongTensor(batch_size, sents_len)%(vocab_size-1)\n",
    "b=torch.unsqueeze(a, dim=2)\n",
    "\n",
    "one_hot = torch.FloatTensor(batch_size, sents_len, vocab_size).zero_()\n",
    "one_hot.scatter_(2, b, 1)\n",
    "one_hot = one_hot.transpose(1,2)\n",
    "\n",
    "print(a.size())\n",
    "print(one_hot.size())\n",
    "\n",
    "print(a)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "a=Variable(torch.rand(2, 5))\n",
    "labels=torch.LongTensor([2,3])\n",
    "nll_loss = nn.NLLLoss()\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = nll_loss(log_softmax(a), Variable(labels))\n",
    "print(loss)\n",
    "\n",
    "loss = nll_loss(torch.log(softmax(a)), Variable(labels))\n",
    "print(loss)\n",
    "\n",
    "loss = cross_entropy(a, Variable(labels))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#large matrix in gpu\n",
    "#43800*50, float tensor\n",
    "vocab_size = 43800\n",
    "sents_len = 50\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "for epoch in range(200):\n",
    "    s=0\n",
    "    enc_inputs = torch.LongTensor(batch_size, sents_len)%(vocab_size-1)\n",
    "    enc_inputs = enc_inputs.unsqueeze(dim=2)\n",
    "    one_hot = torch.FloatTensor(batch_size, sents_len, vocab_size).zero_()\n",
    "    one_hot.scatter_(2, enc_inputs, 1)\n",
    "    one_hot = one_hot.transpose(1,2)\n",
    "    a = Variable(one_hot, requires_grad = 0).cuda()\n",
    "\n",
    "    for ii in range(1):\n",
    "        w=Variable(torch.rand(batch_size, sents_len), requires_grad=1).cuda()\n",
    "        w=softmax(w).unsqueeze(dim=2)\n",
    "        prob_copy = torch.bmm(a,w)\n",
    "        s+=prob_copy\n",
    "    \n",
    "# for ii in range(61):\n",
    "#     prob_copy=Variable(torch.rand(batch_size, vocab_size), requires_grad=1).cuda()\n",
    "#     s+=prob_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7710406610294067"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some bleu calculating\n",
    "predicts='matthew justice is an english film and television producer ( -- death <low_freq> death ) can <split> he can a lead of the \\'\\' \\'s formal be subject can be a lead - in to the \\'\\' subject \\'s real , formal , or extended name '' .'\n",
    "labels='matthew justice is an english film and television producer ( born 1st november 1965 ) . <split> matthew is a governor of the <low_freq> , has produced he can be a lead - in to the \\'\\' subject \\'s real , formal , or extended name '' .'\n",
    "predicts='matthew joshua estrada ( born october 20 , 1988 ) is an american football safety who is currently a free of the toronto argonauts of <split> he the , , he , <low_freq> was a a toronto argonauts of the canadian football league .'\n",
    "labels='matthew joshua estrada ( born october 20 , 1988 ) is an american football safety who is currently a member of the toronto argonauts . <split> on march 29 , 2012 matt estrada signed with the toronto argonauts of the canadian football league .'\n",
    "predicts='matthew k. miller ( born 1949 in cincinnati , ohio ) is an american voice . and ) and kermit host . actor producer . <split> he is also known as kermit miller and kermit <low_freq> .'\n",
    "labels='matthew k. miller ( born 1949 in cincinnati , ohio ) is an american stage , film , and television actor and voice artist . <split> he is also known as kermit miller and kermit <low_freq> .'\n",
    "predicts='matthew <low_freq> or <low_freq> ( greek : <low_freq> <low_freq> <low_freq> , '' <low_freq> <low_freq> <low_freq> , , c. greek 1325 - <low_freq> ) <low_freq> ) was <split> c. was byzantine emperor from <low_freq> to <low_freq> .'\n",
    "labels='matthew <low_freq> or <low_freq> ( greek : <low_freq> <low_freq> <low_freq> , '' <low_freq> <low_freq> <low_freq> '' ) ( c. 1325 -- <low_freq> or <low_freq> ) . <split> he was byzantine emperor from <low_freq> to <low_freq> .'\n",
    "predicts='in fact , west virginia is the site of the worst coal mining disaster to date . <split> the the <low_freq> mining disaster of <low_freq> , west virginia 6 december 1907 .'\n",
    "labels='in fact , west virginia is the site of the worst coal mining disaster to date . <split> with the <low_freq> mine disaster of <low_freq> , west virginia 6 december 1907 .'\n",
    "predicts='in fact , a new term , <split> <low_freq> has has been coined to describe an unhealthy obsession with eating health food .'\n",
    "labels='in fact , a new term . <split> <low_freq> , has been coined to describe an unhealthy obsession with eating health food .'\n",
    "predicts='in fact , templeton rye brand whiskey is distilled and aged in <low_freq> indiana by <low_freq> of indiana , . <low_freq> . . an . flavoring <split> the is combined with an '' alcohol flavoring agent '' from clarendon flavor engineers , and finally bottled at an iowa facility .'\n",
    "labels='in fact , templeton rye brand whiskey is distilled and aged in <low_freq> indiana by <low_freq> of indiana utilizing a recipe shared with other brands . <split> it is combined with an '' alcohol flavoring agent '' from clarendon flavor engineers , and finally bottled at an iowa facility .'\n",
    "\n",
    "a=predicts.split(' ')\n",
    "b=labels.split(' ')\n",
    "sentence_bleu([b], a, smoothing_function = SmoothingFunction(epsilon=0.001).method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  0.7708  0.2877  0.6474  0.5719  0.6309  0.3723\n",
      "  0.4128  0.1720  0.8442  0.1937  0.7954  0.4892\n",
      "  0.8378  0.3698  0.2211  0.8136  0.9741  0.6237\n",
      "  0.7293  0.5401  0.0281  0.4767  0.2357  0.8523\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.2411  0.5577  0.5717  0.9420  0.7847  0.2945\n",
      "  0.7278  0.0168  0.4236  0.9483  0.1195  0.4750\n",
      "  0.2507  0.6052  0.5003  0.3944  0.1121  0.3206\n",
      "  0.7008  0.3773  0.9835  0.2848  0.2439  0.0223\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.5443  0.2949  0.2276  0.2788  0.8578  0.7674\n",
      "  0.5496  0.7211  0.6500  0.1105  0.8284  0.6783\n",
      "  0.3357  0.5301  0.0776  0.6669  0.9750  0.4637\n",
      "  0.7342  0.3033  0.0040  0.0271  0.5337  0.5884\n",
      "[torch.FloatTensor of size 3x4x6]\n",
      "\n",
      "\n",
      " 0  2  3  1\n",
      " 1  5  3  2\n",
      " 3  4  2  1\n",
      "[torch.LongTensor of size 3x4]\n",
      "\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "\n",
      "  0   6  12  18\n",
      "  0   6  12  18\n",
      "  0   6  12  18\n",
      "[torch.LongTensor of size 3x4]\n",
      "\n",
      "\n",
      "  0   0   0   0\n",
      " 24  24  24  24\n",
      " 48  48  48  48\n",
      "[torch.LongTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.7708  0.8442  0.8136  0.5401\n",
      " 0.5577  0.4750  0.3944  0.9835\n",
      " 0.2788  0.8284  0.0776  0.3033\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tensor as index\n",
    "batch_size=3\n",
    "sents_len=4\n",
    "vocab_size=6\n",
    "logits=torch.rand(3,4,6)\n",
    "labels=torch.LongTensor([[0,2,3,1],[1,5,3,2],[3,4,2,1]])\n",
    "\n",
    "print(logits)\n",
    "print(labels)\n",
    "\n",
    "# print(logits)\n",
    "pos_bias=torch.LongTensor([i*vocab_size for i in range(sents_len)]).view(1,-1)\n",
    "pos_bias = pos_bias.expand(batch_size, pos_bias.size(1))\n",
    "print(pos_bias.size())\n",
    "\n",
    "batch_bias = torch.LongTensor([i*vocab_size*sents_len for i in range(batch_size)]).view(-1,1)\n",
    "batch_bias = batch_bias.expand(batch_bias.size(0), sents_len)\n",
    "print(batch_bias.size())\n",
    "\n",
    "indices=labels+pos_bias+batch_bias\n",
    "indices = indices.view(-1)\n",
    "logits=logits.view(-1)\n",
    "results=logits[indices]\n",
    "results=results.view(batch_size, sents_len)\n",
    "\n",
    "print(pos_bias)\n",
    "print(batch_bias)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
