{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import over\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from Vocab import Vocab\n",
    "from LanguageModel import LanguageModel\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print('import over')\n",
    "\n",
    "copy_thres=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_words2sentence(words_list):\n",
    "    return [' '.join(words) for words in words_list]\n",
    "def batch_tokens2words(tokens_list, vocab):\n",
    "    ##    para: tokens_list is list[list] type\n",
    "    ##    return: words_list corresponding to tokens\n",
    "    return [[vocab.token2word[token] for token in tokens] for tokens in tokens_list]\n",
    "\n",
    "def batch_tokens_remove_eos(tokens_list, vocab):\n",
    "    ##    para: tokens_list is list[list] type\n",
    "    ##    return pure tokens_list removed eos symbol\n",
    "    result=[]\n",
    "    for tokens in tokens_list:\n",
    "        tokens_filtered=[]\n",
    "        for token in tokens:\n",
    "            if token == vocab.word2token['<eos>']:\n",
    "#                 tokens_filtered.append(token)\n",
    "                break\n",
    "            else:\n",
    "                tokens_filtered.append(token)\n",
    "        result.append(tokens_filtered)\n",
    "    return result\n",
    "\n",
    "def batch_tokens_bleu(references, candidates, smooth_epsilon=0.001):\n",
    "    ##    para: references and candidates are list[list] type\n",
    "    ##    return: list of BLEU for every sample\n",
    "    ##\n",
    "    bleu_scores=[]\n",
    "    for ref, candidate in zip(references, candidates):\n",
    "        if min(len(ref), len(candidate))<4:\n",
    "            bleu_scores.append(0)\n",
    "        else:\n",
    "            bleu_scores.append(sentence_bleu([ref], candidate, smoothing_function = SmoothingFunction(epsilon=smooth_epsilon).method1))\n",
    "    return bleu_scores\n",
    "\n",
    "with open('data_set/vocab.pk', 'rb') as f:\n",
    "    vocab=pickle.load(f)\n",
    "\n",
    "    \n",
    "def seqs_split(seqs, vocab):\n",
    "    seqs = batch_tokens_remove_eos(seqs, vocab)\n",
    "    simple_sent1s=[]\n",
    "    simple_sent2s=[]\n",
    "    for seq in seqs:\n",
    "        simple_sent1=[]\n",
    "        simple_sent2=[]\n",
    "        sent=simple_sent1\n",
    "        for token in seq:\n",
    "            if token==vocab.word2token['<split>']:\n",
    "                sent=simple_sent2\n",
    "            else:\n",
    "                sent.append(token)\n",
    "        simple_sent1s.append(simple_sent1)\n",
    "        simple_sent2s.append(simple_sent2)\n",
    "        \n",
    "    return simple_sent1s, simple_sent2s\n",
    "\n",
    "def simple_sents_concat(simple_sent1s, simple_sent2s, vocab, max_length):\n",
    "    simple_sent_lens=[]\n",
    "    simple_sents=simple_sent1s\n",
    "    for i, sent in enumerate(simple_sent2s):\n",
    "        simple_sents[i].append(vocab.word2token['<split>'])\n",
    "        for token in sent:\n",
    "            simple_sents[i].append(token)\n",
    "\n",
    "        #if there is no <split> in simple_sent1s and simple_sent2s, then the length of sents_concat will be longer than max_length\n",
    "        if len(simple_sents[i])>max_length:\n",
    "            simple_sents[i] = simple_sents[i][:max_length]\n",
    "            \n",
    "        simple_sent_lens.append(len(simple_sents[i]))\n",
    "            \n",
    "        while(len(simple_sents[i])<max_length):\n",
    "            simple_sents[i].append(vocab.word2token['<padding>'])\n",
    "            \n",
    "    return simple_sents, simple_sent_lens\n",
    "\n",
    "\n",
    "def get_lm_inputs_and_labels(sents, vocab, max_length):\n",
    "    lm_inputs=copy.deepcopy(sents)\n",
    "    lm_labels=copy.deepcopy(sents)\n",
    "    lm_input_lens=[]\n",
    "    \n",
    "    for sent in lm_inputs:\n",
    "        if len(sent)>=max_length:\n",
    "            sent=sent[:max_length-1]\n",
    "        sent.insert(0, vocab.word2token['<sos>'])\n",
    "        lm_input_lens.append(len(sent))\n",
    "        while(len(sent)<max_length):\n",
    "            sent.append(vocab.word2token['<padding>'])\n",
    "\n",
    "    for sent in lm_labels:\n",
    "        if len(sent)>=max_length:\n",
    "            sent = sent[:max_length-1]\n",
    "        sent.append(vocab.word2token['<eos>'])\n",
    "        while(len(sent)<max_length):\n",
    "            sent.append(vocab.word2token['<padding>'])\n",
    "        \n",
    "    return lm_inputs, lm_input_lens, lm_labels\n",
    "\n",
    "\n",
    "def duplicate_reconstruct_labels(sents, topk):\n",
    "    return [x for x in sents for ii in range(topk)]\n",
    "\n",
    "\n",
    "\n",
    "def batch_tokens_bleu_split_version(references, candidates, vocab, smooth_epsilon=0.001):\n",
    "    # needn't remove '<sos>' token before calling this function, which is different from the 'batch_token_bleu()' version\n",
    "    #\n",
    "    ref1, ref2 = seqs_split(references, vocab)\n",
    "    cand1, cand2 = seqs_split(candidates, vocab)\n",
    "    bleu_simple_sent1s = batch_tokens_bleu(ref1, cand1)\n",
    "    bleu_simple_sent2s = batch_tokens_bleu(ref2, cand2)\n",
    "#     print(bleu_simple_sent1s)\n",
    "#     print(bleu_simple_sent2s)\n",
    "    bleu=[]\n",
    "    for idx in range(len(bleu_simple_sent1s)):\n",
    "        bleu.append((bleu_simple_sent1s[idx]+bleu_simple_sent2s[idx])/2)\n",
    "        \n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 9, 90], [], [8], [8, 9, 90], [8, 9, 90]]\n",
      "[[3], [8, 9, 90, 3], [], [3], []]\n",
      "[[0, 8, 9, 90, 1, 1], [0, 1, 1, 1, 1, 1], [0, 8, 1, 1, 1, 1], [0, 8, 9, 90, 1, 1], [0, 8, 9, 90, 1, 1]]\n",
      "[4, 1, 2, 4, 4]\n",
      "[[8, 9, 90, 2, 1, 1], [2, 1, 1, 1, 1, 1], [8, 2, 1, 1, 1, 1], [8, 9, 90, 2, 1, 1], [8, 9, 90, 2, 1, 1]]\n",
      "[[0, 3, 1, 1, 1, 1], [0, 8, 9, 90, 3, 1], [0, 1, 1, 1, 1, 1], [0, 3, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1]]\n",
      "[2, 5, 1, 2, 1]\n",
      "[[3, 2, 1, 1, 1, 1], [8, 9, 90, 3, 2, 1], [2, 1, 1, 1, 1, 1], [3, 2, 1, 1, 1, 1], [2, 1, 1, 1, 1, 1]]\n",
      "[[8, 9, 90], [5, 8, 9], [8, 5, 1], [8, 9, 90], [8, 9, 90]]\n",
      "[3, 3, 2, 3, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.021744100219015735]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs=[[8,9,90,5,3,2,1], [5,8,9,90,5,3,2,1], [8,2,9,40,5,3,2,2,1], [8,9,90,5,3,2,1], [8,9,90]]\n",
    "a,b = seqs_split(seqs, vocab)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "lm_in, lm_in_lens, lm_labels=get_lm_inputs_and_labels(a,vocab, max_length=6)\n",
    "print(lm_in)\n",
    "print(lm_in_lens)\n",
    "print(lm_labels)\n",
    "lm_in, lm_in_lens, lm_labels=get_lm_inputs_and_labels(b,vocab, max_length=6)\n",
    "print(lm_in)\n",
    "print(lm_in_lens)\n",
    "print(lm_labels)\n",
    "\n",
    "c,d=simple_sents_concat(a,b,vocab, 3)\n",
    "print(c)\n",
    "print(d)\n",
    "\n",
    "\n",
    "batch_tokens_bleu([[1,2,3,4,5,6]], [[2,3,1,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_set/fusion_data_set/train_pseudo_simple_sents.pk', 'rb') as f:\n",
    "    fusion_pseudo_train_set_inputs = pickle.load(f)\n",
    "with open('./data_set/fusion_data_set/train_pseudo_simple_sent_lens.pk', 'rb') as f:\n",
    "    fusion_pseudo_train_set_input_lens = pickle.load(f)\n",
    "with open('./data_set/fusion_data_set/train_pseudo_labels.pk', 'rb') as f:\n",
    "    fusion_pseudo_train_set_labels = pickle.load(f)\n",
    "    \n",
    "with open('./data_set/fusion_data_set/validation_pseudo_simple_sents.pk', 'rb') as f:\n",
    "    fusion_pseudo_valid_set_inputs = pickle.load(f)\n",
    "with open('./data_set/fusion_data_set/validation_pseudo_simple_sent_lens.pk', 'rb') as f:\n",
    "    fusion_pseudo_valid_set_input_lens = pickle.load(f)\n",
    "with open('./data_set/fusion_data_set/validation_pseudo_labels.pk', 'rb') as f:\n",
    "    fusion_pseudo_valid_set_labels = pickle.load(f)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "with open('./data_set/split_data_set/train_complex_sents.pk', 'rb') as f:\n",
    "    split_train_set_inputs = pickle.load(f)\n",
    "with open('./data_set/split_data_set/train_complex_sent_lens.pk', 'rb') as f:\n",
    "    split_train_set_input_lens = pickle.load(f)\n",
    "with open('./data_set/split_data_set/train_pseudo_labels.pk', 'rb') as f:\n",
    "    split_pseudo_train_set_labels = pickle.load(f)\n",
    "    \n",
    "with open('./data_set/split_data_set/validation_complex_sents.pk', 'rb') as f:\n",
    "    split_valid_set_inputs = pickle.load(f)\n",
    "with open('./data_set/split_data_set/validation_complex_sent_lens.pk', 'rb') as f:\n",
    "    split_valid_set_input_lens = pickle.load(f)\n",
    "with open('./data_set/split_data_set/validation_labels.pk', 'rb') as f:\n",
    "    split_pseudo_valid_set_labels = pickle.load(f)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# #try true labels\n",
    "# with open('./data_set/fusion_data_set/train_simple_sents.pk', 'rb') as f:\n",
    "#     fusion_pseudo_train_set_inputs = pickle.load(f)\n",
    "# with open('./data_set/fusion_data_set/train_simple_sent_lens.pk', 'rb') as f:\n",
    "#     fusion_pseudo_train_set_input_lens = pickle.load(f)\n",
    "# with open('./data_set/fusion_data_set/train_labels.pk', 'rb') as f:\n",
    "#     fusion_pseudo_train_set_labels = pickle.load(f)\n",
    "    \n",
    "# with open('./data_set/fusion_data_set/validation_simple_sents.pk', 'rb') as f:\n",
    "#     fusion_pseudo_valid_set_inputs = pickle.load(f)\n",
    "# with open('./data_set/fusion_data_set/validation_simple_sent_lens.pk', 'rb') as f:\n",
    "#     fusion_pseudo_valid_set_input_lens = pickle.load(f)\n",
    "# with open('./data_set/fusion_data_set/validation_labels.pk', 'rb') as f:\n",
    "#     fusion_pseudo_valid_set_labels = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "# with open('./data_set/split_data_set/train_complex_sents.pk', 'rb') as f:\n",
    "#     split_train_set_inputs = pickle.load(f)\n",
    "# with open('./data_set/split_data_set/train_complex_sent_lens.pk', 'rb') as f:\n",
    "#     split_train_set_input_lens = pickle.load(f)\n",
    "# with open('./data_set/split_data_set/train_labels.pk', 'rb') as f:\n",
    "#     split_pseudo_train_set_labels = pickle.load(f)\n",
    "    \n",
    "# with open('./data_set/split_data_set/validation_complex_sents.pk', 'rb') as f:\n",
    "#     split_valid_set_inputs = pickle.load(f)\n",
    "# with open('./data_set/split_data_set/validation_complex_sent_lens.pk', 'rb') as f:\n",
    "#     split_valid_set_input_lens = pickle.load(f)\n",
    "# with open('./data_set/split_data_set/validation_labels.pk', 'rb') as f:\n",
    "#     split_pseudo_valid_set_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num=100000\n",
    "# train_set_inputs_10w = train_set_inputs[:num]\n",
    "# train_set_input_lens_10w = train_set_input_lens[:num]\n",
    "# train_set_labels_10w = train_set_labels[:num]\n",
    "\n",
    "# valid_set_inputs_10w = valid_set_inputs[:num]\n",
    "# valid_set_input_lens_10w = valid_set_input_lens[:num]\n",
    "# valid_set_labels_10w = valid_set_labels[:num]\n",
    "\n",
    "\n",
    "# with open('./small_data_set/train_set_inputs_10w.pk', 'bw') as f:\n",
    "#     pickle.dump(train_set_inputs_10w,f)\n",
    "# with open('./small_data_set/train_set_input_lens_10w.pk', 'bw') as f:\n",
    "#     pickle.dump(train_set_input_lens_10w ,f)\n",
    "# with open('./small_data_set/train_set_labels_10w.pk', 'bw') as f:\n",
    "#     pickle.dump(train_set_labels_10w ,f)\n",
    "    \n",
    "# with open('./small_data_set/valid_set_inputs_10w.pk', 'bw') as f:\n",
    "#     pickle.dump(valid_set_inputs_10w ,f)\n",
    "# with open('./small_data_set/valid_set_input_lens_10w.pk', 'bw') as f:\n",
    "#     pickle.dump(valid_set_input_lens_10w ,f)\n",
    "# with open('./small_data_set/valid_set_labels_10w.pk', 'bw') as f:\n",
    "#     pickle.dump(valid_set_labels_10w ,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989944 989944 989944\n",
      "989944 989944 989944\n"
     ]
    }
   ],
   "source": [
    "print(len(split_train_set_inputs), len(split_train_set_input_lens), len(split_pseudo_train_set_labels))\n",
    "print(len(fusion_pseudo_train_set_inputs), len(fusion_pseudo_train_set_input_lens), len(fusion_pseudo_train_set_labels))\n",
    "# for sent_len in valid_set_input_lens:\n",
    "#     if sent_len<=2:\n",
    "#         print('why')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, use_cuda, hidden_dim, input_dim, vocab):#, pre_train_weight, is_fix_word_vector = 1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.input_dim=input_dim\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.lstm=torch.nn.LSTM(input_size=self.input_dim, \n",
    "                                hidden_size= self.hidden_dim, \n",
    "                                bidirectional=True,\n",
    "                                batch_first=True\n",
    "                               )\n",
    "        \n",
    "        #embedding\n",
    "        self.embed=nn.Embedding(len(self.vocab.word2token), input_dim)\n",
    "        #loading pre trained word embedding\n",
    "        with open('data_set/pre_trained_token_embedding.pk', 'rb') as f:\n",
    "            pre_train_word_embedding = pickle.load(f)\n",
    "            \n",
    "        self.embed.weight.data.copy_(torch.FloatTensor(pre_train_word_embedding))\n",
    "#         self.embed.weight.requires_grad = False\n",
    "        \n",
    "    def order(self, inputs, inputs_len):    #inputs: tensor, inputs_len: 1D tensor\n",
    "        inputs_len, sort_ids = torch.sort(inputs_len, dim=0, descending=True)\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            inputs = inputs.index_select(0, Variable(sort_ids).cuda())\n",
    "        else:\n",
    "            inputs = inputs.index_select(0, Variable(sort_ids))\n",
    "        \n",
    "        _, true_order_ids = torch.sort(sort_ids, dim=0, descending=False)\n",
    "        \n",
    "        return inputs, inputs_len, true_order_ids\n",
    "    #\n",
    "    def forward(self, inputs, inputs_len):\n",
    "        inputs = Variable(inputs)\n",
    "        if self.use_cuda:\n",
    "            inputs=inputs.cuda()\n",
    "            \n",
    "        inputs, sort_len, true_order_ids = self.order(inputs, inputs_len)\n",
    "\n",
    "        in_vecs=self.embed(inputs)\n",
    "\n",
    "        packed = rnn_utils.pack_padded_sequence(input=in_vecs, lengths=list(sort_len), batch_first =True)\n",
    "        \n",
    "        outputs, (hn,cn) = self.lstm(packed)\n",
    "        outputs, sent_lens = rnn_utils.pad_packed_sequence(outputs)\n",
    "        \n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        outputs = outputs.transpose(0,1)  #transpose is necessary\n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        \n",
    "        #warnning: outputs, hn and cn have been sorted by sentences length so the order is wrong, now to sort them\n",
    "        if self.use_cuda:\n",
    "            outputs = outputs.index_select(0, Variable(true_order_ids).cuda())\n",
    "        else:\n",
    "            outputs = outputs.index_select(0, Variable(true_order_ids))\n",
    "        \n",
    "        hn = torch.cat((hn[0], hn[1]), dim=1)\n",
    "        cn = torch.cat((cn[0], cn[1]), dim=1)\n",
    "        #print('hn size and cn size: ', hn.size(), cn.size())\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            hn = hn.index_select(0, Variable(true_order_ids).cuda())\n",
    "            cn = cn.index_select(0, Variable(true_order_ids).cuda())\n",
    "        else:\n",
    "            hn = hn.index_select(0, Variable(true_order_ids))\n",
    "            cn = cn.index_select(0, Variable(true_order_ids))\n",
    "            \n",
    "        return outputs, (hn,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inflate(tensor, times, dim):\n",
    "    \"\"\"\n",
    "    Examples::\n",
    "        >> a = torch.LongTensor([[1, 2], [3, 4]])\n",
    "        >> a\n",
    "        1   2\n",
    "        3   4\n",
    "        [torch.LongTensor of size 2x2]\n",
    "        >> b = ._inflate(a, 2, dim=1)\n",
    "        >> b\n",
    "        1   2   1   2\n",
    "        3   4   3   4\n",
    "        [torch.LongTensor of size 2x4]\n",
    "    \"\"\"\n",
    "    repeat_dims = [1] * tensor.dim()\n",
    "    repeat_dims[dim] = times\n",
    "    return tensor.repeat(*repeat_dims)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, use_cuda, encoder, hidden_dim, max_length=25):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.input_dim = encoder.input_dim\n",
    "        self.max_length = max_length\n",
    "        self.vocab = encoder.vocab\n",
    "        self.weight = [1]*len(self.vocab.word2token)\n",
    "        self.weight[self.vocab.word2token['<padding>']]=0\n",
    "        #self.weight[self.vocab.word2token['<eos>']]=1.01\n",
    "        #self.weight[self.vocab.word2token['<split>']]=1.01\n",
    "        \n",
    "        self.hidden_size = self.hidden_dim\n",
    "        self.V = len(self.vocab.word2token)\n",
    "        self.SOS = self.vocab.word2token['<sos>']\n",
    "        self.EOS = self.vocab.word2token['<eos>']\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.lstmcell = torch.nn.LSTMCell(input_size=self.input_dim, hidden_size=self.hidden_dim*2, bias=True)\n",
    "        \n",
    "        #embedding\n",
    "        self.embed=encoder.embed# reference share\n",
    "        #fcnn: projection for crossentroy loss\n",
    "        self.fcnn = nn.Linear(in_features = self.hidden_dim*2, out_features = len(self.vocab.word2token))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.cost_func = nn.CrossEntropyLoss(weight=torch.Tensor(self.weight), reduce=False)\n",
    "        self.nll_loss = nn.NLLLoss(weight=torch.Tensor(self.weight), reduce=False)\n",
    "\n",
    "        print('init lookup embedding matrix size: ', self.embed.weight.data.size())\n",
    "        \n",
    "        #copy\n",
    "        out_features_dim=self.hidden_dim\n",
    "        self.attent_wh = nn.Linear(in_features = self.hidden_dim*2, out_features = out_features_dim, bias = 0)\n",
    "        self.attent_ws = nn.Linear(in_features = self.hidden_dim*2, out_features = out_features_dim, bias = 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.attent_vt = nn.Linear(in_features = out_features_dim, out_features = 1, bias=0)\n",
    "        \n",
    "        self.prob_wh = nn.Linear(in_features = self.hidden_dim*2, out_features = 1, bias=0)\n",
    "        self.prob_ws = nn.Linear(in_features = self.hidden_dim*2, out_features = 1, bias=0)\n",
    "        self.prob_wx = nn.Linear(in_features = self.input_dim, out_features = 1, bias=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def copy_mechanism(self, enc_outputs, this_timestep_input, dec_state, inputs_one_hot):\n",
    "        batch_size = enc_outputs.size(dim = 0)\n",
    "        \n",
    "        wh = self.attent_wh(enc_outputs)\n",
    "        ws = self.attent_ws(dec_state).unsqueeze(dim=1)\n",
    "#         print('wh, ws size: ', wh.size(), ws.size())\n",
    "        ws = ws.expand(ws.size(0), wh.size(1), ws.size(2))\n",
    "#         print('ws size: ', ws.size())\n",
    "        weight = self.attent_vt(self.tanh(wh+ws))\n",
    "#         print('weight size: ', weight.size())\n",
    "        weight = self.softmax(weight.squeeze(dim=2))\n",
    "#         print('weight size: ', weight.size())\n",
    "        context_v = torch.bmm(weight.unsqueeze(dim=1), enc_outputs)\n",
    "#         print('context_v size: ', context_v.size())\n",
    "        context_v = context_v.squeeze(dim=1)\n",
    "        \n",
    "        p_wh = self.prob_wh(context_v)\n",
    "        p_ws = self.prob_ws(dec_state)\n",
    "        p_wx = self.prob_wx(this_timestep_input)\n",
    "        if_copy = self.sigmoid(p_wh+p_ws+p_wx)\n",
    "#         if_copy = 0.3*if_copy\n",
    "#         if_copy = self._tocuda(Variable(torch.ones(batch_size, 1), requires_grad=0))\n",
    "#         print('if_copy size: ', if_copy.size())\n",
    "        \n",
    "        prob_copy = torch.bmm(inputs_one_hot, weight.unsqueeze(dim=2))\n",
    "        prob_copy = prob_copy.squeeze(dim=2)\n",
    "#         prob_copy = self._tocuda(Variable(torch.rand(batch_size, len(self.vocab.word2token)), requires_grad=0))\n",
    "#         prob_copy = self.softmax(prob_copy)\n",
    "\n",
    "#         print('prob_copy size: ', prob_copy.size())\n",
    "#         print(torch.sum(prob_copy, dim=1))\n",
    "#         print(torch.mean(if_copy))\n",
    "        \n",
    "#         if random.random()<0.005:\n",
    "#             print('if_copy mean: ', torch.mean(if_copy))\n",
    "#             _, max_ids = torch.max(prob_copy, dim=1)\n",
    "#             print(self.vocab.token2word[max_ids.data[0]], self.vocab.token2word[max_ids.data[1]], self.vocab.token2word[max_ids.data[2]])\n",
    "            \n",
    "            \n",
    "        return if_copy, prob_copy\n",
    "\n",
    "    def forward(self, enc_outputs, sent_lens, h0_and_c0, labels, inputs, teaching_rate=0.6, is_train=1):\n",
    "        labels = Variable(labels)\n",
    "        if self.use_cuda:\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        all_loss = 0\n",
    "        predicts = []\n",
    "        max_probs=[]\n",
    "        batch_size = enc_outputs.size(dim = 0)\n",
    "        final_hidden_states = h0_and_c0[0]\n",
    "#         print('enc_outputs size:', enc_outputs.size())\n",
    "\n",
    "        sents_len = enc_outputs.size(1)\n",
    "        inputs = inputs[:,:sents_len].unsqueeze(dim=2)\n",
    "        one_hot = torch.FloatTensor(batch_size, sents_len, len(self.vocab.word2token)).zero_()\n",
    "        one_hot.scatter_(2, inputs, 1)\n",
    "        one_hot = one_hot.transpose(1,2)\n",
    "        one_hot = self._tocuda(Variable(one_hot, requires_grad = 0))\n",
    "#         print('one_hot size: ', one_hot.size())\n",
    "        \n",
    "        for ii in range(self.max_length):\n",
    "            if ii==0:\n",
    "                zero_timestep_input = Variable(torch.LongTensor([self.vocab.word2token['<sos>']]*batch_size))\n",
    "                if self.use_cuda:\n",
    "                    zero_timestep_input = zero_timestep_input.cuda()\n",
    "                    \n",
    "                zero_timestep_input = self.embed(zero_timestep_input)#size: batch_size * self.input_dim\n",
    "\n",
    "                last_timestep_hidden_state,cx = self.lstmcell(zero_timestep_input, h0_and_c0)\n",
    "                #print('last_timestep_hidden_state: ', last_timestep_hidden_state.size(), cx.size())\n",
    "                \n",
    "                \n",
    "                logits = self.fcnn(last_timestep_hidden_state)\n",
    "                \n",
    "                #copy or not\n",
    "                copy_control=random.random()\n",
    "                if copy_control<copy_thres:\n",
    "                    if_copy, prob_copy = self.copy_mechanism(enc_outputs=enc_outputs, this_timestep_input=zero_timestep_input, \n",
    "                                                            dec_state = last_timestep_hidden_state, inputs_one_hot = one_hot)\n",
    "                    score = (1-if_copy)*self.softmax(logits)+if_copy*prob_copy\n",
    "                    score = torch.clamp(score, min=10**(-30), max=1)\n",
    "                \n",
    "                #for saving time: no training, no loss calculating\n",
    "                if is_train:\n",
    "                    if copy_control<copy_thres:\n",
    "                        loss = self.nll_loss(torch.log(score), labels[:,0])\n",
    "                    else:\n",
    "                        loss = self.cost_func(logits, labels[:,0])\n",
    "                    all_loss+=loss\n",
    "                \n",
    "                #get predicts\n",
    "                if copy_control<copy_thres:\n",
    "                    _, max_idxs = torch.max(score, dim=1)\n",
    "                else:\n",
    "                    _, max_idxs = torch.max(logits, dim=1)\n",
    "                predicts.append(torch.unsqueeze(max_idxs, dim=0))\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if is_train:\n",
    "                    rand = random.random()\n",
    "                    if rand<teaching_rate:\n",
    "                        this_timestep_input = self.embed(labels[:,ii-1])#label teaching, lookup embedding\n",
    "                    else:\n",
    "                        this_timestep_input = self.embed(max_idxs)#last_timestep output, and then look up word embedding\n",
    "                else:\n",
    "                    this_timestep_input = self.embed(max_idxs)#last_timestep output, and then look up word embedding\n",
    "                    \n",
    "                last_timestep_hidden_state ,cx = self.lstmcell(this_timestep_input, (last_timestep_hidden_state,cx))\n",
    "                \n",
    "                \n",
    "                logits = self.fcnn(last_timestep_hidden_state)\n",
    "                \n",
    "                #copy or not\n",
    "                copy_control=random.random()\n",
    "                if copy_control<copy_thres:\n",
    "                    if_copy, prob_copy = self.copy_mechanism(enc_outputs=enc_outputs, this_timestep_input=this_timestep_input, \n",
    "                                                            dec_state = last_timestep_hidden_state, inputs_one_hot = one_hot)\n",
    "                    score = (1-if_copy)*self.softmax(logits)+if_copy*prob_copy\n",
    "                    score = torch.clamp(score, min=10**(-30), max=1)\n",
    "                \n",
    "                #for saving time: no training, no loss calculating\n",
    "                if is_train:\n",
    "                    if copy_control<copy_thres:\n",
    "                        loss = self.nll_loss(torch.log(score), labels[:,ii])\n",
    "                    else:\n",
    "                        loss = self.cost_func(logits, labels[:,ii])\n",
    "                    all_loss+=loss\n",
    "                \n",
    "                #get predicts\n",
    "                if copy_control<copy_thres:\n",
    "                    _, max_idxs = torch.max(score, dim=1)\n",
    "                else:\n",
    "                    _, max_idxs = torch.max(logits, dim=1)\n",
    "                predicts.append(torch.unsqueeze(max_idxs, dim=0))\n",
    "                \n",
    "        predicts = torch.cat(predicts, dim=0)\n",
    "        predicts = torch.transpose(predicts, 0, 1)\n",
    "    \n",
    "        if is_train:  #training\n",
    "#             all_loss = torch.cat(all_loss, dim=1)\n",
    "#             all_loss = torch.mean(all_loss, dim=1)\n",
    "#             loss = torch.mean(all_loss)\n",
    "            loss = all_loss/self.max_length\n",
    "    \n",
    "            #print('loss size: ', loss.size())\n",
    "            #torch.cuda.empty_cache()\n",
    "            if self.use_cuda:\n",
    "                return loss, predicts.data.cpu().tolist()\n",
    "            else:\n",
    "                return loss, predicts.data.tolist()\n",
    "        else:   #testing\n",
    "            if self.use_cuda:\n",
    "                return predicts.data.cpu().tolist()\n",
    "            else:\n",
    "                return predicts.data.tolist()\n",
    "#         if is_train:  #training\n",
    "#             if self.use_cuda:\n",
    "#                 return all_loss/(self.max_length+1), predicts.data.cpu().numpy()\n",
    "#             else:\n",
    "#                 return all_loss/(self.max_length+1), predicts.data.numpy()\n",
    "#         else:   #testing\n",
    "#             if self.use_cuda:\n",
    "#                 return predicts.data.cpu().numpy()\n",
    "#             else:\n",
    "#                 return predicts.data.numpy()\n",
    "    \n",
    "    \n",
    "    def decode_topk_seqs(self, encoder, inputs, input_lens, topk=3):\n",
    "        enc_outputs, (enc_hn, enc_cn) = encoder(inputs, input_lens)\n",
    "        batch_size = enc_outputs.size(dim = 0)\n",
    "        \n",
    "        #one hot of inputs\n",
    "        sents_len = enc_outputs.size(1)\n",
    "        inputs = inputs[:,:sents_len].unsqueeze(dim=2)\n",
    "        one_hot = torch.FloatTensor(batch_size, sents_len, len(self.vocab.word2token)).zero_()\n",
    "        one_hot.scatter_(2, inputs, 1)\n",
    "        one_hot = one_hot.transpose(1,2)\n",
    "        one_hot = self._tocuda(Variable(one_hot, requires_grad = 0))\n",
    "        \n",
    "        metadata = self.decode_by_beamsearch(encoder_hidden=(enc_hn, enc_cn), encoder_outputs=enc_outputs, inputs_one_hot=one_hot,topk = topk)\n",
    "        results = metadata['topk_sequence']\n",
    "        results =torch.cat(results, dim = 2)\n",
    "        results=results.view(batch_size*topk, -1)\n",
    "        if self.use_cuda:\n",
    "            results = results.data.cpu().tolist()\n",
    "        else:\n",
    "            results = results.data.tolist()\n",
    "#         results=batch_tokens_remove_eos(results, self.vocab)\n",
    "\n",
    "#         labels = [x for x in labels for ii in range(topk)]\n",
    "#         labels = batch_tokens_remove_eos(labels, self.vocab)\n",
    "#         bleu_scores = batch_tokens_bleu(references=labels, candidates=results, smooth_epsilon=0.01)\n",
    "        \n",
    "#         bleu_scores = torch.FloatTensor(bleu_scores).view(batch_size, topk)\n",
    "#         bleu_max, _ = torch.max(bleu_scores, dim=1)\n",
    "        \n",
    "#         bleu_mean = torch.mean(bleu_scores, dim=1).unsqueeze(dim=1)\n",
    "#         bleu_scores = bleu_scores-bleu_mean\n",
    "#         bleu_scores = bleu_scores.view(-1)\n",
    "        \n",
    "#         bleu_scores = self._tocuda(Variable(bleu_scores, requires_grad = 0))\n",
    "#         log_probs = metadata['score']\n",
    "#         log_probs = log_probs.view(batch_size*topk)\n",
    "#         loss = -torch.dot(log_probs, bleu_scores)/batch_size/topk\n",
    "#         return loss, results, torch.mean(bleu_mean.squeeze()), torch.mean(bleu_max)\n",
    "\n",
    "        log_probs = metadata['score']\n",
    "        log_probs = log_probs.view(batch_size*topk)\n",
    "        \n",
    "        return results, log_probs\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _tocuda(self, var):\n",
    "        if self.use_cuda:\n",
    "            return var.cuda()\n",
    "        else:\n",
    "            return var\n",
    "    def decode_by_beamsearch(self, encoder_hidden=None, encoder_outputs=None, inputs_one_hot=None, topk = 10):\n",
    "        self.k = topk\n",
    "        batch_size = encoder_outputs.size(dim=0)\n",
    "        \n",
    "        self.pos_index = self._tocuda(Variable(torch.LongTensor(range(batch_size)) * self.k).view(-1, 1))\n",
    "\n",
    "        hidden = tuple([_inflate(h, self.k, 1).view(batch_size*self.k, -1) for h in encoder_hidden])\n",
    "        #print('hidden0 size: (%s, %s)'%(hidden[0].size(), hidden[1].size()))\n",
    "\n",
    "        encoder_outputs = _inflate(encoder_outputs, self.k, 1).view(batch_size*self.k, encoder_outputs.size(1), encoder_outputs.size(2))\n",
    "        inputs_one_hot = _inflate(inputs_one_hot, self.k, 1).view(batch_size*self.k, inputs_one_hot.size(1), inputs_one_hot.size(2))\n",
    "        \n",
    "        # Initialize the scores; for the first step,\n",
    "        # ignore the inflated copies to avoid duplicate entries in the top k\n",
    "        sequence_scores = torch.Tensor(batch_size * self.k, 1)\n",
    "        sequence_scores.fill_(-float('Inf'))\n",
    "        sequence_scores.index_fill_(0, torch.LongTensor([i * self.k for i in range(0, batch_size)]), 0.0)\n",
    "        sequence_scores = self._tocuda(Variable(sequence_scores))\n",
    "\n",
    "        # Initialize the input vector\n",
    "        input_var = self._tocuda(Variable(torch.LongTensor([self.SOS] * batch_size * self.k)))\n",
    "\n",
    "        # Store decisions for backtracking\n",
    "        stored_outputs = list()\n",
    "        stored_scores = list()\n",
    "        stored_predecessors = list()\n",
    "        stored_emitted_symbols = list()\n",
    "        stored_hidden = list()\n",
    "\n",
    "        for ii in range(0, self.max_length):\n",
    "            # Run the RNN one step forward\n",
    "            #print('setp: %s'%ii)\n",
    "            input_vec = self.embed(input_var)\n",
    "            #print('input_var and input_vec size: ', input_var.size(), input_vec.size())\n",
    "            hidden = self.lstmcell(input_vec, hidden)\n",
    "            #print('hidden size: (%s, %s)'%(hidden[0].size(), hidden[1].size()))\n",
    "            \n",
    "            #log_softmax_output = self.log_softmax(self.fcnn(hidden[0]))\n",
    "            \n",
    "            logits = self.fcnn(hidden[0])\n",
    "#             print('logits size', logits.size())\n",
    "#             print(encoder_outputs.size())\n",
    "#             print(input_vec.size())\n",
    "#             print(hidden[0].size())\n",
    "#             print(inputs_one_hot.size())\n",
    "            if_copy, prob_copy = self.copy_mechanism(enc_outputs=encoder_outputs, this_timestep_input=input_vec.squeeze(dim=1), \n",
    "                                                            dec_state = hidden[0], inputs_one_hot = inputs_one_hot)\n",
    "#             print('if_copy size', if_copy.size(), 'prob_copy size', prob_copy.size())\n",
    "            \n",
    "            score = (1-if_copy)*self.softmax(logits)+if_copy*prob_copy\n",
    "            score = torch.clamp(score, min=10**(-30), max=1)\n",
    "#             print('score size: ', score.size())\n",
    "\n",
    "            # To get the full sequence scores for the new candidates, add the local scores for t_i to the predecessor scores for t_(i-1)\n",
    "            sequence_scores = _inflate(sequence_scores, self.V, 1)\n",
    "            sequence_scores += torch.log(score).squeeze(1)\n",
    "            scores, candidates = sequence_scores.view(batch_size, -1).topk(self.k, dim=1)\n",
    "\n",
    "            # Reshape input = (bk, 1) and sequence_scores = (bk, 1)\n",
    "            input_var = (candidates % self.V).view(batch_size * self.k, 1)\n",
    "            sequence_scores = scores.view(batch_size * self.k, 1)\n",
    "\n",
    "            # Update fields for next timestep\n",
    "            predecessors = (candidates / self.V + self.pos_index.expand_as(candidates)).view(batch_size * self.k, 1)\n",
    "            if isinstance(hidden, tuple):\n",
    "                hidden = tuple([h.index_select(0, predecessors.squeeze()) for h in hidden])\n",
    "            else:\n",
    "                hidden = hidden.index_select(0, predecessors.squeeze())\n",
    "\n",
    "            # Update sequence scores and erase scores for end-of-sentence symbol so that they aren't expanded\n",
    "            stored_scores.append(sequence_scores.clone())\n",
    "            eos_indices = input_var.data.eq(self.EOS)\n",
    "            if eos_indices.nonzero().dim() > 0:\n",
    "                sequence_scores.data.masked_fill_(eos_indices, -float('inf'))\n",
    "\n",
    "            # Cache results for backtracking\n",
    "            stored_predecessors.append(predecessors)\n",
    "            stored_emitted_symbols.append(input_var)\n",
    "#             stored_hidden.append(hidden)\n",
    "\n",
    "        # Do backtracking to return the optimal values\n",
    "        output, h_t, h_n, s, l, p = self._backtrack(hidden,\n",
    "                                                    stored_predecessors, stored_emitted_symbols,\n",
    "                                                    stored_scores, batch_size, self.hidden_size)\n",
    "\n",
    "        metadata = {}\n",
    "\n",
    "        metadata['score'] = s\n",
    "        metadata['topk_length'] = l\n",
    "        metadata['topk_sequence'] = p\n",
    "        metadata['length'] = [seq_len[0] for seq_len in l]\n",
    "        metadata['sequence'] = [seq[0] for seq in p]\n",
    "        \n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "    def _backtrack(self, hidden, predecessors, symbols, scores, b, hidden_size):\n",
    "        \"\"\"Backtracks over batch to generate optimal k-sequences.\n",
    "\n",
    "        Args:\n",
    "            nw_output [(batch*k, vocab_size)] * sequence_length: A Tensor of outputs from network\n",
    "            nw_hidden [(num_layers, batch*k, hidden_size)] * sequence_length: A Tensor of hidden states from network\n",
    "            predecessors [(batch*k)] * sequence_length: A Tensor of predecessors\n",
    "            symbols [(batch*k)] * sequence_length: A Tensor of predicted tokens\n",
    "            scores [(batch*k)] * sequence_length: A Tensor containing sequence scores for every token t = [0, ... , seq_len - 1]\n",
    "            b: Size of the batch\n",
    "            hidden_size: Size of the hidden state\n",
    "\n",
    "        Returns:\n",
    "            output [(batch, k, vocab_size)] * sequence_length: A list of the output probabilities (p_n)\n",
    "            from the last layer of the RNN, for every n = [0, ... , seq_len - 1]\n",
    "\n",
    "            h_t [(batch, k, hidden_size)] * sequence_length: A list containing the output features (h_n)\n",
    "            from the last layer of the RNN, for every n = [0, ... , seq_len - 1]\n",
    "\n",
    "            h_n(batch, k, hidden_size): A Tensor containing the last hidden state for all top-k sequences.\n",
    "\n",
    "            score [batch, k]: A list containing the final scores for all top-k sequences\n",
    "\n",
    "            length [batch, k]: A list specifying the length of each sequence in the top-k candidates\n",
    "\n",
    "            p (batch, k, sequence_len): A Tensor containing predicted sequence\n",
    "        \"\"\"\n",
    "\n",
    "        lstm = isinstance(hidden, tuple)\n",
    "\n",
    "        # initialize return variables given different types\n",
    "        output = list()\n",
    "        h_t = list()\n",
    "        p = list()\n",
    "        # Placeholder for last hidden state of top-k sequences.\n",
    "        # If a (top-k) sequence ends early in decoding, `h_n` contains\n",
    "        # its hidden state when it sees EOS.  Otherwise, `h_n` contains\n",
    "        # the last hidden state of decoding.\n",
    "        if lstm:\n",
    "            state_size = hidden[0].size()\n",
    "            h_n = tuple([torch.zeros(state_size), torch.zeros(state_size)])\n",
    "        else:\n",
    "            h_n = torch.zeros(nw_hidden[0].size())\n",
    "        l = [[self.max_length] * self.k for _ in range(b)]  # Placeholder for lengths of top-k sequences\n",
    "                                                                # Similar to `h_n`\n",
    "\n",
    "        # the last step output of the beams are not sorted\n",
    "        # thus they are sorted here\n",
    "        sorted_score, sorted_idx = scores[-1].view(b, self.k).topk(self.k)\n",
    "        # initialize the sequence scores with the sorted last step beam scores\n",
    "        s = sorted_score.clone()\n",
    "\n",
    "        batch_eos_found = [0] * b   # the number of EOS found\n",
    "                                    # in the backward loop below for each batch\n",
    "\n",
    "        t = self.max_length - 1\n",
    "        # initialize the back pointer with the sorted order of the last step beams.\n",
    "        # add self.pos_index for indexing variable with b*k as the first dimension.\n",
    "        t_predecessors = (sorted_idx + self.pos_index.expand_as(sorted_idx)).view(b * self.k)\n",
    "        while t >= 0:\n",
    "            # Re-order the variables with the back pointer\n",
    "            current_symbol = symbols[t].index_select(0, t_predecessors)\n",
    "            # Re-order the back pointer of the previous step with the back pointer of\n",
    "            # the current step\n",
    "            t_predecessors = predecessors[t].index_select(0, t_predecessors).squeeze()\n",
    "\n",
    "            # This tricky block handles dropped sequences that see EOS earlier.\n",
    "            # The basic idea is summarized below:\n",
    "            #\n",
    "            #   Terms:\n",
    "            #       Ended sequences = sequences that see EOS early and dropped\n",
    "            #       Survived sequences = sequences in the last step of the beams\n",
    "            #\n",
    "            #       Although the ended sequences are dropped during decoding,\n",
    "            #   their generated symbols and complete backtracking information are still\n",
    "            #   in the backtracking variables.\n",
    "            #   For each batch, everytime we see an EOS in the backtracking process,\n",
    "            #       1. If there is survived sequences in the return variables, replace\n",
    "            #       the one with the lowest survived sequence score with the new ended\n",
    "            #       sequences\n",
    "            #       2. Otherwise, replace the ended sequence with the lowest sequence\n",
    "            #       score with the new ended sequence\n",
    "            #\n",
    "            eos_indices = symbols[t].data.squeeze(1).eq(self.EOS).nonzero()\n",
    "            if eos_indices.dim() > 0:\n",
    "                for i in range(eos_indices.size(0)-1, -1, -1):\n",
    "                    # Indices of the EOS symbol for both variables\n",
    "                    # with b*k as the first dimension, and b, k for\n",
    "                    # the first two dimensions\n",
    "                    idx = eos_indices[i]\n",
    "                    b_idx = int(idx[0] / self.k)\n",
    "                    # The indices of the replacing position\n",
    "                    # according to the replacement strategy noted above\n",
    "                    res_k_idx = self.k - (batch_eos_found[b_idx] % self.k) - 1\n",
    "                    batch_eos_found[b_idx] += 1\n",
    "                    res_idx = b_idx * self.k + res_k_idx\n",
    "\n",
    "                    # Replace the old information in return variables\n",
    "                    # with the new ended sequence information\n",
    "                    t_predecessors[res_idx] = predecessors[t][idx[0]]\n",
    "\n",
    "                    current_symbol[res_idx, :] = symbols[t][idx[0]]\n",
    "                    s[b_idx, res_k_idx] = scores[t][idx[0]]\n",
    "                    l[b_idx][res_k_idx] = t + 1\n",
    "\n",
    "            # record the back tracked results\n",
    "            p.append(current_symbol)\n",
    "            t -= 1\n",
    "\n",
    "        # Sort and re-order again as the added ended sequences may change\n",
    "        # the order (very unlikely)\n",
    "        s, re_sorted_idx = s.topk(self.k)\n",
    "        for b_idx in range(b):\n",
    "            l[b_idx] = [l[b_idx][k_idx.data[0]] for k_idx in re_sorted_idx[b_idx,:]]\n",
    "\n",
    "        re_sorted_idx = (re_sorted_idx + self.pos_index.expand_as(re_sorted_idx)).view(b * self.k)\n",
    "\n",
    "        # Reverse the sequences and re-order at the same time\n",
    "        # It is reversed because the backtracking happens in reverse time order\n",
    "#         output = [step.index_select(0, re_sorted_idx).view(b, self.k, -1) for step in reversed(output)]\n",
    "        p = [step.index_select(0, re_sorted_idx).view(b, self.k, -1) for step in reversed(p)]\n",
    "        #    --- fake output ---\n",
    "        output = None\n",
    "        #    --- fake ---\n",
    "        return output, h_t, h_n, s, l, p\n",
    "\n",
    "    def _mask_symbol_scores(self, score, idx, masking_score=-float('inf')):\n",
    "            score[idx] = masking_score\n",
    "\n",
    "    def _mask(self, tensor, idx, dim=0, masking_score=-float('inf')):\n",
    "        if len(idx.size()) > 0:\n",
    "            indices = idx[:, 0]\n",
    "            tensor.index_fill_(dim, indices, masking_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, use_cuda, input_dim, hidden_dim, vocab, max_length = 25):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.enc = Encoder(use_cuda=use_cuda, hidden_dim=hidden_dim, input_dim=input_dim, vocab=vocab)\n",
    "        self.dec = Decoder(use_cuda=use_cuda, encoder=self.enc, hidden_dim=hidden_dim, max_length=max_length)\n",
    "        if use_cuda:\n",
    "            self.enc = self.enc.cuda()\n",
    "            self.dec = self.dec.cuda()\n",
    "    def forward(self, inputs, input_lens, labels, is_train=1, teaching_rate=1):\n",
    "        enc_outputs, (enc_hn, enc_cn) = self.enc(torch.LongTensor(inputs), torch.LongTensor(input_lens))\n",
    "        if is_train:\n",
    "            loss, predicts = self.dec(enc_outputs = enc_outputs, \n",
    "                                    h0_and_c0=(enc_hn, enc_cn), \n",
    "                                    sent_lens=input_lens,\n",
    "                                    labels=torch.LongTensor(labels), \n",
    "                                    is_train=1, \n",
    "                                    teaching_rate = 1,\n",
    "                                    inputs = inputs\n",
    "                                    )\n",
    "            return loss, predicts\n",
    "        else:\n",
    "            predicts = self.dec(enc_outputs = enc_outputs, \n",
    "                                h0_and_c0=(enc_hn, enc_cn), \n",
    "                                sent_lens=input_lens,\n",
    "                                labels=torch.LongTensor(labels), \n",
    "                                is_train=0, \n",
    "                                teaching_rate = 1,\n",
    "                                inputs = inputs\n",
    "                                )\n",
    "            return predicts\n",
    "#     def train_using_rl(self, inputs, input_lens, labels, is_train=1, teaching_rate=1):\n",
    "#         enc_outputs, (enc_hn, enc_cn) = self.enc(torch.LongTensor(inputs), torch.LongTensor(input_lens))\n",
    "#         loss, predicts, bleu_mean = self.dec.train_using_rl_2(enc_outputs = enc_outputs, \n",
    "#                                                 h0_and_c0=(enc_hn, enc_cn), \n",
    "#                                                 sent_lens=input_lens,\n",
    "#                                                 labels=labels,\n",
    "#                                                 is_train=1, \n",
    "#                                                 teaching_rate = 1\n",
    "#                                                 )\n",
    "#         return loss, predicts, bleu_mean\n",
    "\n",
    "    def tocuda(self, x):\n",
    "        if self.use_cuda:\n",
    "            return x.cuda()\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def train_using_reward(self, inputs, input_lens, reconstruct_labels, reconstruct_model, language_model, topk=3, loss_ratio=0.5):\n",
    "#         all_time=time.time()\n",
    "        dec_seqs, log_probs = self.dec.decode_topk_seqs(self.enc, inputs, input_lens, topk=topk)\n",
    "#         enc_outputs, (enc_hn, enc_cn) = self.enc(torch.LongTensor(inputs), torch.LongTensor(input_lens))\n",
    "#         results = self.dec.decode_no_labels(enc_outputs=enc_outputs, h0_and_c0=(enc_hn, enc_cn), topk=topk)\n",
    "\n",
    "#         a=time.time()\n",
    "\n",
    "        simple_sent1s, simple_sent2s = seqs_split(dec_seqs, self.enc.vocab)\n",
    "        \n",
    "        lm_input1s, lm_input1_lens, lm_label1s = get_lm_inputs_and_labels(simple_sent1s, self.enc.vocab, self.dec.max_length)\n",
    "        simple_sent1s_ppl = language_model.get_sentences_ppl(torch.LongTensor(lm_input1s), \n",
    "                                                      torch.LongTensor(lm_input1_lens), \n",
    "                                                      torch.LongTensor(lm_label1s)\n",
    "                                                    )\n",
    "        lm_input2s, lm_input2_lens, lm_label2s = get_lm_inputs_and_labels(simple_sent2s, self.enc.vocab, self.dec.max_length)\n",
    "        simple_sent2s_ppl = language_model.get_sentences_ppl(torch.LongTensor(lm_input2s), \n",
    "                                                      torch.LongTensor(lm_input2_lens), \n",
    "                                                      torch.LongTensor(lm_label2s)\n",
    "                                                    )\n",
    "        \n",
    "        simple_inputs, simple_input_lens = simple_sents_concat(simple_sent1s, simple_sent2s, self.enc.vocab, self.dec.max_length)\n",
    "        \n",
    "        #reconstruct labels\n",
    "        reconstruct_loss, predicts = reconstruct_model.forward(torch.LongTensor(simple_inputs), \n",
    "                                     torch.LongTensor(simple_input_lens), \n",
    "                                     labels=reconstruct_labels, \n",
    "                                     is_train=1, teaching_rate=1)\n",
    "#         print('cpu: ', time.time()-a)\n",
    "        #rm_rewards: reconstruct model rewards\n",
    "        #lm_rewards: language model rewards\n",
    "        rm_rewards=-reconstruct_loss.data\n",
    "        lm_rewards=self.tocuda(-(torch.Tensor(simple_sent1s_ppl)+torch.Tensor(simple_sent2s_ppl))/2)\n",
    "        \n",
    "        rm_rewards_mean = torch.mean(rm_rewards.view(-1, topk), dim=1)\n",
    "        lm_rewards_mean = torch.mean(lm_rewards.view(-1, topk), dim=1)\n",
    "        rm_rewards = rm_rewards.view(-1, topk) - rm_rewards_mean.unsqueeze(dim=1)\n",
    "        lm_rewards = lm_rewards.view(-1, topk) - lm_rewards_mean.unsqueeze(dim=1)\n",
    "        \n",
    "        rm_rewards = rm_rewards.view(-1)\n",
    "        lm_rewards = lm_rewards.view(-1)\n",
    "        \n",
    "        #sum both rewards up\n",
    "        rewards = loss_ratio*rm_rewards+(1-loss_ratio)*lm_rewards\n",
    "        rewards = Variable(rewards, requires_grad=0)\n",
    "#         print(rewards.size(), log_probs.size())\n",
    "        \n",
    "        #regarding rewards as weights of every seq\n",
    "        loss = -torch.dot(log_probs, rewards)/log_probs.size(0)\n",
    "#         print('all', time.time()-all_time)\n",
    "\n",
    "#         labels = [x for x in labels for ii in range(topk)]\n",
    "#         labels = batch_tokens_remove_eos(labels, self.vocab)\n",
    "#         bleu_scores = batch_tokens_bleu(references=labels, candidates=results, smooth_epsilon=0.01)\n",
    "        \n",
    "#         bleu_scores = torch.FloatTensor(bleu_scores).view(batch_size, topk)\n",
    "#         bleu_max, _ = torch.max(bleu_scores, dim=1)\n",
    "        \n",
    "#         bleu_mean = torch.mean(bleu_scores, dim=1).unsqueeze(dim=1)\n",
    "#         bleu_scores = bleu_scores-bleu_mean\n",
    "#         bleu_scores = bleu_scores.view(-1)\n",
    "        \n",
    "#         bleu_scores = self._tocuda(Variable(bleu_scores, requires_grad = 0))\n",
    "        \n",
    "#         log_probs = metadata['score']\n",
    "#         log_probs = log_probs.view(batch_size*topk)\n",
    "    \n",
    "#         loss = -torch.dot(log_probs, bleu_scores)/batch_size/topk\n",
    "        \n",
    "        return loss, reconstruct_loss, torch.mean(rm_rewards_mean), torch.mean(lm_rewards_mean)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading pre-train weight for language model.\n",
      "init lookup embedding matrix size:  torch.Size([44380, 100])\n",
      "init lookup embedding matrix size:  torch.Size([44380, 100])\n"
     ]
    }
   ],
   "source": [
    "lm_hidden_dim=1024\n",
    "lm_input_dim=300\n",
    "use_cuda=1\n",
    "\n",
    "language_model = LanguageModel(use_cuda = use_cuda, input_dim = lm_input_dim, hidden_dim = lm_hidden_dim, vocab = vocab)\n",
    "#512\n",
    "model_path = './models_language_model/time-[2019-02-26-11-27-36]-info=[language_model]-loss=3.414012194-bleu=-1.0000-hidden_dim=512-input_dim=300-epoch=21-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050'\n",
    "#2048\n",
    "model_path = './models_language_model/time-[2019-02-28-07-04-08]-info=[language_model]-loss=3.475848675-bleu=-1.0000-hidden_dim=2048-input_dim=300-epoch=4-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050'\n",
    "#1024\n",
    "model_path = './models_language_model/time-[2019-02-27-21-58-23]-info=[language_model]-loss=4.111208439-bleu=-1.0000-hidden_dim=1024-input_dim=300-epoch=6-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050'\n",
    "\n",
    "pre_train = torch.load(model_path, map_location='cpu')\n",
    "language_model.load_state_dict(pre_train)\n",
    "\n",
    "if use_cuda:\n",
    "    language_model = language_model.cuda()\n",
    "    \n",
    "language_model.eval()\n",
    "\n",
    "print('finish loading pre-train weight for language model.')\n",
    "\n",
    "\n",
    "\n",
    "use_cuda = 1\n",
    "hidden_dim = 256\n",
    "input_dim = 100\n",
    "lr=0.005\n",
    "\n",
    "split_model = Seq2Seq(use_cuda = use_cuda, input_dim = input_dim, hidden_dim = hidden_dim, \n",
    "                          vocab = vocab, max_length = 61)\n",
    "\n",
    "fusion_model = Seq2Seq(use_cuda = use_cuda, input_dim = input_dim, hidden_dim = hidden_dim, \n",
    "                          vocab = vocab, max_length = 51)\n",
    "#pre train para\n",
    "# pre_train = torch.load('./models_saved/time-[2019-03-03-01-10-08]-info=[split_model]-loss=0.796790183-bleu=0.7053-hidden_dim=256-input_dim=100-epoch=3-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050', map_location='cpu')\n",
    "# split_model.load_state_dict(pre_train)\n",
    "# pre_train = torch.load('./models_saved/time-[2019-03-03-01-10-09]-info=[fusion_model]-loss=0.491095543-bleu=0.7543-hidden_dim=256-input_dim=100-epoch=3-batch_size=100-batch_id=[1-[of]-9899]-lr=0.0050', map_location='cpu')\n",
    "# fusion_model.load_state_dict(pre_train)\n",
    "\n",
    "#pre train para\n",
    "# pre_train = torch.load('./models_saved/time-[2019-03-06-08-04-50]-info=[split_model-epoch+3]-loss=0.048888605-bleu=0.6069-hidden_dim=256-input_dim=100-epoch=0-batch_size=100-batch_id=[9001-[of]-9899]-lr=0.0050', map_location='cpu')\n",
    "# split_model.load_state_dict(pre_train)\n",
    "# pre_train = torch.load('./models_saved/time-[2019-03-06-08-04-51]-info=[fusion_model-epoch+3]-loss=0.010411686-bleu=0.9965-hidden_dim=256-input_dim=100-epoch=0-batch_size=100-batch_id=[9001-[of]-9899]-lr=0.0050', map_location='cpu')\n",
    "# fusion_model.load_state_dict(pre_train)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    split_model = split_model.cuda()\n",
    "    fusion_model = fusion_model.cuda()\n",
    "        \n",
    "split_optimizer = optim.Adam(filter(lambda p: p.requires_grad, split_model.parameters()), lr=lr)\n",
    "fusion_optimizer = optim.Adam(filter(lambda p: p.requires_grad, fusion_model.parameters()), lr=lr)\n",
    "\n",
    "\n",
    "for param in fusion_model.parameters():\n",
    "     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updata paras time:  27.869161367416382\n",
      "time-[2019-03-08-19-09-58]-\n",
      "updata paras time:  27.774999856948853\n",
      "updata paras time:  29.88867712020874\n",
      "time-[2019-03-08-19-10-59]-\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bab54e7749f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_train_set_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running time: %.2f mins'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-bab54e7749f0>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(epoch, batch_size, train_set_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0msplit_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#clear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0msplit_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'updata paras time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=25\n",
    "split_train_set_size=int(len(split_train_set_inputs)/300)\n",
    "epochs=10000\n",
    "train_bleu_mean=-1\n",
    "train_bleu_max=-1\n",
    "topk=2\n",
    "loss_ratio=0.95\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def model_train(epoch, batch_size, train_set_size):\n",
    "    batch_id = 0\n",
    "    valid_bleu = 0\n",
    "    for start_idx in range(0, train_set_size-batch_size+1, batch_size):\n",
    "            \n",
    "        batch_id+=1\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        split_optimizer.zero_grad()#clear\n",
    "        total_loss, reconstruct_loss, rm_rewards, lm_rewards=split_model.train_using_reward(inputs=torch.LongTensor(split_train_set_inputs[start_idx:end_idx]), \n",
    "                               input_lens=torch.LongTensor(split_train_set_input_lens[start_idx:end_idx]), \n",
    "                               reconstruct_labels=torch.LongTensor(duplicate_reconstruct_labels(fusion_pseudo_train_set_labels[start_idx:end_idx],topk)), \n",
    "                               reconstruct_model=fusion_model, \n",
    "                               language_model=language_model, \n",
    "                               topk=topk, loss_ratio=loss_ratio)\n",
    "        reconstruct_loss = torch.mean(reconstruct_loss)\n",
    "        \n",
    "        a=time.time()\n",
    "        split_optimizer.zero_grad()#clear\n",
    "        total_loss.backward()#retain_graph=True)\n",
    "        split_optimizer.step()\n",
    "        print('updata paras time: ', time.time()-a)\n",
    "        \n",
    "#         fusion_optimizer.zero_grad()\n",
    "#         reconstruct_loss.backward()\n",
    "#         fusion_optimizer.step()\n",
    "    \n",
    "        if batch_id%2==1:\n",
    "            now = int(round(time.time()*1000))\n",
    "            time_stamp = time.strftime('time-[%Y-%m-%d-%H-%M-%S]-',time.localtime(now/1000))\n",
    "            print(time_stamp)\n",
    "            \n",
    "            \n",
    "#         if batch_id%10==1:\n",
    "#             split_model.eval()\n",
    "#             fusion_model.eval()\n",
    "            \n",
    "#             sample_num = 5\n",
    "#             rand_idx = random.randint(0, train_set_size-sample_num-1)\n",
    "            \n",
    "#             print('--------split model training sampling display--------')\n",
    "#             #teaching forcing\n",
    "#             loss_, predicts = split_model.forward(torch.LongTensor(split_train_set_inputs[rand_idx:rand_idx+sample_num]), \n",
    "#                                              torch.LongTensor(split_train_set_input_lens[rand_idx:rand_idx+sample_num]), \n",
    "#                                              labels=torch.LongTensor(split_pseudo_train_set_labels[rand_idx:rand_idx+sample_num]), \n",
    "#                                              is_train=1, teaching_rate=1)\n",
    "#             del loss_\n",
    "            \n",
    "#             predicts = batch_tokens_remove_eos(predicts, vocab)\n",
    "#             labels = batch_tokens_remove_eos(split_pseudo_train_set_labels[rand_idx:rand_idx+sample_num], vocab)\n",
    "            \n",
    "#             predicts = batch_tokens2words(predicts, vocab)\n",
    "#             labels = batch_tokens2words(labels, vocab)\n",
    "            \n",
    "#             predicts_sents = batch_words2sentence(predicts)\n",
    "#             labels_sents = batch_words2sentence(labels)\n",
    "            \n",
    "#             for (predict_sent, label_sent) in zip(predicts_sents, labels_sents):\n",
    "#                 print(' 1----> ', predict_sent)\n",
    "#                 print(' 2----> ', label_sent)\n",
    "#                 print('\\n')\n",
    "            \n",
    "#             info_stamp = 'info=[{:s}]-total_loss={:2.9f}-rec_loss={:2.9f}-lm_rewards={:5.4f}-hidden_dim={:n}-input_dim={:n}-epoch={:n}-batch_size={:n}-batch_id=[{:n}-[of]-{:n}]-lr={:1.4f}'.format(\n",
    "#                               'split_model', total_loss.data[0], reconstruct_loss.data[0], lm_rewards, \n",
    "#                             hidden_dim, input_dim, epoch, batch_size, batch_id, int(train_set_size/batch_size), lr)\n",
    "#             print(info_stamp)\n",
    "            \n",
    "#             if batch_id%20==1:\n",
    "#                 rand_idx=random.randint(0, len(split_valid_set_inputs)-batch_size-1-1)\n",
    "#                 predicts = split_model.forward(torch.LongTensor(split_valid_set_inputs[rand_idx:rand_idx+batch_size]), \n",
    "#                                                  torch.LongTensor(split_valid_set_input_lens[rand_idx:rand_idx+batch_size]), \n",
    "#                                                  labels=[],#torch.LongTensor(valid_set_labels[rand_idx:rand_idx+batch_size]), \n",
    "#                                                  is_train=0, teaching_rate=1)\n",
    "#                 predicts = batch_tokens_remove_eos(predicts, vocab)\n",
    "#                 labels = batch_tokens_remove_eos(split_pseudo_valid_set_labels[rand_idx:rand_idx+batch_size], vocab)\n",
    "                \n",
    "#                 bleu_scores = batch_tokens_bleu(references=labels, candidates=predicts, smooth_epsilon=0.001)\n",
    "\n",
    "#                 valid_bleu = 0\n",
    "#                 for x in bleu_scores:\n",
    "#                     valid_bleu+=x\n",
    "#                 valid_bleu/=len(bleu_scores)\n",
    "                       \n",
    "#                 info_stamp = 'info=[{:s}]-total_loss={:2.9f}-rec_loss={:2.9f}-lm_rewards={:5.4f}-bleu={:1.4f}-topk={:n}-hidden_dim={:n}-input_dim={:n}-epoch={:n}-batch_size={:n}-batch_id=[{:n}-[of]-{:n}]-lr={:1.4f}-loss_ratio={:1.4f}'.format(\n",
    "#                               'split_model', total_loss.data[0], reconstruct_loss.data[0], lm_rewards, valid_bleu, topk,\n",
    "#                             hidden_dim, input_dim, epoch, batch_size, batch_id, int(train_set_size/batch_size), lr, loss_ratio)\n",
    "                \n",
    "#                 print(info_stamp, valid_bleu)\n",
    "                \n",
    "#                 now = int(round(time.time()*1000))\n",
    "#                 time_stamp = time.strftime('time-[%Y-%m-%d-%H-%M-%S]-',time.localtime(now/1000))\n",
    "# #                 torch.save(split_model.state_dict(), ''.join(['./models_saved/', time_stamp, info_stamp]))\n",
    "# #                 torch.save(fusion_model.state_dict(), ''.join(['./models_saved/', time_stamp, 'info=[fusion_model]']))\n",
    "#             split_model.train()\n",
    "#             fusion_model.train()\n",
    "            \n",
    "for epoch in range(epochs):\n",
    "    model_train(epoch, batch_size, split_train_set_size)\n",
    "    \n",
    "print('running time: %.2f mins'%((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-30d9529ff51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_num=2\n",
    "topk=20\n",
    "\n",
    "predicts, log_probs=split_model.dec.decode_topk_seqs(split_model.enc, inputs=torch.LongTensor(split_train_set_inputs[0:sample_num]), \n",
    "                             input_lens=torch.LongTensor(split_train_set_input_lens[0:sample_num]), \n",
    "                             topk=topk)\n",
    "\n",
    "predicts = batch_tokens_remove_eos(predicts, vocab)\n",
    "labels = batch_tokens_remove_eos(split_pseudo_train_set_labels[0:sample_num], vocab)\n",
    "\n",
    "predicts = batch_tokens2words(predicts, vocab)\n",
    "labels = batch_tokens2words(labels, vocab)\n",
    "\n",
    "predicts_sents = batch_words2sentence(predicts)\n",
    "labels_sents = batch_words2sentence(labels)\n",
    "\n",
    "for idx, sent in enumerate(predicts_sents):\n",
    "    print(' 1----> ', sent)\n",
    "    if idx%topk==(topk-1):\n",
    "        print(' 2----> ', labels_sents[int(idx/topk)])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_thres=1.0\n",
    "# split_loss, predicts = split_model.forward(torch.LongTensor(split_train_set_inputs[0:sample_num]), \n",
    "#                                      torch.LongTensor(split_train_set_input_lens[0:sample_num]), \n",
    "#                                      labels=torch.LongTensor(split_pseudo_train_set_labels[0:sample_num]), \n",
    "#                                      is_train=1, teaching_rate=1)\n",
    "\n",
    "# predicts = batch_tokens_remove_eos(predicts, vocab)\n",
    "# labels = batch_tokens_remove_eos(split_pseudo_train_set_labels[0:sample_num], vocab)\n",
    "\n",
    "# predicts = batch_tokens2words(predicts, vocab)\n",
    "# labels = batch_tokens2words(labels, vocab)\n",
    "\n",
    "# predicts_sents = batch_words2sentence(predicts)\n",
    "# labels_sents = batch_words2sentence(labels)\n",
    "\n",
    "# for (predict_sent, label_sent) in zip(predicts_sents, labels_sents):\n",
    "#     print(' 1----> ', predict_sent)\n",
    "#     print(' 2----> ', label_sent)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
