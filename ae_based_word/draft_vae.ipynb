{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import over\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import time\n",
    "\n",
    "from Vocab import Vocab\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "print('import over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenized_sent2real_sent(tokenized_sent, vocab):\n",
    "    real_sent=[]\n",
    "    for token in tokenized_sent:\n",
    "        if token == vocab.word2token['eos']:\n",
    "            break\n",
    "        else:\n",
    "            real_sent.append(vocab.token2word[token])\n",
    "    return ''.join(real_sent)\n",
    "\n",
    "def reverse_tokenized_sent2real_sent(tokenized_sent, vocab):\n",
    "    real_sent=[]\n",
    "    for token in tokenized_sent:\n",
    "        if token == vocab.word2token['eos']:\n",
    "            break\n",
    "        else:\n",
    "            real_sent.append(vocab.token2word[token])\n",
    "    real_sent.reverse()\n",
    "    return ''.join(real_sent)\n",
    "\n",
    "\n",
    "def data_set_bleu(sents1, sents2):\n",
    "    cnt=0\n",
    "    bleu_score_sum=0\n",
    "    \n",
    "    for sent1, sent2 in zip(sents1, sents2):\n",
    "        if min(len(sent1), len(sent2))<4:\n",
    "            pass\n",
    "        else:\n",
    "            cnt+=1\n",
    "            bleu_socre_sum = sentence_bleu([list(sent1)], list(sent2))+bleu_score_sum\n",
    "            \n",
    "    return bleu_score_sum, cnt\n",
    "\n",
    "\n",
    "with open('vocab.pk', 'rb') as f:\n",
    "    vocab=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "公历纷繁复杂\n",
      "纷繁复杂公历mask\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_sent2real_sent([5,6,2,1,1], vocab))\n",
    "print(reverse_tokenized_sent2real_sent([4,5,6,2,1,1], vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data_set/train_set_inputs.pk', 'rb') as f:\n",
    "    train_set_inputs = pickle.load(f)\n",
    "with open('./data_set/train_set_input_lens.pk', 'rb') as f:\n",
    "    train_set_input_lens = pickle.load(f)\n",
    "with open('./data_set/train_set_labels.pk', 'rb') as f:\n",
    "    train_set_labels = pickle.load(f)\n",
    "    \n",
    "with open('./data_set/valid_set_inputs.pk', 'rb') as f:\n",
    "    valid_set_inputs = pickle.load(f)\n",
    "with open('./data_set/valid_set_input_lens.pk', 'rb') as f:\n",
    "    valid_set_input_lens = pickle.load(f)\n",
    "with open('./data_set/valid_set_labels.pk', 'rb') as f:\n",
    "    valid_set_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8697000 8697000 8697000 1185955 1185955 1185955\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set_inputs), len(train_set_input_lens), len(train_set_labels), \n",
    "      len(valid_set_input_lens), len(valid_set_inputs), len(valid_set_labels))\n",
    "\n",
    "for sent_len in valid_set_input_lens:\n",
    "    if sent_len<=2:\n",
    "        print('why')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, use_cuda, hidden_dim, input_dim, vocab):#, pre_train_weight, is_fix_word_vector = 1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.input_dim=input_dim\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.lstm=torch.nn.LSTM(input_size=self.input_dim, \n",
    "                                hidden_size= self.hidden_dim, \n",
    "                                bidirectional=True,\n",
    "                                batch_first=True\n",
    "                               )\n",
    "        \n",
    "        #embedding\n",
    "        self.embed=nn.Embedding(len(self.vocab.word2token), input_dim)\n",
    "        \n",
    "        with open('../pre_train_wordembedding/pre_train_word_embedding.pk', 'rb') as f:\n",
    "            pre_train_word_embedding = pickle.load(f)\n",
    "            \n",
    "        self.embed.weight.data.copy_(torch.FloatTensor(pre_train_word_embedding))\n",
    "        #self.embed.weight.requires_grad = False\n",
    "        \n",
    "#         self.fcnn1=nn.Linear(hidden_dim*2, hidden_dim)\n",
    "#         self.fcnn2=nn.Linear(hidden_dim, hidden_dim)\n",
    "#         self.activate_func=nn.ReLU()\n",
    "        \n",
    "#         self.loss_func = nn.MSELoss()\n",
    "        \n",
    "    def order(self, inputs, inputs_len):\n",
    "        \n",
    "        inputs_len, sort_ids = torch.sort(inputs_len, dim=0, descending=True)\n",
    "        #print(inputs.shape, sort_ids.shape, inputs_len.shape)\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            inputs = inputs.index_select(0, Variable(sort_ids).cuda())\n",
    "        else:\n",
    "            inputs = inputs.index_select(0, Variable(sort_ids))\n",
    "        \n",
    "        _, true_order_ids = torch.sort(sort_ids, dim=0, descending=False)\n",
    "        \n",
    "        return inputs, inputs_len, true_order_ids\n",
    "    #\n",
    "    def forward(self, inputs, inputs_len):\n",
    "        inputs = Variable(inputs)\n",
    "        if self.use_cuda:\n",
    "            inputs=inputs.cuda()\n",
    "            \n",
    "        inputs, sort_len, true_order_ids = self.order(inputs, inputs_len)\n",
    "\n",
    "#         print(self.embed.weight.data[0])\n",
    "#         self.embed.weight.data[0]=torch.LongTensor(([2]*400))\n",
    "#         print(self.embed.weight.data[0])\n",
    "#         print(self.embed.weight)\n",
    "        \n",
    "        #print('encoder lstm, inputs size:', inputs.size())\n",
    "        in_vec=self.embed(inputs)\n",
    "        #print('encoder lstm, in_vec size:', in_vec.size())\n",
    "        packed = rnn_utils.pack_padded_sequence(input=in_vec, lengths=list(sort_len), batch_first =True)\n",
    "        \n",
    "        outputs, (hn,cn) = self.lstm(packed)\n",
    "        outputs, sent_lens = rnn_utils.pad_packed_sequence(outputs)\n",
    "        \n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        \n",
    "        outputs = outputs.transpose(0,1)\n",
    "        #print(outputs)\n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            outputs = outputs.index_select(0, Variable(true_order_ids).cuda())\n",
    "        else:\n",
    "            outputs = outputs.index_select(0, Variable(true_order_ids))\n",
    "        \n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        #\n",
    "        # warnning: hn and cn have not been sorted by sentences length so the order is wrong.\n",
    "        #\n",
    "        #print('hn and cn: ', hn, cn)\n",
    "        hn = torch.cat((hn[0], hn[1]), dim=1)\n",
    "        cn = torch.cat((cn[0], cn[1]), dim=1)\n",
    "        #print('hn size and cn size: ', hn.size(), cn.size())\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            hn = hn.index_select(0, Variable(true_order_ids).cuda())\n",
    "            cn = cn.index_select(0, Variable(true_order_ids).cuda())\n",
    "        else:\n",
    "            hn = hn.index_select(0, Variable(true_order_ids))\n",
    "            cn = cn.index_select(0, Variable(true_order_ids))\n",
    "            \n",
    "        #print('hn and cn: ', hn, cn)\n",
    "        \n",
    "#         print(outputs.size())\n",
    "#         print(hn.size())\n",
    "\n",
    "        return outputs, (hn,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, use_cuda, encoder, hidden_dim, max_length=25):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.input_dim = encoder.input_dim\n",
    "        self.max_length = max_length\n",
    "        self.vocab = encoder.vocab\n",
    "        self.weight = [1]*len(self.vocab.word2token)\n",
    "        self.weight[self.vocab.word2token['padding']]=0\n",
    "        #self.weight[self.vocab.word2token['eos']]=1.01\n",
    "        \n",
    "#         self.lstm=torch.nn.LSTM(input_size=self.input_dim, \n",
    "#                                 hidden_size= self.hidden_dim, \n",
    "#                                 bidirectional=True,\n",
    "#                                 batch_first=True\n",
    "#                                )\n",
    "        \n",
    "        self.lstm = torch.nn.LSTMCell(input_size=self.input_dim, hidden_size=self.hidden_dim*2, bias=True)\n",
    "        \n",
    "        #embedding\n",
    "        self.embed=encoder.embed# reference share\n",
    "        #softmax\n",
    "        self.fcnn = nn.Linear(in_features = self.hidden_dim*2, out_features = len(self.vocab.word2token))\n",
    "        \n",
    "#         with open('../pre_train_wordembedding/pre_train_word_embedding.pk', 'rb') as f:\n",
    "#             pre_train_word_embedding = pickle.load(f)\n",
    "#         self.fcnn.weight.data.copy_(torch.FloatTensor(pre_train_word_embedding))\n",
    "#         self.fcnn.weight.requires_grad = True\n",
    "#         #self.fcnn.bias.data.fill_(0.0)\n",
    "#         #self.fcnn.bias.requires_grad = True\n",
    "        \n",
    "#         self.transform = nn.Linear(in_features = self.hidden_dim*2, out_features = self.input_dim)\n",
    "#         #self.transform.bias.data.fill_(0.0)\n",
    "#         #self.transform.bias.requires_grad = False\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        self.cost_func = nn.CrossEntropyLoss(torch.Tensor(self.weight))\n",
    "        \n",
    "        print('init lookup embedding matrix size: ', self.embed.weight.data.size())\n",
    "        \n",
    "    def forward(self, enc_outputs, sent_lens, h0_and_c0, labels, teaching_rate=0.6, is_train=1, force_argmax=1):\n",
    "        labels = Variable(labels)\n",
    "        if self.use_cuda:\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "\n",
    "        all_loss = 0\n",
    "        predicts = []\n",
    "        batch_size = enc_outputs.size(dim = 0)\n",
    "\n",
    "        \n",
    "        #print('enc_outputs size: ', enc_outputs.size())\n",
    "#         for ii in range(batch_size):\n",
    "#             forward_result = enc_outputs[ii, sent_lens[ii]-1, :self.hidden_dim].unsqueeze(dim=0)\n",
    "#             reverse_result = enc_outputs[ii, 0, self.hidden_dim:].unsqueeze(dim=0)\n",
    "#             final_hidden_states[ii] = torch.cat([forward_result, reverse_result], dim = 1)   #so enc_outputs[ii, sent_lens[ii]-1, :] 's size: self.hidden_dim*2\n",
    "        \n",
    "#         #print('final_hidden_states[0] size', final_hidden_states[0].size())\n",
    "#         final_hidden_states = torch.cat(final_hidden_states, dim=0)\n",
    "        \n",
    "        #print('final_hidden_states size: ', final_hidden_states.size())\n",
    "        \n",
    "        final_hidden_states = h0_and_c0[0]\n",
    "        embed_weight = self.embed.weight\n",
    "        embed_weight_expand  =embed_weight.expand(batch_size, embed_weight.size(0), embed_weight.size(1))\n",
    "        \n",
    "        for ii in range(self.max_length+1):\n",
    "            if ii==0:\n",
    "                zero_timestep_input = torch.LongTensor([self.vocab.word2token['sos']]*batch_size)\n",
    "                zero_timestep_input = Variable(zero_timestep_input)\n",
    "                if self.use_cuda:\n",
    "                    zero_timestep_input = zero_timestep_input.cuda()\n",
    "                    \n",
    "                zero_timestep_input = self.embed(zero_timestep_input)#size: batch_size * self.input_dim\n",
    "\n",
    "                #print('zero_timestep_input size: ', zero_timestep_input.size())\n",
    "                \n",
    "                \n",
    "#                 h0 = Variable(torch.zeros((batch_size, self.hidden_dim*2)))\n",
    "#                 c0 = Variable(torch.zeros((batch_size, self.hidden_dim*2)))\n",
    "#                 if self.use_cuda:\n",
    "#                     h0 = h0.cuda()\n",
    "#                     c0 = c0.cuda()\n",
    "                    \n",
    "                #h0_and_c0=(h0,c0)\n",
    "                \n",
    "                #print('zero_timestep_input size: ', zero_timestep_input.size())\n",
    "                #print('final_hidden_states size: ', final_hidden_states.size())\n",
    "                \n",
    "                #last_timestep_hidden_state,cx = self.lstm(torch.cat([zero_timestep_input, final_hidden_states],dim=1), h0_and_c0)#h0 and c0\n",
    "                \n",
    "                #last_timestep_hidden_state,cx = self.lstm(zero_timestep_input, h0_and_c0)\n",
    "                #print('hn and cn sizes: ', last_timestep_hidden_state.size(), cx.size())\n",
    "                \n",
    "                last_timestep_hidden_state,cx = self.lstm(zero_timestep_input,(h0_and_c0[0]-h0_and_c0[0], h0_and_c0[1]-h0_and_c0[1]))\n",
    "                \n",
    "                #print(last_timestep_hidden_state.size(), type(hn), type(cn))\n",
    "                last_timestep_output = self.softmax(self.fcnn(last_timestep_hidden_state))\n",
    "                #print('last_timestep_hidden_state size: ', last_timestep_output.size(), 'last_timestep_output size: ', last_timestep_output.size())\n",
    "                if is_train:\n",
    "                    #print('last_timestep_output size: ', last_timestep_output.size(), labels[:,0].size())\n",
    "                    loss = self.cost_func(last_timestep_output, labels[:,0])\n",
    "                    #print('loss size: ', loss.size(), loss.data, torch.mean(loss).data)\n",
    "                    all_loss+=loss\n",
    "                #else:\n",
    "                #print(last_timestep_output.size())\n",
    "                #x=torch.squeeze(last_timestep_output, dim=1)\n",
    "                #print('x size: ', x.size())\n",
    "                _, max_idxs = torch.max(last_timestep_output, dim=1)\n",
    "                predicts.append(torch.unsqueeze(max_idxs, dim=0))\n",
    "                #print('max_idxs size: ',max_idxs.size(), max_idxs)\n",
    "                \n",
    "            else: # ii !=0\n",
    "                if is_train:\n",
    "                    rand = random.random()\n",
    "                    if rand<teaching_rate:\n",
    "                        #print('rand: ', rand)\n",
    "                        this_timestep_input = self.embed(labels[:,ii-1])#label teaching, lookup embedding\n",
    "                    elif force_argmax==1:\n",
    "                        this_timestep_input = self.embed(max_idxs)#last_timestep output, and then look up word embedding\n",
    "                    else:\n",
    "                        \n",
    "                        #print(embed_weight.size(), last_timestep_output.size())\n",
    "                        this_timestep_input = torch.bmm(last_timestep_output.unsqueeze(dim=1), \n",
    "                                                embed_weight_expand)#global embedding\n",
    "                        #print('block multi', this_timestep_input.size())\n",
    "                else:\n",
    "                    if force_argmax==1:\n",
    "                        this_timestep_input = self.embed(max_idxs)#last_timestep output, and then look up word embedding\n",
    "                    else:\n",
    "                        \n",
    "                        #print(embed_weight.size(), last_timestep_output.size())\n",
    "                        this_timestep_input = torch.bmm(last_timestep_output.unsqueeze(dim=1), \n",
    "                                                embed_weight_expand)#global embedding\n",
    "                        #print('block multi', this_timestep_input.size())\n",
    "                \n",
    "                \n",
    "                #print('this_timestep_input size: ', this_timestep_input.size())\n",
    "                #print('final_hidden_states size: ', final_hidden_states.size())\n",
    "#                 last_timestep_hidden_state ,cx = self.lstm(torch.cat([this_timestep_input.squeeze(dim=1), final_hidden_states],dim=1)\n",
    "#                                                            , (last_timestep_hidden_state,cx))\n",
    "\n",
    "                last_timestep_hidden_state ,cx = self.lstm(this_timestep_input, (last_timestep_hidden_state,cx))\n",
    "\n",
    "                last_timestep_output = self.softmax(self.fcnn(last_timestep_hidden_state))\n",
    "                \n",
    "                if is_train:\n",
    "                    #print('x size and labels[:, 0] size: ', x.size(), labels[:,0].size())\n",
    "                    #x=torch.squeeze(last_timestep_output, dim=1)\n",
    "                    #print('x size and labels[:, 0] size: ', x.size(), labels[:,0].size())\n",
    "                    loss = self.cost_func(last_timestep_output, labels[:,ii])\n",
    "                    all_loss+=loss\n",
    "                \n",
    "                #x=torch.squeeze(last_timestep_output, dim=1)\n",
    "                _, max_idxs = torch.max(last_timestep_output, dim=1)\n",
    "                #print('max_idx size: ', max_idxs.size(), max_idxs)\n",
    "                predicts.append(torch.unsqueeze(max_idxs, dim=0))\n",
    "                \n",
    "#                 if ii==1:\n",
    "#                     print('this_timestep_input size: ', this_timestep_input.size(), 'max_idxs size: ', max_idxs.size())\n",
    "                    \n",
    "#         if is_train:\n",
    "#             return all_loss/(self.max_length+1)\n",
    "#         else:\n",
    "#             #predict results\n",
    "#             predicts = torch.cat(predicts, dim=0)\n",
    "#             #print('predicts size: ', predicts.size())\n",
    "#             predicts = torch.transpose(predicts, 0, 1)\n",
    "#             if self.use_cuda:\n",
    "#                 return predicts.data.cpu().numpy()\n",
    "#             else:\n",
    "#                 return predicts.data.numpy()\n",
    "\n",
    "\n",
    "        predicts = torch.cat(predicts, dim=0)\n",
    "        predicts = torch.transpose(predicts, 0, 1)\n",
    "        #print('predicts size: ', predicts.size())\n",
    "        \n",
    "        if is_train:  #training\n",
    "            if self.use_cuda:\n",
    "                return all_loss/(self.max_length+1), predicts.data.cpu().numpy()\n",
    "            else:\n",
    "                return all_loss/(self.max_length+1), predicts.data.numpy()\n",
    "        else:   #testing\n",
    "            if self.use_cuda:\n",
    "                return predicts.data.cpu().numpy()\n",
    "            else:\n",
    "                return predicts.data.numpy()\n",
    "            \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences length:  (8, 11, 11, 13, 7, 9, 25, 7, 7, 11, 8)\n",
      "enc result size:  torch.Size([11, 25, 256]) torch.Size([11, 256]) torch.Size([11, 256])\n",
      "init lookup embedding matrix size:  torch.Size([98637, 300])\n",
      "loss is 11.4992046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/hmx/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/data1/hmx/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:147: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = 1\n",
    "hidden_dim = 128\n",
    "input_dim = 300\n",
    "\n",
    "\n",
    "enc = Encoder(use_cuda=use_cuda, \n",
    "            hidden_dim=hidden_dim, \n",
    "            input_dim=input_dim, \n",
    "            vocab=vocab\n",
    "           )\n",
    "if use_cuda:\n",
    "    enc = enc.cuda()\n",
    "    \n",
    "    \n",
    "sample_num = 11\n",
    "print('sentences length: ', train_set_input_lens[0:sample_num])\n",
    "\n",
    "enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[0:sample_num]), \n",
    "                                    torch.LongTensor(train_set_input_lens[0:sample_num]))\n",
    "print('enc result size: ', enc_outputs.size(), enc_hn.size(), enc_cn.size())\n",
    "\n",
    "dec = Decoder(use_cuda=use_cuda, encoder=enc, hidden_dim=hidden_dim, max_length=25)\n",
    "if use_cuda:\n",
    "    dec = dec.cuda()\n",
    "    \n",
    "loss, predicts = dec(enc_outputs = enc_outputs, \n",
    "    h0_and_c0=(enc_hn, enc_cn), \n",
    "    sent_lens=train_set_input_lens[0:sample_num], \n",
    "    labels=torch.LongTensor(train_set_labels[0:sample_num]), \n",
    "    is_train=1, teaching_rate = 1, force_argmax=1)\n",
    "print('loss is %4.7f'%loss.data[0])\n",
    "# print(enc_outputs, enc_hn, enc_cn)\n",
    "#print(enc_hn, enc_cn)\n",
    "\n",
    "# pre_trained = torch.load('./models_saved/dec-loss-8.221987724-bleu-0.0000-hidden_dim-256-input_dim-256-lr-0.0050') \n",
    "# dec.load_state_dict(pre_trained)\n",
    "\n",
    "# pre_trained = torch.load('./models_saved/enc-loss-8.221987724-blue-0.0000-hidden_dim-256-input_dim-256-lr-0.0050') \n",
    "# enc.load_state_dict(pre_trained)\n",
    "\n",
    "# enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[0:sample_num]), \n",
    "#                                     torch.LongTensor(train_set_input_lens[0:sample_num]))\n",
    "# dec(enc_outputs = enc_outputs, \n",
    "#     h0_and_c0=(enc_hn, enc_cn), \n",
    "#     sent_lens=train_set_input_lens[0:sample_num], \n",
    "#     labels=torch.LongTensor(train_set_labels[0:sample_num]), \n",
    "#     is_train=1, teaching_rate = 1, force_argmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/hmx/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/data1/hmx/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:147: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_start_idx:  200041\n",
      "亲历下载速度排泄物vikram镰状小明下载速度排泄物排泄物聚居乱糟糟加多少愤青下载速度愤青有滋有味生个生个生个生个生个生个生个生个生个生个 end            尽管有这样的先见之明，但仍不足以令其免遭low_freq。\n",
      "亲历亲历下载速度下载速度下载速度下载速度愤青生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个 end            你已经low_freq了。\n",
      "亲历亲历打折打折打折下载速度osama有滋有味生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个 end            你看上去很low_freq。\n",
      "亲历亲历W打折打折打折不太熟亲历亲历流星雨圣克鲁兹说得够打折打折打折排泄物育婴室有滋有味生个生个生个生个生个生个生个生个 end            \"传你们来的？\"\"殿下是传我们来的。\n",
      "亲历亲历这样一来这样一来这样一来兼论13000放回拐弯粒度泪痕试播兼论这样一来这样一来亲历亲历之静美这样一来英国外交部小明大多数打折育婴室记性生个 end            这些系统和需求一起构成了集成场景，门户需要满足这些场景以向最终用户提供一个统一视图。\n",
      "亲历亲历亲历亲历排泄物排泄物凯特林佩琳打折兼论国民性亲历亲历亲历生个生个生个生个生个生个生个生个生个生个生个生个 end            有的时候，我们遭遇不幸我们需要悲伤一会。\n",
      "亲历亲历圣克鲁兹打折镰状圣克鲁兹下载速度打折圆屋顶挥挥手下载速度osama有滋有味生个生个生个生个生个生个生个生个生个生个生个生个生个 end            我知道，我明白。我很抱歉。\n",
      "亲历新闻频道排泄物亲历猎食干呕溯有滋有味生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个 end            一定是那块翡翠作怪\n",
      "亲历利比亚一尾打折一尾排泄物圆屋顶圣克鲁兹下载速度圆屋顶有滋有味生个生个生个生个生个生个生个生个生个生个生个生个生个生个生个 end            吃吧，今天会很忙。\n",
      "亲历亲历打折打折打折心无旁骛冻干冻干圣克鲁兹亲历下载速度圣克鲁兹圣克鲁兹打折红莲vikramvikram冻干记性生个生个生个生个生个生个生个 end            我觉得，我今晚就是该去那里。明白我的意思吗？\n",
      "0.0%(1/500000), loss: 11.499205589, bleu_score: 0.0000\n",
      "valid_start_idx:  200146\n",
      "我 end            把水位推高。\n",
      "我 end            多人low_freq战略，捍卫你的域名和备用对立派别low_freq。\n",
      "我 end            因为你是我的梦中情人，low_freq\n",
      "我 end            嗯，我得孵蛋。\n",
      "我 end            你们看到了吗？\n",
      "我 end            low_freq那家伙的头的时候，\n",
      "我 end            偷走所有美国制造的老爷车。\n",
      "我 end            有点类似，low_freq互相吸引。\n",
      "我 end            你的下一个任务在北非。\n",
      "我 end            你别说了行不？\n",
      "0.0%(101/500000), loss: 11.336358070, bleu_score: 0.0000\n",
      "valid_start_idx:  200153\n",
      "我 end            有点类似，low_freq互相吸引。\n",
      "我 end            你的下一个任务在北非。\n",
      "我 end            你别说了行不？\n",
      "我 end            我可以把您的包放到居室去了吗？\n",
      "我 end            好吧，好的，瞧。\n",
      "我 end            你知不知道抓到你你兄弟会给\n",
      "我 end            从今以后，你们要叫我齐尔格长官！\n",
      "我 end            哦，今天刚发。\n",
      "我 end            兄弟，我告诉你。\n",
      "我 end            你知道吗，我对你说的话是认真的。\n",
      "0.0%(201/500000), loss: 11.350864410, bleu_score: 0.0000\n",
      "valid_start_idx:  200004\n",
      "我 end            噢，是么？看着你，就是这样。\n",
      "我 end            这两种low_freq的价格令资本主义low_freq价格几乎是竞争low_freq的一半。\n",
      "我 end            呃，你不能用过度的暴力去保护宠物\n",
      "我 end            我们可以将礼品放在客厅的窗边。\n",
      "我 end            一起来看一下。\n",
      "我 end            出现轻微的骨质疏松。\n",
      "我 end            一旦天黑，他就成功了。\n",
      "我 end            就180号班机的爆炸成因...\n",
      "我 end            我们该这样吗？\n",
      "我 end            乔治城的low_freq先生说这反映了公众对已经开始在金家王朝low_freq的某人的认同。\n",
      "0.1%(301/500000), loss: 11.358386993, bleu_score: 0.0000\n",
      "valid_start_idx:  200153\n",
      "我 end            有点类似，low_freq互相吸引。\n",
      "我 end            你的下一个任务在北非。\n",
      "我 end            你别说了行不？\n",
      "我我 end            我可以把您的包放到居室去了吗？\n",
      "我 end            好吧，好的，瞧。\n",
      "我 end            你知不知道抓到你你兄弟会给\n",
      "我 end            从今以后，你们要叫我齐尔格长官！\n",
      "我 end            哦，今天刚发。\n",
      "我我 end            兄弟，我告诉你。\n",
      "我 end            你知道吗，我对你说的话是认真的。\n",
      "0.1%(401/500000), loss: 11.334943771, bleu_score: 0.0000\n",
      "valid_start_idx:  200146\n",
      "我我 end            把水位推高。\n",
      "我我我 end            多人low_freq战略，捍卫你的域名和备用对立派别low_freq。\n",
      "我我我我我我 end            因为你是我的梦中情人，low_freq\n",
      "我我我我我 end            嗯，我得孵蛋。\n",
      "我我我 end            你们看到了吗？\n",
      "我我我我 end            low_freq那家伙的头的时候，\n",
      "我我 end            偷走所有美国制造的老爷车。\n",
      "我我 end            有点类似，low_freq互相吸引。\n",
      "我我我 end            你的下一个任务在北非。\n",
      "我我我 end            你别说了行不？\n",
      "0.1%(501/500000), loss: 11.337005615, bleu_score: 0.0000\n",
      "valid_start_idx:  200053\n",
      "我我 end            它们还注意到了一个初露头角的机遇：与中国集团联手，投标世界各地的高铁项目从美国加州到俄罗斯\n",
      "我 end            他一个low_freq内干什么？\n",
      "我我我我我我我我我我 end            我喜欢一周low_freq这部剧，但我却真的不知道这个人到底是什么样的。\n",
      "我我我 end            你记得我们的上次在长城的拍摄吗？\n",
      "我我我 end            好。我们可以送她上下班加强巡逻。\n",
      "我我我我我我我我 end            在我看来，让他们见面只会让瑞恩斯更加烦乱而不是开口说话\n",
      "我我 end            现在24小时营业。\n",
      "我我我 end            否则我们再找你再在弄你一遍。\n",
      "我我我 end            她什么都可以得到手\n",
      "我我我 end            啊，欢迎回来！\n",
      "0.1%(601/500000), loss: 11.344221115, bleu_score: 0.0000\n",
      "valid_start_idx:  200161\n",
      "我我我我 end            兄弟，我告诉你。\n",
      "我我我我我我我我我 end            你知道吗，我对你说的话是认真的。\n",
      "我我 end            我们将接受你永恒的使命。\n",
      "我我我我 end            她们可去的地方，和她们可以找的人还有足够的钱吃饭和坐车。\n",
      "我我我我 end            low_freq回声，探测器...\n",
      "我我我我我 end            什么是我最健康的习惯？\n",
      "我我我我我 end            不过，我到没有因此消沉。\n",
      "我 end            只是把一些截止到上世纪的东西清除掉。\n",
      "我我我我我我我 end            充满了淡淡的甜味。我快要吐了。\n",
      "我我我 end            最后，李维先生表示，谷歌的“把更多木头安在更少的箭头后面”的战略事实上已经变成了\n",
      "0.1%(701/500000), loss: 11.352558136, bleu_score: 0.0000\n",
      "valid_start_idx:  200000\n",
      "我我我 end            不，他能把医院的手续low_freq\n",
      "我我 end            当然这玩意儿包含铅涂料还有毒，\n",
      "我我我 end            不，他不在，\n",
      "我我我 end            我从没去过学校的舞会，如果你指的是这个。\n",
      "我我我我我 end            噢，是么？看着你，就是这样。\n",
      "我 end            这两种low_freq的价格令资本主义low_freq价格几乎是竞争low_freq的一半。\n",
      "我我我我 end            呃，你不能用过度的暴力去保护宠物\n",
      "我我 end            我们可以将礼品放在客厅的窗边。\n",
      "我 end            一起来看一下。\n",
      "我我 end            出现轻微的骨质疏松。\n",
      "0.2%(801/500000), loss: 11.326128006, bleu_score: 0.0000\n",
      "valid_start_idx:  200099\n",
      "我我我我我我我 end            既然你不看警察了为什么你还帮我看？\n",
      "我我我我我我我我我我我 end            他们一般不把异国同盟放在眼里，这个我承认。\n",
      "我我 end            赴镇途中low_freq而卒。\n",
      "我我我我我我我我我我我 end            好，你们有一个月教他工作，否则我自己把他卖掉，\n",
      "我我我 end            我叫弗雷德里克。\n",
      "我 end            他妈的，没错\n",
      "我我我 end            家住low_freq社区的何阿婆孙女要上学，清晨low_freq，何阿婆像往常一样早早起床，用高压锅给孩子\n",
      "我我我 end            你现在谈恋爱会不会太早了点？不会。\n",
      "我我 end            它可以在天空中盘旋数小时，甚至可以利用传感器追踪移动目标。\n",
      "我我我我我我我我我我 end            今天之后，你我心照不宣别让我问你何出此言。\n",
      "0.2%(901/500000), loss: 11.341408730, bleu_score: 0.0000\n",
      "valid_start_idx:  200062\n",
      "我我我 end            啊，欢迎回来！\n",
      "我我我 end            我的收获可不止报仇这么简单。\n",
      "我我我我我 end            根据越南欧洲low_freqalainlow_freq和出口顾问jeanmichellow_freq的说法，法国商人在90年代就进入了越南，\n",
      "我我我我我 end            他们是唯一知道怎么应对的人。\n",
      "我我我 end            哪怕是在形势最好的时候，这种平衡也难以捕捉。\n",
      "我我 end            如果有办法阻止那帮人，我们就应该行动。\n",
      "我 end            他说得对你应该告诉大家。\n",
      "我我我我我我我 end            关键是，那晚我真的很害怕。\n",
      "我 end            他还是活蹦乱跳？\n",
      "我我 end            妈呀这丫头知道怎么用她的屁屁喝彩。\n",
      "0.2%(1001/500000), loss: 11.351233482, bleu_score: 0.0000\n",
      "valid_start_idx:  200197\n",
      "我我 end            反对者认为这肮脏能源命题抗议瓦莱罗加油站加州地球日。\n",
      "我我我 end            你父亲会遭遇的厄运吗？\n",
      "我我我 end            但是除了公共卫生、高架水渠和道路low_freqlow_freqlow_freqmorelow_freqfromlow_freqlow_freqlow_freq\n",
      "我我我我我我 end            嗨，姑娘们。点到点的开心时段！\n",
      "我我我我我我 end            嗨，拜。你都这么想了。我只是说说。\n",
      "我 end            更像一条到处蜕皮的蛇。\n",
      "我我 end            我想是直到受到诅咒。\n",
      "我我我我 end            专利专家米勒（low_freqlow_freq）认为，就连专利官司的和解也有可能变得更加困难。\n",
      "我 end            句号，玩儿完了，但是新闻不会死亡。\n",
      "我我我我我我 end            你要把你剩下唯一值钱的东西浪费在这个low_freq不停车的偏僻小镇吗？\n",
      "0.2%(1101/500000), loss: 11.326972961, bleu_score: 0.0000\n",
      "valid_start_idx:  200091\n",
      "我我我我我我 end            你又说让我帮你。\n",
      "我我我我 end            把他们从中国偷渡出来很简单\n",
      "我 end            哦，没错。尤其是在荷兰这个国家，如果可能的话，每个人都会骑自行车代步的。\n",
      "我我我我我我我我 end            你看，小low_freq，我仔细想过了。\n",
      "我我我我我 end            呆这儿，我马上回来。\n",
      "我我 end            受理查德·瓦格纳的歌剧启发，\n",
      "我我 end            至于别人，都算不了什么。\n",
      "我 end            他在做什么？我不知道，你在做什么，马克斯？\n",
      "我我我我我我我 end            既然你不看警察了为什么你还帮我看？\n",
      "我我我我我我我我我我我 end            他们一般不把异国同盟放在眼里，这个我承认。\n",
      "0.2%(1201/500000), loss: 11.326612473, bleu_score: 0.0000\n",
      "valid_start_idx:  200004\n",
      "我我我我我 end            噢，是么？看着你，就是这样。\n",
      "我 end            这两种low_freq的价格令资本主义low_freq价格几乎是竞争low_freq的一半。\n",
      "我我我我 end            呃，你不能用过度的暴力去保护宠物\n",
      "我我 end            我们可以将礼品放在客厅的窗边。\n",
      "我 end            一起来看一下。\n",
      "我我我 end            出现轻微的骨质疏松。\n",
      "我我我我 end            一旦天黑，他就成功了。\n",
      "我我我我 end            就180号班机的爆炸成因...\n",
      "我我我 end            我们该这样吗？\n",
      "我我我我我我 end            乔治城的low_freq先生说这反映了公众对已经开始在金家王朝low_freq的某人的认同。\n",
      "0.3%(1301/500000), loss: 11.340517044, bleu_score: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-15122632b3b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[start_idx:start_idx+batch_size]), \n\u001b[0;32m---> 19\u001b[0;31m                                         torch.LongTensor(train_set_input_lens[start_idx:start_idx+batch_size]))\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     loss, predicts = dec(enc_outputs, h0_and_c0=(enc_hn, enc_cn), \n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-9d443c3a3168>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, inputs_len)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_order_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device, async)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=0.005\n",
    "\n",
    "epochs=500000\n",
    "start_idx=0\n",
    "batch_size=150\n",
    "train_set_size=int(len(train_set_inputs)/40000)\n",
    "\n",
    "model_paras = list(dec.parameters())+list(enc.parameters())\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_paras), lr=lr)#optimizer for epoch in range(epochs):\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #print(epoch)\n",
    "\n",
    "    optimizer.zero_grad()#clear\n",
    "\n",
    "    enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[start_idx:start_idx+batch_size]), \n",
    "                                        torch.LongTensor(train_set_input_lens[start_idx:start_idx+batch_size]))\n",
    "\n",
    "    loss, predicts = dec(enc_outputs, h0_and_c0=(enc_hn, enc_cn), \n",
    "               sent_lens = train_set_input_lens[start_idx:start_idx+batch_size],\n",
    "               labels=torch.LongTensor(train_set_labels[start_idx:start_idx+batch_size]), \n",
    "               teaching_rate=1,\n",
    "               is_train=1,\n",
    "               force_argmax = 1)\n",
    "    #optimize\n",
    "    loss.backward()#retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    start_idx=200000+epoch*batch_size%(train_set_size-batch_size-1)    # samples change\n",
    "\n",
    "    \n",
    "    valid_batch_size=10\n",
    "    valid_start_idx=200000+random.randint(0, train_set_size-valid_batch_size-1)\n",
    "    if random.random()<0.5:\n",
    "        valid_start_idx=random.randint(0, len(train_set_inputs)-1-valid_batch_size-1)\n",
    "    valid_start_idx=200000+random.randint(0, train_set_size-valid_batch_size-1)\n",
    "    \n",
    "    if epoch%100 == 1:\n",
    "        \n",
    "        enc.eval()\n",
    "        dec.eval()\n",
    "        enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[valid_start_idx:valid_start_idx+valid_batch_size]), \n",
    "                                        torch.LongTensor(train_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size]))\n",
    "\n",
    "        loss_, predicts = dec(enc_outputs, \n",
    "                       sent_lens = train_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size],\n",
    "                       h0_and_c0=(enc_hn, enc_cn), \n",
    "                       labels=torch.LongTensor(train_set_labels[valid_start_idx:valid_start_idx+valid_batch_size]),\n",
    "                       is_train=1,\n",
    "                       teaching_rate=1,\n",
    "                       force_argmax=1)\n",
    "        del loss_\n",
    "\n",
    "        tokenized_sents=predicts.tolist()\n",
    "        real_sents=[]\n",
    "        label_tokenized_sents=train_set_labels[valid_start_idx:valid_start_idx+valid_batch_size]\n",
    "        label_real_sents=[]\n",
    "        for idx, sent in enumerate(tokenized_sents):\n",
    "            real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "        for sent in label_tokenized_sents:\n",
    "            label_real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "        print('valid_start_idx: ', valid_start_idx)\n",
    "        for (real_sent, label_real_sent) in zip(real_sents, label_real_sents):\n",
    "            print(real_sent, 'end           ', label_real_sent)\n",
    "        \n",
    "        \n",
    "        bleu_score = 0\n",
    "        #valid\n",
    "        if epoch%4000==1:\n",
    "            valid_rand_idx=random.randint(0, len(valid_set_inputs)-batch_size-1-1)\n",
    "            enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(valid_set_inputs[valid_rand_idx:valid_rand_idx+batch_size]), \n",
    "                                            torch.LongTensor(valid_set_input_lens[valid_rand_idx:valid_rand_idx+batch_size]))\n",
    "\n",
    "            predicts = dec(enc_outputs, \n",
    "                           sent_lens = valid_set_input_lens[valid_rand_idx:valid_rand_idx+batch_size],\n",
    "                           h0_and_c0=(enc_hn, enc_cn), \n",
    "                           labels=torch.LongTensor([0]), \n",
    "                           is_train=0,\n",
    "                           teaching_rate=1,\n",
    "                           force_argmax=1)\n",
    "\n",
    "            tokenized_sents=predicts.tolist()\n",
    "            real_sents=[]\n",
    "            label_tokenized_sents=valid_set_labels[valid_rand_idx:valid_rand_idx+batch_size]\n",
    "            label_real_sents=[]\n",
    "            for sent in tokenized_sents:\n",
    "                real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "                #real_sents.append(reverse_tokenized_sent2real_sent(sent, enc.vocab))\n",
    "            for sent in label_tokenized_sents:\n",
    "                label_real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "                #label_real_sents.append(reverse_tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "            bleu_sum, valid_num = data_set_bleu(label_real_sents, real_sents)\n",
    "            if valid_num>10:\n",
    "                bleu_score = bleu_sum/valid_num\n",
    "            else:\n",
    "                bleu_score = 999\n",
    "            #sava\n",
    "            torch.save(enc.state_dict(), \n",
    "                    './models_saved/enc-loss-{:2.9f}-blue-{:1.4f}-hidden_dim-{:n}-input_dim-{:n}-lr-{:1.4f}'.format(\n",
    "                          loss.data[0], bleu_score, hidden_dim, input_dim, lr))\n",
    "            torch.save(dec.state_dict(),\n",
    "            './models_saved/dec-loss-{:2.9f}-bleu-{:1.4f}-hidden_dim-{:n}-input_dim-{:n}-lr-{:1.4f}'.format(\n",
    "                    loss.data[0], bleu_score, hidden_dim, input_dim, lr))\n",
    "\n",
    "        print('%2.1f%%(%s/%s), loss: %2.9f, bleu_score: %1.4f'%(epoch*100/epochs, epoch, epochs, loss.data[0], bleu_score))\n",
    "        \n",
    "        enc.train()\n",
    "        dec.train()\n",
    "        \n",
    "print('running time: %.2f mins'%((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 8.243618965\n"
     ]
    }
   ],
   "source": [
    "stop_this_cell\n",
    "\n",
    "#print('running time: %.2f mins'%((time.time()-start_time)/60))\n",
    "#sava\n",
    "torch.save(enc.state_dict(), \n",
    "        './models/enc-loss-{:2.9f}-blue-{:1.4f}-hidden_dim-{:n}-input_dim-{:n}-lr-{:1.4f}'.format(\n",
    "              loss.data[0], bleu_score, hidden_dim, input_dim, lr))\n",
    "torch.save(dec.state_dict(),\n",
    "'./models/dec-loss-{:2.9f}-bleu-{:1.4f}-hidden_dim-{:n}-input_dim-{:n}-lr-{:1.4f}'.format(\n",
    "        loss.data[0], bleu_score, hidden_dim, input_dim, lr))\n",
    "#a little ok: dec-loss-8.243618965-bleu-0.0000-hidden_dim-256-input_dim-256-lr-0.0050 and enc-......\n",
    "#results： for example：\n",
    "# 我对我们一上，上一里里不对里。             全给我吃完，地上一粒米也不许剩。\n",
    "# 有能和我，我能对。她这里。              喝得烂醉；我只能把她赶出去。 \n",
    "# 了，这是吗？。 是的。对吗。              是这样吗？ 是的。随便啦。 \n",
    "# 是你的！是！！来！！来！来！来！              你喝的都是自来水！去找饮用水来！ \n",
    "# 以他以不是这里的。              他以前不是那样的。 \n",
    "#\n",
    "print('loss: %2.9f'%loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 512]) torch.Size([11, 512])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'tuple' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0807b824b17a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tuple' and 'tuple'"
     ]
    }
   ],
   "source": [
    "a=enc_hn.size()\n",
    "b=torch.zeros(a)\n",
    "print(a, b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             科伊内说，在谷歌，每个人都觉得自己几乎无时无刻不在赢；来自这样的谷歌，\n",
      "，的的的的。。             埋在车屋边空地上。\n",
      "，，，，，，，，，，的的的。。             听着，是谁给你权力接管我生活的？\n",
      "我我我的我的。。             我看你是没啥价值。\n",
      "，，，，，的的的的。。             带着假消息的假的背叛者呢？\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             传统的体育学习评价只是为了把学生分成三六九等，注重选拔与甄别功能，客观\n",
      "我我，我，我的我的我的的。。。             我是觉得他们觉得你警察味略重。 \n",
      "，，，，，，，的的的的。。             是，今天玩得很高兴的那种。 \n",
      "我我我我我的的。。             我不能让你看账单。 \n",
      "，，，，，，，，，的的的。。             小红帽，不要，小红帽！是我啊 \n",
      "，，，，，的的。。             好吧，船长。好吧。 \n",
      "我，我的我的的。。。             想想你选择的每个行动 \n",
      "我我我的我的的。。             我们被遗忘在这里。 \n",
      "我我我的我的的。。             我到现在还了解她。 \n",
      "我，我我的我的我的我的的。。             我也会回敬他，我们是一国的。 \n",
      "我我，我的我的我的的。。             我渴望将要到来的节假日， \n",
      "我，我，我，我的的的。。             如果你不了解我的所作所为… \n",
      "，，，，，的的的的。。             如果他这么需要钱来保释， \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的的。。             每一员工都是美容院的骄傲和依靠，而美容院是他们温馨的家，他们引以为荣。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，的的的的。。             金田一耕助在进入政界前是一位著名的社会运动家，而且是前卫生部长。\n",
      "，，，，，，，，的的的。。             华女，喜欢吃什么你自己选吧 \n",
      "，，的的的。。             在比赛的现阶段。\n",
      "我，，我的的的。。             她总会买一些东西， \n",
      "，，，，，，的的的。。             什么？你和他们一起的？ \n",
      "我我我我我我的的。。             我知道接下去怎么做。 \n",
      "，，，，，，，的的的的的。。             一有困难，你们就拍屁股走人啊？\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的。。             初中，某数学老师讲方程式变换，在讲台上袖子一挽大声喝道：同学们注意，我\n",
      "我我，我的我的我的的的。。             我别无选择只能向董事会建议 \n",
      "，，，，，，，，，，，，的的的的的的。。             想到这些马尼勋爵夫妇所使用的房间用来招待 \n",
      "我我我，我的我的的。。             我来决定是谁。你走开。 \n",
      "，，，，，，，，，，，，的的的的的的的。。             如果它们想要有得吃，它们就需要为之付出努力。 \n",
      "我，我的我的的的。。             我喜欢她眼睛的光彩。\n",
      "，，，，的的。。             好，我们没有订婚。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的的的。。             他也不是一点也不情愿出卖他自己；霍尔顿将软弱和自我憎恨巧妙地表现在角色\n",
      "，，，，，的的的的。。             两小时做的都不过如此， \n",
      "我我我我的的。。             你对我动了真情。 \n",
      "的的。。             或者特工？\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             电影剧本的形式与传统小说有很大区别，对新人来说很难要求他们回馈有用的信\n",
      "，我的我的的。。             你一定会爱上它的。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，的的的的的的的的。。             其二是赋予监管者自由裁量权，将银行债务存量的一部分转变为股权，即所谓的\n",
      "，，，，，，，，，，，，，，的的的。。             嗯，你告诉你的巴西朋友要是他们想一起搞，\n",
      "，，的的的。。             因为她身上比较粘。\n",
      "，，，，，的的的。。             商学院里的每门课你都上？\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             如果某个非洲政府将中国拥有的矿藏国有化，或缅甸的某个民主政府否认它们的\n",
      "，，我，，，，我的的我的的的的的。。             像这种时候我都开放我的思维。让其自由。 \n",
      "，，，，，，，的的的的的的。。             你应该把意大利面再多煮0分钟的。\n",
      "我我我我我我我的我的我的。。。             我妈现在想让我去看精神病医生。 \n",
      "我我我的我的我的的。。             我女儿为了你冒很大的险 \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的。。。             他们会说，不，美国人可以做出那些事，他们已经做了啊，可他们同时还假惺惺\n",
      "我我我，我我，我，我的我的我的。。。             我知道今天才号，可要么提前拆礼物…… \n",
      "，，，，的的。。             看，尽可能清除了，\n",
      "，，我的的的的。。             但当你真正去演绎时 \n",
      "，，，的的的。。             今天已经来不及了。 \n",
      "，，，，，，，，，，，的的的的的的的的的的。。             他是被混混杀死的，他们把罪推到她身上，是不是？ \n",
      "，，，，，，的的的的的。。             产于马来半岛和苏门答腊岛的low_freq。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             因此，“按顺序列单”成为早期娱乐最流行的一种形式，险胜成年割礼。\n",
      "，，，，，的的的的。。             房间太小。等在外面好了。 \n",
      "，，，，，，的的的。。             阿威克，我们不会伤害你的。\n",
      "我，我我的我的我的的。。             我听说你们现在有两个人了。\n",
      "，，，，，，，，，，，，，，，，，，，，，的，，的的的的的的的。。             而对于那些不支持我的美国人我可能还没有赢得你们的选票，但是我听到了你们\n",
      "，，，，，，，的的的。。             开始吧，我已经迫不待及了。\n",
      "我，，，的的的的。。             或谎言或其他什么把戏，\n",
      "，，，，，，，，，的的的的的。。             一般植发手术会先检查你的毛囊状况。\n",
      "我，我的，，，的的的的的的的的的的。。             我是在忙着其他的事。但你可以拖住他们啊 \n",
      "，，，，，，的的的。。             好了，进去拿着气球没？ \n",
      "，，的的。。             别用那种眼神看我\n",
      "我，，我，，我的的的。。             你干嘛提着裙子跑来跑去？ \n",
      "我的我的。。             他们得铐着你。\n",
      "，，，，的的的的的。。。             把这些薯片当作卡科日亚。 \n",
      "，，，，，，，，，，，，，，的的的的。。             心悸是一种心脏跳动的感觉好像你的心在奔跑。\n",
      "，，，，，的的的的。。             准备好，各位，伽马队形。 \n",
      "我，我的我的的。。             我只是一节老树桩。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             如果这个行业的内部人士能从中获取如此高的收益，那能给这些顾客们留下点什\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             租地权至少自中世纪以来就在欧洲广泛存在，租地权周期普遍适用于公民私有财\n",
      "我，我的我的的。。。             我可能有点神经衰弱。 \n",
      "，，，的的的的。。。             原来有一只母印度豹。 \n",
      "，，，，，的的的。。。             很快大家都加入了游戏。 \n",
      "，，，，，，，，，，，的的的。。             嗯，但你可能不知道当你得水痘时， \n",
      "，，，，，，，，，，的的的。。             带回了，他说没有一张是要找的证人。\n",
      "我，我的我的我的的的。。。             我被书中的内容吸引住了   \n",
      "我我，我我我的。。。             去告诉我们的兄弟…… \n",
      "，，，，，，，，，，，的的的。。             天哪。撞了人就逃走，这还是人吗？ \n",
      "，，，，，，，，，，，，，的的的的。。             正言汇社就长远的社会福利规划提交的意见书。\n",
      "，，，，，的的的的。。             品客薯片的罐子，不过继续。\n",
      "我，我，，，，的的的。。             天啊！你们看。我有照片。 \n",
      "，，，，，的的的的。。             客房提供高速互联网接入， \n",
      "，，的的的。。             整个房子空空如也 \n",
      "我我，我的，我的的的的的。。             我是说在我到岁的时候会喜欢。 \n",
      "我，我，我，我的我的的。。             想想彗星再想想她离你多近， \n",
      "，，，，，，，，，，，，的的。。             开头有点走调但你知道我最欣赏什么吗？\n",
      "，，，，，，，，，，的的的的的的的的。。             他对那些宣称控枪措施违反宪法的人斥之以鼻。\n",
      "，，，，，，，，，，，，，的的的的。。             好极了。他怎么改变主意了？是行为分析组。\n",
      "，，，，，，的的的的的。。             每次见到她，都发觉她愈发动人。\n",
      "，我，我，，我的，我的，我的的的的的的。。             在我看来你们都是同一类人，但我确定那不是你。\n",
      "，，，，，，，，的的的的的的的。。             一种由砷酸铜和醋酸铜形成的有毒复盐。\n",
      "，，，，，，，，的的的。。             就在今天我们消灭了一位暴君。\n",
      "，，，，，，，的的的的的的。。。             哪怕你只是那么一瞬间怒气爆发了… \n",
      "，，，，，，，，，，，，的的的的的。。。             感谢科波之主，看到你们我们终于舒了口气。 \n",
      "，，，，，，，，，，，的的的的的的的。。             他研究了地图，试图记住到罗丝家那条街的路。\n",
      "，，，，的的的。。             总要问一个“如果？ \n",
      "，，，，的的的的。。             地球，战争开始之前。 \n",
      "，，，，，，，，，，的的的的。。             当然，你后来头晕眼花的还胃痉挛了。\n",
      "我，我，我，，，我的我的我的的的。。             在我们到餐馆前你得让你的鸭子们排好队。\n",
      "我我我的的。。             我可以去个地方。\n",
      "我，我我，我，我的我的我的的。。             我们第二天下午飞回休斯顿，当…… \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的。。             晚上点，他驱车前往位于纽约第六大道与街交界处的 办公室，签署最后协议。\n",
      "，，，，，，，，，，，，，的的的。。             什么，你认为你在这里很安全吗？好吧。 \n",
      "我，我，我，我，我的我的我的的的的。。             在我看来你最不需要的就是多一张嘴吃饭。 \n",
      "，我的的。。             如果还招架不住 \n",
      "我我我我我我我我的的。。             我记得你告诉过我要提前考虑\n",
      "，，，，，，，，，，的的的的的的的的的。。             如果这句话能从我们赞助商口中说出那会更有趣。 \n",
      "，，，，，，，，，的的的的。。             如果一路绿灯的话我们什么都能做到。\n",
      "，，，，，，，，，，的的的。。             嘿，茜茜莉？我不知道该怎么办！ \n",
      "我我，我我，我的我的的。。             把我爸的事告诉他们真不容易。\n",
      "，，，，，，的的的。。             不过，爹真的下不了手。 \n",
      "我，我我，我我的我的我的的。。             你说我们没有足够的共同起诉案， \n",
      "，，，，，的的的的。。             天神真的拥有千里眼么？ \n",
      "，，，，，，，，，，，，，，，，，，，，，的的的的的的的的。。             这项研究令我颇感兴趣的是，它揭示记忆力具有有限性质所采用的方式。\n",
      "我，，我的的的的的。。             你当然可以和别人调调情。\n",
      "，，，，，，的的的。。             个人气象服务台，您好。 \n",
      "我我的我的的。。             但我们无家可归。 \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             凯西带艾凡去看葛斯特夫医生。医生问了艾凡几个问题并检查他的身体。 \n",
      "，，，，，，，，，，的的的的的。。             带上盖世群音到我们礼堂来周五三点整。 \n",
      "我，我，我的我的的的。。             我觉得他的计划跟机械有关 \n",
      "我我的我的我的的。。             我的小儿子得了鹅口疮。\n",
      "，，，的。。             嗯……说吧。 \n",
      "，，，，，，，，，，，，的的的的的。。             她的政治生涯到此为止但是应该不会坐牢。 \n",
      "，，，，的的的。。             找到了什么？是的。 \n",
      "我我，我的我的的。。             我们是纽约警察，别动！\n",
      "我，我，，我的，我的的的的。。             当年我红的时候你一直在沾我光！ \n",
      "，，，，，，，，，，，，，，，的的的的的的。。             把孩子送出去的人是啊？我知道。我正打算这么做呢。\n",
      "，，，，，，，，，，，，，，，的的的。。             好吧，那么，我想理清楚你征用了平民的车辆，\n",
      "的。。             空间 感觉\n",
      "，我，我，我的的的。。             你受伤了么，中枪了么？ \n",
      "，，，，，，，，，，，，，，的的的的的的。。             与此记录相关的测试结果保存在其他六个硬盘中。 \n",
      "我的的。。             你的手真稳。\n",
      "，，，，，，，，，，，，，，，，的的的的。。             当龙卷风把拖车卷起，抛向一间孤儿院这样叫邪恶吗？\n",
      "，，的的的的。。             像一只小金丝雀。 \n",
      "，，，，，，，，，，，的的的的。。             ' 不管到天涯海角我永远为你祈祷' ，\n",
      "，，，，，，，，，，的的的的的。。             从产品零件图看出只需要一次不变薄拉伸。\n",
      "我我我的的。。             我比你年轻多了 \n",
      "，，，，，，，的的的的的的的的。。             有没有可能我能加入你们和你们结盟？ \n",
      "我我，我我，我，我，我的我的我的我的的的。。             你就不能让我像个流浪汉那样进去只甩下0块钱。 \n",
      "，，，，，，，的的的。。             嘿，小心点。你，小声点。 \n",
      "我，我，我的我的我的我的的。。             我把我的书拿出来。好。嗯。好了。\n",
      "，，，的的的。。             今晚会有两人离开。 \n",
      "我我，我我的我的我的的。。             我买了一个新闹钟，你知道。 \n",
      "，，，，的的的的。。             是一般情况下是美元， \n",
      "我，我，我，我，我的我的的。。             别他妈的这么对我，我没穿袜子。 \n",
      "，的的。。。             秘密总是会泄露 \n",
      "，，，，，，，，，的的的的。。             抱歉，法兰克，我没时间刮胡子。 \n",
      "，，我，我的的的的。。             所以你们要去清理现场？ \n",
      "我我我我的的。。             我们关不掉煤气！ \n",
      "我，，，，，，，，，，，的的的的的的的的的。。             你得接受人们需要自己照顾自己的现实你自己也是。 \n",
      "我，我，我，我的，我的的的。。             别以为我在说笑话。我是认真的。 \n",
      "，，，，，的的的。。             咬下去，然后说蛋黄酱是\n",
      "我，，我，我，我的，我的的的。。             如果你是想说太难了让我们别做梦了… \n",
      "，，，，，，，，的的的的的的。。             但是这些房子都不是热卖的物业对吧？\n",
      "，，，，的的的的。。             听证会的笔录 要公开？\n",
      "，我的的的。。             其实你一点都不牛 \n",
      "我的的。。             其实他是对的。\n",
      "，，，，的。。。             嘿！ 他咳嗽了。 \n",
      "我我，我，我，我的我的我的的。。             我们几个月前就想分开，但是我们的 \n",
      "，，，，的的的。。             现在 从他整体来看，\n",
      "，，，的的的。。             分区会让专家来处理。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的。。。             在几个海湾国家的援助下，也门总统阿里阿卜杜拉萨利赫获得了豁免权，允许暂\n",
      "，，，，的的的的。。。             第一个出口右转至  街。 \n",
      "，，，的的的的。。             对！对！蓝色运动裤！\n",
      "，，，，，的的的的的的的的。。             你的新主人们，赌一赌他们谁先死。\n",
      "，，，，我的的的。。             如果他离开就通知我们。 \n",
      "，，，，，，，的的的。。             几年之后，我们就可以回来。\n",
      "，，，，的的的的。。             或是阴囊海报之类的吗？\n",
      "我，，我的的的的。。             你们的行程一定很满。 \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的。。             杨肃斌：新员工必须掌握我们所称的三种语言：上帝的语言，人类的语言和机器\n",
      "，我，我的的的。。             你亲自看到了，西蒙 \n",
      "我，我我，我的我的我的的。。             我欠她一个人情她  你知道的。\n",
      "，，，，，的的的的。。             不是天空，我问的是艾克巴\n",
      "，，，，的的的的。。             这是一个重大的转折点。\n",
      "，，，，，，，，，，，，，，的的的的。。             昨天晚上我和他通了电话。他说他感觉好些了。\n",
      "我，我的的。。             但你要离开他了。 \n",
      "，我，我，，我的我的的的。。             你还没准备好吧，儿子，对吗？ \n",
      "我，我，我，我，我，，我的，我的我的我的的的的。。             所以我才叫你不要轻举妄动。他太年轻了不可能是疑犯。 \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，的的的的的的的的。。             对人权方面存在的这样那样的弊端和消极现象，中国政府一直认真努力加以克服\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的的。。             销售员第二个最强的武器是他们的交流方法，或者说他们如何与潜在的客户展开\n",
      "，，，，，，，，，的的的的。。             但是无论我怎么做，始终无法成功。\n",
      "，，，，，，，，的的的的的的。。             这将启用除了类监视以外的所有选项。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的的的。。             一个较为可靠的民意测验，材料评审委员会的最新数据显示新民主党支持率为%\n",
      "我我我我，我的我的我的我的的。。             我知道你的来意。你面临了大秘密， \n",
      "我，我，我，我的的。。             因为他们害怕。你害怕我？ \n",
      "，，，，，，的的的的的。。             犬类研究专家说事实不是这样的。\n",
      "我，我我，我的我的的。。             我们错过了时尚周又怎样。\n",
      "我，我，我，，，，，，，，，的的的的的的。。             我知道，宇宙一定要平衡。这种屁话我听多了。 \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，的的的的。。             虽然谈不上“即时”，但通过发现网站要比现在使用的爬虫方法更快。\n",
      "我，我，我的，我的的的的的的的的的。。。             我是洛城警局的副局长布兰达·雷·强生。 \n",
      "我，，的的的的的的。。             你以前住哪花花公子公馆。\n",
      "我，，，，，的的的。。             况且我一直就很想见你， \n",
      "，，，，，，的的的的的的的。。             但是幸存者们却困在了年的岛上， \n",
      "我我我我的。。             我说叫他们撤走。\n",
      "，，，，，，，，的的的的。。             臭味相投的人，例如达拉斯警方。\n",
      "，，，，的的的。。             有什么用呢什么用都有\n",
      "我，我，我的我的的的。。             你回去继续你的介绍会吧。 \n",
      "，，，的的的的。。             但是需要两个人合作。\n",
      "，，，，，，，，，的的的的。。             因此，就像蹦跳着走路一样轻快。 \n",
      "，，，，，，，，的的的的的的。。             想喝罐美味可乐吗？可乐很好喝的。 \n",
      "，，，，，，，，，的的的。。             到现在，我设法戒烟已快两年了。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             拉格泰姆节奏爵士乐的一种风格，特点是旋律中强切分音和伴奏中有规律的重音\n",
      "我，我，我，我，，我的我的我的的的。。             你就没想到她会采取行动做些什么？没有。 \n",
      "，我，我，我的的。。             不然我就用手铐抓她来。\n",
      "我我，我，我的我的我的的的。。             我想昆特洛和其他人现在都来这儿。\n",
      "，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             哈瓦那革命广场上，一个女人在观看和平无国界音乐会时翩翩起舞。\n",
      "，，，，，，，，，，，，，，，，，，，，，，的的的的的的。。             如果一家连月拖欠账单的小企业破产，其供应链上的所有企业都会遭殃。\n",
      "我，我，我，，我的的我的的的。。             你们0点就该来的，发生什么事了？ \n",
      "，，，，，，的的的的的。。             一切都已准备就绪。是，副官。\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的的的。。             这幅画描绘了宋朝首都low_freq京（即今天的开封）中人们的日常生活，主题侧重于渲\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的。。             党内许多人领导人都在推诿，认为努尔会赢得更大的影响力，今年早些时候，在\n",
      "我我的。。。             我明白我…  \n",
      "，，，，，，，，，，，，的的的的的。。             回到他身边去。把标记给我你就会长生不老。 \n",
      "我，我，我，我，我的我的我的的的。。             你现在不相信我了？无所谓了，我不在乎。\n",
      "，，，，，，，，，，，，，的的的的的。。             几小时以后她便抽出身来重新开始西行的旅程。\n",
      "，，的的的的。。             为了服部家的荣耀。\n",
      "我，我，我，我的的。。             快给我醒过来，快！拉升！\n",
      "我，我，，我，，我的的，我的的的的。。             他们一个字都没和我说我也没和他们说话。 \n",
      "，，我的的的。。             你可真是个坏女孩。\n",
      "，，的的的的的的。。             她的癫痫发作的很严重。\n",
      "我，我，我的我的我的的的。。             我们主要关心的是提高教育水平。\n",
      "，，，，，，，，的的的的的的的的。。             其中一切都来自基本原理和基本的物理学。 \n",
      "，，，，，，，，，，，，，，的的的。。             就跟下一个家伙一样棒。看，还是忘了她吧，\n",
      "，，，，的的的的。。             一波又一波从深海中升起\n",
      "我，我，我，，，，，我的我的的的。。             打给我的英语老师！ 为什么是英语老师？ \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             在美国建国初期，建造大坝是外来者定居美国的重要途径，他们可以在河流附近\n",
      "，，，，，，，，，的的的的的。。             上周我查看一个被关在笼子里的孩子 \n",
      "我，我，我的的。。。             所以我们要更深入调查。 \n",
      "我，，，我的的的的。。             你的未来命运是由不得你。\n",
      "，，，，，，，，，，，，，，，，的的的的的的的。。             为了将自己从这痛楚中解放出来我想要结束自己的生命。 \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的的。。             杰克是一个下身瘫痪的老兵,他被派往潘多拉星,操纵自己的阿凡达融入当地居\n",
      "，，，，，，，，，，，，，，的的的的。。             他们在世时望之俨然，但如今已少有人记得了。\n",
      "，，，，的的。。             当然不是，好吧。 \n",
      "我，，我的的的的。。             她来这里见某个小伙吗？\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             中国小贴士（  ）是一套系列导游书，适合那些既想避开游客泛滥的景点，但\n",
      "，，，的的的的。。             买这或那花了多少？ \n",
      "，，的的的的。。             上次说是第一首。 \n",
      "，，，，，的的的。。。             历史气息味道就像旧烟灰缸。 \n",
      "我，我的的。。             一秒也不想再看。\n",
      "我我我的我的的。。             我想确定你是否同意。\n",
      "，我，，我的的的。。。             但结果，我们选了名幸运女孩\n",
      "，，，，，，，，，，，，，，，，，，，，，的的的。。             稍微好点的餐馆难道会不知道每个人都会在感恩节吃南瓜派吗？\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             约翰逊是一个好学生，也是一名非常出色的运动员，他曾担任棒球队和足球队队\n",
      "我，我，我，我的我的我的的的。。             他说我只是有时运气好没有真才实料。\n",
      "，，，，，，的的的的的。。             不是正宗的前哥伦布时期文物。\n",
      "，的的。。             可怕的选择。\n",
      "我，我，我的我的我的我的的。。             我不知道哪样更糟，教堂还是监狱？\n",
      "，，，，，，，，，，，，，，的的的的的的。。             对于套标等包装原因出现的不合格品，挑出并返工。\n",
      "，，，，，，，，，，，，，，，，，，，，，的的的的的。。             对王刚的母亲来说，由于缺乏问责制度，安全问题还将继续存在。\n",
      "我，，，，，，的的的的的的。。             他在干什么，想换装混入人群吗？ \n",
      "，，，，的的的。。             当它问道“这是为什么\n",
      "，，，，，的的的的。。             当时不是用的这个能源。 \n",
      "我，我，我，，，，，，的的的的的的的的。。             我不喜欢有人派兵来统治我们，收我们的税， \n",
      "，，我的的的。。             为何你不把人数减到?\n",
      "，，，，，，，，，，，的的的。。             听啊。闭嘴。你们喝的可是我的啤酒。\n",
      "我我，我的我的的的。。             我可以同时看桑福德和… \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             如果您的目的地在这个范围之内，那么您就一定可以在这里找到您需要的那本旅\n",
      "，，，，的的的。。             贝丝昨天收到一封血书。\n",
      "我我我我的我的的。。             我能和其他谁谈谈么？ \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             如果一个发展中国家选择与其要素禀赋结构相一致的技术结构，那么这个发展中\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             马哈拉施特拉邦的人民正在寻求一位救星，而查万先生就是那唯一明智的人选。\n",
      "我，，，的的的的的。。             你下半生又会回到轮椅上？\n",
      "，，，，的的的的的。。             但是人类的血效果更好。 \n",
      "我，我的的。。             想叫你别来了。 \n",
      "我，我，我的的的的。。             我在场。看着他做的。 \n",
      "，，，，，，，，，，的的的的的。。             有过共同的麻烦和敌人而且远不止这些。\n",
      "的的。。             不是指控。\n",
      "，，，，，，，，的的的的的的的。。             中国还帮助巴基斯坦建造瓜达尔深海港口。\n",
      "，，，，，的的的的。。             像鲍翅那种菜我可不会做。 \n",
      "，，，的的的的。。             可是这真的很难想象。\n",
      "，，的的。。             五加五等於十。\n",
      "，的。。             帐怎么算呢？\n",
      "，，，，，，，，，，，，的的的。。             嘿女士，你为什么要这样对我们的车？ \n",
      "我，，我的的的的的的。。             她的火车没把她送到奥兰多。\n",
      "我的的。。。             哥哥照顾妹妹。 \n",
      "，，，的的的。。             砂粒把杠杆臂卡住了。\n",
      "我我，我，我，我，我的我的我的的的。。             我再想不出比你们更适合抚育孩子的夫妇了。\n",
      "，我我的我的。。             你拆了我的礼物没？\n",
      "，的的的的。。。             房间内提供免费报纸 \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的的。。             左派政党联盟的民粹主张，帮助它从曾经的默默无闻一跃成为希腊第二受欢迎的\n",
      "我，我，，，，，，，，，，的的的的的的的的。。             我现在没有温文尔雅的情绪，如果你受不了是你的事。\n",
      "，，，，，，，的的的。。             你总喜欢在背后说别人坏话？\n",
      "，，，的的的的。。。             家庭房中可提供沙发床。 \n",
      "，我的的的。。             你的光明必须照亮\n",
      "我我我的的。。             我不该信她的。 \n",
      "我的。。             给女人的爱\n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的的。。             为了保证顾客满意，亚利桑那州立大学会给学生发短信提醒他们的衣服已经洗干\n",
      "，，，，，，的的的的。。             必须协助我。这里不安全。 \n",
      "我，我，我的，我的我的的的。。             全给我吃完，地上一粒米也不许剩。\n",
      "，，，，，，，，的的的。。             喝得烂醉；我只能把她赶出去。 \n",
      "，，，，，的，的的的的。。             是这样吗？ 是的。随便啦。 \n",
      "我，，，，，，，，，的的的的。。             你喝的都是自来水！去找饮用水来！ \n",
      "我，，的的的的。。             他以前不是那样的。 \n",
      "，，，，，，，，，，，，，，，，，，，，，，，，，，，，的的的的。。             自然界锂同位素分馏强烈，这使得它在很多方面都得到了应用，如地球化学、天\n",
      "，，，，，，，，，，的的的的的的的。。             但如果让人觉得那是经常性的那我们就完了。 \n",
      "我，我的我的的。。             我从你家门前经过。 \n",
      "### ........................ ###\n",
      "### ........................ ###\n",
      "### ........................ ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/hmx/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/data1/hmx/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension specified as 0, but tensor has no dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7159ebb6b719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(valid_set_inputs[valid_start_idx:valid_start_idx+valid_batch_size]), \n\u001b[0;32m---> 41\u001b[0;31m                                 torch.LongTensor(valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size]))\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m predicts = dec(enc_outputs, \n",
      "\u001b[0;32m/data1/hmx/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-9212ee36d5af>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, inputs_len)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_order_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#         print(self.embed.weight.data[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-9212ee36d5af>\u001b[0m in \u001b[0;36morder\u001b[0;34m(self, inputs, inputs_len)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0minputs_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m#print(inputs.shape, sort_ids.shape, inputs_len.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension specified as 0, but tensor has no dimensions"
     ]
    }
   ],
   "source": [
    "valid_start_idx=600\n",
    "valid_batch_size=300\n",
    "\n",
    "dec.eval()\n",
    "enc.eval()\n",
    "enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(valid_set_inputs[valid_start_idx:valid_start_idx+valid_batch_size]), \n",
    "                                torch.LongTensor(valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size]))\n",
    "\n",
    "predicts = dec(enc_outputs, \n",
    "               sent_lens = valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size],\n",
    "               h0_and_c0=(enc_hn, enc_cn), \n",
    "               labels=torch.LongTensor([0]), \n",
    "               is_train=0,\n",
    "               teaching_rate=0,\n",
    "               force_argmax = 1)\n",
    "\n",
    "tokenized_sents=predicts.tolist()\n",
    "real_sents=[]\n",
    "label_tokenized_sents=valid_set_labels[valid_start_idx:valid_start_idx+valid_batch_size]\n",
    "label_real_sents=[]\n",
    "for sent in tokenized_sents:\n",
    "    real_sents.append(reverse_tokenized_sent2real_sent(sent, enc.vocab))\n",
    "for sent in label_tokenized_sents:\n",
    "    label_real_sents.append(reverse_tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "for (real_sent, label_real_sent) in zip(real_sents, label_real_sents):\n",
    "    print(real_sent, '           ', label_real_sent)\n",
    "    \n",
    "    \n",
    "print('### ........................ ###')\n",
    "print('### ........................ ###')\n",
    "print('### ........................ ###')\n",
    "\n",
    "\n",
    "valid_start_idx=620\n",
    "valid_batch_size=0\n",
    "\n",
    "dec.eval()\n",
    "enc.eval()\n",
    "enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(valid_set_inputs[valid_start_idx:valid_start_idx+valid_batch_size]), \n",
    "                                torch.LongTensor(valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size]))\n",
    "\n",
    "predicts = dec(enc_outputs, \n",
    "               sent_lens = valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size],\n",
    "               h0_and_c0=(enc_hn, enc_cn), \n",
    "               labels=torch.LongTensor([0]), \n",
    "               is_train=0,\n",
    "               teaching_rate=0,\n",
    "               force_argmax = 1)\n",
    "\n",
    "tokenized_sents=predicts.tolist()\n",
    "real_sents=[]\n",
    "label_tokenized_sents=valid_set_labels[valid_start_idx:valid_start_idx+valid_batch_size]\n",
    "label_real_sents=[]\n",
    "for sent in tokenized_sents:\n",
    "    real_sents.append(reverse_tokenized_sent2real_sent(sent, enc.vocab))\n",
    "for sent in label_tokenized_sents:\n",
    "    label_real_sents.append(reverse_tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "for (real_sent, label_real_sent) in zip(real_sents, label_real_sents):\n",
    "    print(real_sent, '           ', label_real_sent)\n",
    "    \n",
    "dec.train()\n",
    "enc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "a=filter(lambda p: p.requires_grad, model_paras)\n",
    "for idx, x in enumerate(a):\n",
    "    pass\n",
    "print(idx)\n",
    "for idx, x in enumerate(model_paras):\n",
    "    pass\n",
    "print(idx)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
