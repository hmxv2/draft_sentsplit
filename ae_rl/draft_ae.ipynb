{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import over\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import time\n",
    "\n",
    "from Vocab import Vocab\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "print('import over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenized_sent2real_sent(tokenized_sent, vocab):\n",
    "    real_sent=[]\n",
    "    for token in tokenized_sent:\n",
    "        if token == vocab.word2token['eos']:\n",
    "            break\n",
    "        else:\n",
    "            real_sent.append(vocab.token2word[token])\n",
    "    return ''.join(real_sent)\n",
    "\n",
    "def reverse_tokenized_sent2real_sent(tokenized_sent, vocab):\n",
    "    real_sent=[]\n",
    "    for token in tokenized_sent:\n",
    "        if token == vocab.word2token['eos']:\n",
    "            break\n",
    "        else:\n",
    "            real_sent.append(vocab.token2word[token])\n",
    "    real_sent.reverse()\n",
    "    return ''.join(real_sent)\n",
    "\n",
    "def data_set_bleu(sents1, sents2):\n",
    "    cnt=0\n",
    "    bleu_score_sum=0\n",
    "    \n",
    "    for sent1, sent2 in zip(sents1, sents2):\n",
    "        if min(len(sent1), len(sent2))<4:\n",
    "            pass\n",
    "        else:\n",
    "            cnt+=1\n",
    "            bleu_score_sum = sentence_bleu([list(sent1)], list(sent2))+bleu_score_sum\n",
    "            \n",
    "    return bleu_score_sum, cnt\n",
    "\n",
    "with open('vocab.pk', 'rb') as f:\n",
    "    vocab=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "公历纷繁复杂\n",
      "纷繁复杂公历mask\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_sent2real_sent([5,6,2,1,1], vocab))\n",
    "print(reverse_tokenized_sent2real_sent([4,5,6,2,1,1], vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data_set/train_set_inputs.pk', 'rb') as f:\n",
    "    train_set_inputs = pickle.load(f)\n",
    "with open('./data_set/train_set_input_lens.pk', 'rb') as f:\n",
    "    train_set_input_lens = pickle.load(f)\n",
    "with open('./data_set/train_set_labels.pk', 'rb') as f:\n",
    "    train_set_labels = pickle.load(f)\n",
    "    \n",
    "with open('./data_set/valid_set_inputs.pk', 'rb') as f:\n",
    "    valid_set_inputs = pickle.load(f)\n",
    "with open('./data_set/valid_set_input_lens.pk', 'rb') as f:\n",
    "    valid_set_input_lens = pickle.load(f)\n",
    "with open('./data_set/valid_set_labels.pk', 'rb') as f:\n",
    "    valid_set_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8697000 8697000 8697000 1185955 1185955 1185955\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set_inputs), len(train_set_input_lens), len(train_set_labels), \n",
    "      len(valid_set_input_lens), len(valid_set_inputs), len(valid_set_labels))\n",
    "\n",
    "for sent_len in valid_set_input_lens:\n",
    "    if sent_len<=2:\n",
    "        print('why')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, use_cuda, hidden_dim, input_dim, vocab):#, pre_train_weight, is_fix_word_vector = 1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.input_dim=input_dim\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.lstm=torch.nn.LSTM(input_size=self.input_dim, \n",
    "                                hidden_size= self.hidden_dim, \n",
    "                                bidirectional=True,\n",
    "                                batch_first=True\n",
    "                               )\n",
    "        \n",
    "        #embedding\n",
    "        self.embed=nn.Embedding(len(self.vocab.word2token), input_dim)\n",
    "        \n",
    "        with open('../pre_train_wordembedding/pre_train_word_embedding.pk', 'rb') as f:\n",
    "            pre_train_word_embedding = pickle.load(f)\n",
    "            \n",
    "        self.embed.weight.data.copy_(torch.FloatTensor(pre_train_word_embedding))\n",
    "        #self.embed.weight.requires_grad = False\n",
    "        \n",
    "#         self.fcnn1=nn.Linear(hidden_dim*2, hidden_dim)\n",
    "#         self.fcnn2=nn.Linear(hidden_dim, hidden_dim)\n",
    "#         self.activate_func=nn.ReLU()\n",
    "        \n",
    "#         self.loss_func = nn.MSELoss()\n",
    "        \n",
    "    def order(self, inputs, inputs_len):\n",
    "        \n",
    "        inputs_len, sort_ids = torch.sort(inputs_len, dim=0, descending=True)\n",
    "        #print(inputs.shape, sort_ids.shape, inputs_len.shape)\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            inputs = inputs.index_select(0, Variable(sort_ids).cuda())\n",
    "        else:\n",
    "            inputs = inputs.index_select(0, Variable(sort_ids))\n",
    "        \n",
    "        _, true_order_ids = torch.sort(sort_ids, dim=0, descending=False)\n",
    "        \n",
    "        return inputs, inputs_len, true_order_ids\n",
    "    #\n",
    "    def forward(self, inputs, inputs_len):\n",
    "        inputs = Variable(inputs)\n",
    "        if self.use_cuda:\n",
    "            inputs=inputs.cuda()\n",
    "            \n",
    "        inputs, sort_len, true_order_ids = self.order(inputs, inputs_len)\n",
    "\n",
    "#         print(self.embed.weight.data[0])\n",
    "#         self.embed.weight.data[0]=torch.LongTensor(([2]*400))\n",
    "#         print(self.embed.weight.data[0])\n",
    "#         print(self.embed.weight)\n",
    "        \n",
    "        #print('encoder lstm, inputs size:', inputs.size())\n",
    "        in_vec=self.embed(inputs)\n",
    "        #print('encoder lstm, in_vec size:', in_vec.size())\n",
    "        packed = rnn_utils.pack_padded_sequence(input=in_vec, lengths=list(sort_len), batch_first =True)\n",
    "        \n",
    "        outputs, (hn,cn) = self.lstm(packed)\n",
    "        outputs, sent_lens = rnn_utils.pad_packed_sequence(outputs)\n",
    "        \n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        \n",
    "        outputs = outputs.transpose(0,1)\n",
    "        #print(outputs)\n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            outputs = outputs.index_select(0, Variable(true_order_ids).cuda())\n",
    "        else:\n",
    "            outputs = outputs.index_select(0, Variable(true_order_ids))\n",
    "        \n",
    "        #print('outpurs size, hn size and cn size: ', outputs.size(), hn.size(), cn.size())\n",
    "        #\n",
    "        # warnning: hn and cn have not been sorted by sentences length so the order is wrong.\n",
    "        #\n",
    "        #print('hn and cn: ', hn, cn)\n",
    "        hn = torch.cat((hn[0], hn[1]), dim=1)\n",
    "        cn = torch.cat((cn[0], cn[1]), dim=1)\n",
    "        #print('hn size and cn size: ', hn.size(), cn.size())\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            hn = hn.index_select(0, Variable(true_order_ids).cuda())\n",
    "            cn = cn.index_select(0, Variable(true_order_ids).cuda())\n",
    "        else:\n",
    "            hn = hn.index_select(0, Variable(true_order_ids))\n",
    "            cn = cn.index_select(0, Variable(true_order_ids))\n",
    "            \n",
    "        #print('hn and cn: ', hn, cn)\n",
    "        \n",
    "#         print(outputs.size())\n",
    "#         print(hn.size())\n",
    "\n",
    "        return outputs, (hn,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, use_cuda, encoder, hidden_dim, max_length=25):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.use_cuda = use_cuda\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.input_dim = encoder.input_dim\n",
    "        self.max_length = max_length\n",
    "        self.vocab = encoder.vocab\n",
    "        self.weight = [1]*len(self.vocab.word2token)\n",
    "        self.weight[self.vocab.word2token['padding']]=0\n",
    "        #self.weight[self.vocab.word2token['eos']]=1.01\n",
    "        \n",
    "#         self.lstm=torch.nn.LSTM(input_size=self.input_dim, \n",
    "#                                 hidden_size= self.hidden_dim, \n",
    "#                                 bidirectional=True,\n",
    "#                                 batch_first=True\n",
    "#                                )\n",
    "        \n",
    "        self.lstm = torch.nn.LSTMCell(input_size=self.input_dim, hidden_size=self.hidden_dim*2, bias=True)\n",
    "        \n",
    "        #embedding\n",
    "        self.embed=encoder.embed# reference share\n",
    "        #softmax\n",
    "        self.fcnn = nn.Linear(in_features = self.hidden_dim*2, out_features = len(self.vocab.word2token))\n",
    "        \n",
    "#         with open('../pre_train_wordembedding/pre_train_word_embedding.pk', 'rb') as f:\n",
    "#             pre_train_word_embedding = pickle.load(f)\n",
    "#         self.fcnn.weight.data.copy_(torch.FloatTensor(pre_train_word_embedding))\n",
    "#         self.fcnn.weight.requires_grad = True\n",
    "#         #self.fcnn.bias.data.fill_(0.0)\n",
    "#         #self.fcnn.bias.requires_grad = True\n",
    "        \n",
    "#         self.transform = nn.Linear(in_features = self.hidden_dim*2, out_features = self.input_dim)\n",
    "#         #self.transform.bias.data.fill_(0.0)\n",
    "#         #self.transform.bias.requires_grad = False\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        self.cost_func = nn.CrossEntropyLoss(torch.Tensor(self.weight))\n",
    "        \n",
    "        print('init lookup embedding matrix size: ', self.embed.weight.data.size())\n",
    "        \n",
    "    def forward(self, enc_outputs, sent_lens, h0_and_c0, labels, teaching_rate=0.6, is_train=1, force_argmax=1):\n",
    "        labels = Variable(labels)\n",
    "        if self.use_cuda:\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "\n",
    "        all_loss = 0\n",
    "        predicts = []\n",
    "        batch_size = enc_outputs.size(dim = 0)\n",
    "\n",
    "        \n",
    "        #print('enc_outputs size: ', enc_outputs.size())\n",
    "#         for ii in range(batch_size):\n",
    "#             forward_result = enc_outputs[ii, sent_lens[ii]-1, :self.hidden_dim].unsqueeze(dim=0)\n",
    "#             reverse_result = enc_outputs[ii, 0, self.hidden_dim:].unsqueeze(dim=0)\n",
    "#             final_hidden_states[ii] = torch.cat([forward_result, reverse_result], dim = 1)   #so enc_outputs[ii, sent_lens[ii]-1, :] 's size: self.hidden_dim*2\n",
    "        \n",
    "#         #print('final_hidden_states[0] size', final_hidden_states[0].size())\n",
    "#         final_hidden_states = torch.cat(final_hidden_states, dim=0)\n",
    "        \n",
    "        #print('final_hidden_states size: ', final_hidden_states.size())\n",
    "        \n",
    "        final_hidden_states = h0_and_c0[0]\n",
    "        embed_weight = self.embed.weight\n",
    "        embed_weight_expand  =embed_weight.expand(batch_size, embed_weight.size(0), embed_weight.size(1))\n",
    "        \n",
    "        for ii in range(self.max_length+1):\n",
    "            if ii==0:\n",
    "                zero_timestep_input = torch.LongTensor([self.vocab.word2token['sos']]*batch_size)\n",
    "                zero_timestep_input = Variable(zero_timestep_input)\n",
    "                if self.use_cuda:\n",
    "                    zero_timestep_input = zero_timestep_input.cuda()\n",
    "                    \n",
    "                zero_timestep_input = self.embed(zero_timestep_input)#size: batch_size * self.input_dim\n",
    "\n",
    "                #print('zero_timestep_input size: ', zero_timestep_input.size())\n",
    "                \n",
    "                \n",
    "#                 h0 = Variable(torch.zeros((batch_size, self.hidden_dim*2)))\n",
    "#                 c0 = Variable(torch.zeros((batch_size, self.hidden_dim*2)))\n",
    "#                 if self.use_cuda:\n",
    "#                     h0 = h0.cuda()\n",
    "#                     c0 = c0.cuda()\n",
    "                    \n",
    "                #h0_and_c0=(h0,c0)\n",
    "                \n",
    "                #print('zero_timestep_input size: ', zero_timestep_input.size())\n",
    "                #print('final_hidden_states size: ', final_hidden_states.size())\n",
    "                \n",
    "                #last_timestep_hidden_state,cx = self.lstm(torch.cat([zero_timestep_input, final_hidden_states],dim=1), h0_and_c0)#h0 and c0\n",
    "                \n",
    "                last_timestep_hidden_state,cx = self.lstm(zero_timestep_input, h0_and_c0)\n",
    "                #print('hn and cn sizes: ', last_timestep_hidden_state.size(), cx.size())\n",
    "                \n",
    "                #last_timestep_hidden_state,cx = self.lstm(zero_timestep_input,(h0_and_c0[0]-h0_and_c0[0], h0_and_c0[1]-h0_and_c0[1]))\n",
    "                \n",
    "                #print(last_timestep_hidden_state.size(), type(hn), type(cn))\n",
    "                #last_timestep_output = self.softmax(self.fcnn(last_timestep_hidden_state))\n",
    "                last_timestep_output = self.fcnn(last_timestep_hidden_state)\n",
    "                \n",
    "                #print('last_timestep_hidden_state size: ', last_timestep_output.size(), 'last_timestep_output size: ', last_timestep_output.size())\n",
    "                if is_train:\n",
    "                    #print('last_timestep_output size: ', last_timestep_output.size(), labels[:,0].size())\n",
    "                    loss = self.cost_func(last_timestep_output, labels[:,0])\n",
    "                    #print('loss size: ', loss.size(), loss.data, torch.mean(loss).data)\n",
    "                    all_loss+=loss\n",
    "                #else:\n",
    "                #print(last_timestep_output.size())\n",
    "                #x=torch.squeeze(last_timestep_output, dim=1)\n",
    "                #print('x size: ', x.size())\n",
    "                _, max_idxs = torch.max(last_timestep_output, dim=1)\n",
    "                predicts.append(torch.unsqueeze(max_idxs, dim=0))\n",
    "                #print('max_idxs size: ',max_idxs.size(), max_idxs)\n",
    "                \n",
    "            else: # ii !=0\n",
    "                if is_train:\n",
    "                    rand = random.random()\n",
    "                    if rand<teaching_rate:\n",
    "                        #print('rand: ', rand)\n",
    "                        this_timestep_input = self.embed(labels[:,ii-1])#label teaching, lookup embedding\n",
    "                    elif force_argmax==1:\n",
    "                        this_timestep_input = self.embed(max_idxs)#last_timestep output, and then look up word embedding\n",
    "                    else:\n",
    "                        \n",
    "                        #print(embed_weight.size(), last_timestep_output.size())\n",
    "                        this_timestep_input = torch.bmm(last_timestep_output.unsqueeze(dim=1), \n",
    "                                                embed_weight_expand)#global embedding\n",
    "                        #print('block multi', this_timestep_input.size())\n",
    "                else:\n",
    "                    if force_argmax==1:\n",
    "                        this_timestep_input = self.embed(max_idxs)#last_timestep output, and then look up word embedding\n",
    "                    else:\n",
    "                        \n",
    "                        #print(embed_weight.size(), last_timestep_output.size())\n",
    "                        this_timestep_input = torch.bmm(last_timestep_output.unsqueeze(dim=1), \n",
    "                                                embed_weight_expand)#global embedding\n",
    "                        #print('block multi', this_timestep_input.size())\n",
    "                \n",
    "                \n",
    "                #print('this_timestep_input size: ', this_timestep_input.size())\n",
    "                #print('final_hidden_states size: ', final_hidden_states.size())\n",
    "#                 last_timestep_hidden_state ,cx = self.lstm(torch.cat([this_timestep_input.squeeze(dim=1), final_hidden_states],dim=1)\n",
    "#                                                            , (last_timestep_hidden_state,cx))\n",
    "\n",
    "                last_timestep_hidden_state ,cx = self.lstm(this_timestep_input, (last_timestep_hidden_state,cx))\n",
    "\n",
    "                #last_timestep_output = self.softmax(self.fcnn(last_timestep_hidden_state))\n",
    "                last_timestep_output = self.fcnn(last_timestep_hidden_state)\n",
    "                \n",
    "                if is_train:\n",
    "                    #print('x size and labels[:, 0] size: ', x.size(), labels[:,0].size())\n",
    "                    #x=torch.squeeze(last_timestep_output, dim=1)\n",
    "                    #print('x size and labels[:, 0] size: ', x.size(), labels[:,0].size())\n",
    "                    loss = self.cost_func(last_timestep_output, labels[:,ii])\n",
    "                    all_loss+=loss\n",
    "                \n",
    "                #x=torch.squeeze(last_timestep_output, dim=1)\n",
    "                _, max_idxs = torch.max(last_timestep_output, dim=1)\n",
    "                #print('max_idx size: ', max_idxs.size(), max_idxs)\n",
    "                predicts.append(torch.unsqueeze(max_idxs, dim=0))\n",
    "                \n",
    "#                 if ii==1:\n",
    "#                     print('this_timestep_input size: ', this_timestep_input.size(), 'max_idxs size: ', max_idxs.size())\n",
    "                    \n",
    "#         if is_train:\n",
    "#             return all_loss/(self.max_length+1)\n",
    "#         else:\n",
    "#             #predict results\n",
    "#             predicts = torch.cat(predicts, dim=0)\n",
    "#             #print('predicts size: ', predicts.size())\n",
    "#             predicts = torch.transpose(predicts, 0, 1)\n",
    "#             if self.use_cuda:\n",
    "#                 return predicts.data.cpu().numpy()\n",
    "#             else:\n",
    "#                 return predicts.data.numpy()\n",
    "\n",
    "\n",
    "        predicts = torch.cat(predicts, dim=0)\n",
    "        predicts = torch.transpose(predicts, 0, 1)\n",
    "        #print('predicts size: ', predicts.size())\n",
    "        \n",
    "        if is_train:  #training\n",
    "            if self.use_cuda:\n",
    "                return all_loss/(self.max_length+1), predicts.data.cpu().numpy()\n",
    "            else:\n",
    "                return all_loss/(self.max_length+1), predicts.data.numpy()\n",
    "        else:   #testing\n",
    "            if self.use_cuda:\n",
    "                return predicts.data.cpu().numpy()\n",
    "            else:\n",
    "                return predicts.data.numpy()\n",
    "            \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences length:  (8, 11, 11, 13, 7, 9, 25, 7, 7, 11, 8)\n",
      "enc result size:  torch.Size([11, 25, 1024]) torch.Size([11, 1024]) torch.Size([11, 1024])\n",
      "init lookup embedding matrix size:  torch.Size([98637, 300])\n",
      "loss is 11.4964514\n"
     ]
    }
   ],
   "source": [
    "use_cuda = 1\n",
    "hidden_dim = 512\n",
    "input_dim = 300\n",
    "\n",
    "\n",
    "enc = Encoder(use_cuda=use_cuda, \n",
    "            hidden_dim=hidden_dim, \n",
    "            input_dim=input_dim, \n",
    "            vocab=vocab\n",
    "           )\n",
    "if use_cuda:\n",
    "    enc = enc.cuda()\n",
    "    \n",
    "    \n",
    "sample_num = 11\n",
    "print('sentences length: ', train_set_input_lens[0:sample_num])\n",
    "\n",
    "enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[0:sample_num]), \n",
    "                                    torch.LongTensor(train_set_input_lens[0:sample_num]))\n",
    "print('enc result size: ', enc_outputs.size(), enc_hn.size(), enc_cn.size())\n",
    "\n",
    "dec = Decoder(use_cuda=use_cuda, encoder=enc, hidden_dim=hidden_dim, max_length=25)\n",
    "if use_cuda:\n",
    "    dec = dec.cuda()\n",
    "    \n",
    "loss, predicts = dec(enc_outputs = enc_outputs, \n",
    "    h0_and_c0=(enc_hn, enc_cn), \n",
    "    sent_lens=train_set_input_lens[0:sample_num], \n",
    "    labels=torch.LongTensor(train_set_labels[0:sample_num]), \n",
    "    is_train=1, teaching_rate = 1, force_argmax=1)\n",
    "print('loss is %4.7f'%loss.data[0])\n",
    "# print(enc_outputs, enc_hn, enc_cn)\n",
    "#print(enc_hn, enc_cn)\n",
    "\n",
    "# pre_trained = torch.load('./models_saved/dec-loss-8.221987724-bleu-0.0000-hidden_dim-256-input_dim-256-lr-0.0050') \n",
    "# dec.load_state_dict(pre_trained)\n",
    "\n",
    "# pre_trained = torch.load('./models_saved/enc-loss-8.221987724-blue-0.0000-hidden_dim-256-input_dim-256-lr-0.0050') \n",
    "# enc.load_state_dict(pre_trained)\n",
    "\n",
    "# enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[0:sample_num]), \n",
    "#                                     torch.LongTensor(train_set_input_lens[0:sample_num]))\n",
    "# dec(enc_outputs = enc_outputs, \n",
    "#     h0_and_c0=(enc_hn, enc_cn), \n",
    "#     sent_lens=train_set_input_lens[0:sample_num], \n",
    "#     labels=torch.LongTensor(train_set_labels[0:sample_num]), \n",
    "#     is_train=1, teaching_rate = 1, force_argmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_start_idx:  3493882\n",
      "我觉得low_freqlow_freq，的的，多的low_freq。。 end            我和所罗门兄弟公司有过一次不太愉快的合作经历。\n",
      "在low_freq里low_freq，、，的，，low_freqlow_freq、免费、冰箱、、、免费、免费、免费冰箱 end            从享用免费欧式早餐开始精力充沛的一天，包括华夫饼、热咖啡、热腾腾的茶水、酥饼和面包、新鲜水果\n",
      "他们是是这里里。 end            他们的确在丛林里。\n",
      "快他们的是是的的的。 end            告诉他们。这是不对的。\n",
      "有一个人的人呢？ end            以一个新的身份潜逃？\n",
      "我觉得了，伙计。 end            我挂了，拜。\n",
      "她的，，我们，我的，我们还在在并它的让它们的low_freq提供，中国年代， end            更糟的是，巴茨加入雅虎时，公司董事会承诺，如果她能够让公司的股票价格回升到25美元/\n",
      "但我想，，，会地。 end            因为我开车的时候我们不停接吻。\n",
      "他们不，你事 end            并不意味着什么坏事\n",
      "你想想你你你就知道 end            你刚刚到这儿难怪你不知道\n",
      "0.0%(1/500000), loss: 3.864894390, bleu_score: 0.4393\n",
      "valid_start_idx:  1532679\n",
      "你知道去你的衣服。 end            你不能离开你的妻子。\n",
      "是啊，我是是在在他们没有了。 end            是啊，本来我还不确定是不是定了。\n",
      "他的是都low_freq。 end            他的家里满是这些。\n",
      "现在你是，，我是是了个！ end            现在你知道了，你也有了犯罪感！\n",
      "所以我的在我的我的的情景。 end            所以我想是因为面包和果酱low_freq的关系。\n",
      "low_freq人的的是的的的在是在的很久。 end            这些新殖民主义者不仅压迫第三世界人民，也会压迫本国公民。\n",
      "你说说吗？好明白。 end            你不会介意吧？当然不。\n",
      "孩子！，low_freq了。。 end            小子们，打扫一下这。\n",
      "low_freq上的，，的，，low_freq：，的行为。 end            前十名流通股股东之间存在关联关系或一致行动人的情况。\n",
      "我知道是在我的衣服衣服，，我说话。 end            我也会把自己的一些趣事讲给你听。\n",
      "0.0%(51/500000), loss: 4.253524780, bleu_score: 0.4393\n"
     ]
    }
   ],
   "source": [
    "lr=0.005\n",
    "\n",
    "epochs=500000\n",
    "start_idx=0\n",
    "batch_size=200\n",
    "train_set_size=int(len(train_set_inputs)/2)\n",
    "\n",
    "model_paras = list(dec.parameters())+list(enc.parameters())\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_paras), lr=lr)#optimizer for epoch in range(epochs):\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "bleu_score = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #print(epoch)\n",
    "\n",
    "    optimizer.zero_grad()#clear\n",
    "\n",
    "    enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[start_idx:start_idx+batch_size]), \n",
    "                                        torch.LongTensor(train_set_input_lens[start_idx:start_idx+batch_size]))\n",
    "\n",
    "    loss, predicts = dec(enc_outputs, h0_and_c0=(enc_hn, enc_cn), \n",
    "               sent_lens = train_set_input_lens[start_idx:start_idx+batch_size],\n",
    "               labels=torch.LongTensor(train_set_labels[start_idx:start_idx+batch_size]), \n",
    "               teaching_rate=1,\n",
    "               is_train=1,\n",
    "               force_argmax = 1)\n",
    "    #optimize\n",
    "    loss.backward()#retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    start_idx=epoch*batch_size%(train_set_size-batch_size-1)    # samples change\n",
    "\n",
    "    \n",
    "    valid_batch_size=10\n",
    "    valid_start_idx=random.randint(0, train_set_size-valid_batch_size-1)\n",
    "    if random.random()<0.5:\n",
    "        valid_start_idx=random.randint(0, len(train_set_inputs)-1-valid_batch_size-1)\n",
    "    #valid_start_idx=random.randint(0, train_set_size-valid_batch_size-1)\n",
    "    \n",
    "    if epoch%50 == 1:\n",
    "        \n",
    "        enc.eval()\n",
    "        dec.eval()\n",
    "        enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(train_set_inputs[valid_start_idx:valid_start_idx+valid_batch_size]), \n",
    "                                        torch.LongTensor(train_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size]))\n",
    "\n",
    "        loss_, predicts = dec(enc_outputs, \n",
    "                       sent_lens = train_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size],\n",
    "                       h0_and_c0=(enc_hn, enc_cn), \n",
    "                       labels=torch.LongTensor(train_set_labels[valid_start_idx:valid_start_idx+valid_batch_size]),\n",
    "                       is_train=1,\n",
    "                       teaching_rate=1,\n",
    "                       force_argmax=1)\n",
    "        del loss_\n",
    "\n",
    "        tokenized_sents=predicts.tolist()\n",
    "        real_sents=[]\n",
    "        label_tokenized_sents=train_set_labels[valid_start_idx:valid_start_idx+valid_batch_size]\n",
    "        label_real_sents=[]\n",
    "        for idx, sent in enumerate(tokenized_sents):\n",
    "            real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "        for sent in label_tokenized_sents:\n",
    "            label_real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "        print('valid_start_idx: ', valid_start_idx)\n",
    "        for (real_sent, label_real_sent) in zip(real_sents, label_real_sents):\n",
    "            print(real_sent, 'end           ', label_real_sent)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #valid\n",
    "        if epoch%1000==1:\n",
    "            valid_rand_idx=random.randint(0, len(valid_set_inputs)-batch_size-1-1)\n",
    "            enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(valid_set_inputs[valid_rand_idx:valid_rand_idx+batch_size]), \n",
    "                                            torch.LongTensor(valid_set_input_lens[valid_rand_idx:valid_rand_idx+batch_size]))\n",
    "\n",
    "            predicts = dec(enc_outputs, \n",
    "                           sent_lens = valid_set_input_lens[valid_rand_idx:valid_rand_idx+batch_size],\n",
    "                           h0_and_c0=(enc_hn, enc_cn), \n",
    "                           labels=torch.LongTensor([0]), \n",
    "                           is_train=0,\n",
    "                           teaching_rate=1,\n",
    "                           force_argmax=1)\n",
    "            \n",
    "            tokenized_sents=predicts.tolist()\n",
    "            real_sents=[]\n",
    "            label_tokenized_sents=valid_set_labels[valid_rand_idx:valid_rand_idx+batch_size]\n",
    "            label_real_sents=[]\n",
    "            for sent in tokenized_sents:\n",
    "                real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "                #real_sents.append(reverse_tokenized_sent2real_sent(sent, enc.vocab))\n",
    "            for sent in label_tokenized_sents:\n",
    "                label_real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "                #label_real_sents.append(reverse_tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "            bleu_sum, valid_num = data_set_bleu(label_real_sents, real_sents)\n",
    "            if valid_num>10:\n",
    "                bleu_score = bleu_sum/valid_num\n",
    "            else:\n",
    "                bleu_score = 999\n",
    "            #sava\n",
    "            torch.save(enc.state_dict(), \n",
    "                    './models_saved/enc-loss-{:2.9f}-bleu-{:1.4f}-hidden_dim-{:n}-input_dim-{:n}-lr-{:1.4f}'.format(\n",
    "                          loss.data[0], bleu_score, hidden_dim, input_dim, lr))\n",
    "            torch.save(dec.state_dict(),\n",
    "            './models_saved/dec-loss-{:2.9f}-bleu-{:1.4f}-hidden_dim-{:n}-input_dim-{:n}-lr-{:1.4f}'.format(\n",
    "                    loss.data[0], bleu_score, hidden_dim, input_dim, lr))\n",
    "\n",
    "        print('%2.1f%%(%s/%s), loss: %2.9f, bleu_score: %1.4f'%(epoch*100/epochs, epoch, epochs, loss.data[0], bleu_score))\n",
    "        \n",
    "        enc.train()\n",
    "        dec.train()\n",
    "        \n",
    "print('running time: %.2f mins'%((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_this_cell\n",
    "\n",
    "#print('running time: %.2f mins'%((time.time()-start_time)/60))\n",
    "#sava\n",
    "torch.save(enc.state_dict(), \n",
    "        './models/enc-loss-{:2.9f}-blue-{:1.4f}-hidden_dim-{:n}-input_dim-{:n}-lr-{:1.4f}'.format(\n",
    "              loss.data[0], bleu_score, hidden_dim, input_dim, lr))\n",
    "torch.save(dec.state_dict(),\n",
    "'./models/dec-loss-{:2.9f}-bleu-{:1.4f}-hidden_dim-{:n}-input_dim-{:n}-lr-{:1.4f}'.format(\n",
    "        loss.data[0], bleu_score, hidden_dim, input_dim, lr))\n",
    "#a little ok: dec-loss-8.243618965-bleu-0.0000-hidden_dim-256-input_dim-256-lr-0.0050 and enc-......\n",
    "#results： for example：\n",
    "# 我对我们一上，上一里里不对里。             全给我吃完，地上一粒米也不许剩。\n",
    "# 有能和我，我能对。她这里。              喝得烂醉；我只能把她赶出去。 \n",
    "# 了，这是吗？。 是的。对吗。              是这样吗？ 是的。随便啦。 \n",
    "# 是你的！是！！来！！来！来！来！              你喝的都是自来水！去找饮用水来！ \n",
    "# 以他以不是这里的。              他以前不是那样的。 \n",
    "#\n",
    "print('loss: %2.9f'%loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_start_idx=600\n",
    "valid_batch_size=30\n",
    "\n",
    "dec.eval()\n",
    "enc.eval()\n",
    "enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(valid_set_inputs[valid_start_idx:valid_start_idx+valid_batch_size]), \n",
    "                                torch.LongTensor(valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size]))\n",
    "\n",
    "predicts = dec(enc_outputs, \n",
    "               sent_lens = valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size],\n",
    "               h0_and_c0=(enc_hn, enc_cn), \n",
    "               labels=torch.LongTensor([0]), \n",
    "               is_train=0,\n",
    "               teaching_rate=0,\n",
    "               force_argmax = 1)\n",
    "\n",
    "tokenized_sents=predicts.tolist()\n",
    "real_sents=[]\n",
    "label_tokenized_sents=valid_set_labels[valid_start_idx:valid_start_idx+valid_batch_size]\n",
    "label_real_sents=[]\n",
    "for sent in tokenized_sents:\n",
    "    real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "for sent in label_tokenized_sents:\n",
    "    label_real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "for (real_sent, label_real_sent) in zip(real_sents, label_real_sents):\n",
    "    print(real_sent, '           ', label_real_sent)\n",
    "    \n",
    "    \n",
    "print('### ........................ ###')\n",
    "print('### ........................ ###')\n",
    "print('### ........................ ###')\n",
    "\n",
    "\n",
    "valid_start_idx=620\n",
    "valid_batch_size=200\n",
    "\n",
    "dec.eval()\n",
    "enc.eval()\n",
    "enc_outputs, (enc_hn, enc_cn) = enc(torch.LongTensor(valid_set_inputs[valid_start_idx:valid_start_idx+valid_batch_size]), \n",
    "                                torch.LongTensor(valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size]))\n",
    "\n",
    "predicts = dec(enc_outputs, \n",
    "               sent_lens = valid_set_input_lens[valid_start_idx:valid_start_idx+valid_batch_size],\n",
    "               h0_and_c0=(enc_hn, enc_cn), \n",
    "               labels=torch.LongTensor([0]), \n",
    "               is_train=0,\n",
    "               teaching_rate=1,\n",
    "               force_argmax = 1)\n",
    "\n",
    "tokenized_sents=predicts.tolist()\n",
    "real_sents=[]\n",
    "label_tokenized_sents=valid_set_labels[valid_start_idx:valid_start_idx+valid_batch_size]\n",
    "label_real_sents=[]\n",
    "for sent in tokenized_sents:\n",
    "    real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "for sent in label_tokenized_sents:\n",
    "    label_real_sents.append(tokenized_sent2real_sent(sent, enc.vocab))\n",
    "\n",
    "# for (real_sent, label_real_sent) in zip(real_sents, label_real_sents):\n",
    "#     print(real_sent, '           ', label_real_sent)\n",
    "    \n",
    "dec.train()\n",
    "enc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_set_bleu1(sents1, sents2):\n",
    "    cnt=0\n",
    "    bleu_score_sum=0\n",
    "    \n",
    "    for sent1, sent2 in zip(sents1, sents2):\n",
    "        if min(len(sent1), len(sent2))<4:\n",
    "            pass\n",
    "        else:\n",
    "            cnt+=1\n",
    "            bleu_score_sum = sentence_bleu([list(sent1)], list(sent2))+bleu_score_sum\n",
    "            \n",
    "    return bleu_score_sum, cnt\n",
    "\n",
    "bleu_sum, valid_num = data_set_bleu1(label_real_sents, real_sents)\n",
    "print(len(label_real_sents), bleu_sum, valid_num, bleu_sum/valid_num)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
