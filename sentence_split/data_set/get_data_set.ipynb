{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "from Vocab import Vocab\n",
    "\n",
    "file_group = 'train'    #availabe:  train    test    validation    tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_file_path = 'vocab.pk'\n",
    "with open(vocab_file_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split dataset\n",
    "os.system(''.join(['cp ', file_group, '_complex_sents.pk', ' ', './split_data_set/', file_group, '_complex_sents.pk']))\n",
    "os.system(''.join(['cp ', file_group, '_complex_sent_lens.pk', ' ', './split_data_set/', file_group, '_complex_sent_lens.pk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(''.join([file_group, '_simple_sents.pk']), 'rb') as f:\n",
    "    simple_sents = pickle.load(f)\n",
    "    \n",
    "for sent in simple_sents:\n",
    "    if sent[-1]!=vocab.word2token['<padding>']:\n",
    "        sent.append(vocab.word2token['<eos>'])\n",
    "    else:\n",
    "        for ii in range(59, -1, -1):\n",
    "            if sent[ii] != vocab.word2token['<padding>']:\n",
    "                sent.insert(ii+1, vocab.word2token['<eos>'])\n",
    "                break\n",
    "                \n",
    "with open(''.join(['./split_data_set/', file_group, '_labels.pk']), 'wb') as f:\n",
    "    pickle.dump(simple_sents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20606, 34682, 2026, 36235, 24520, 27513, 1645, 15319, 34417, 27305, 25168, 8773, 3, 24520, 37734, 5, 32715, 22944, 13578, 8651, 20403, 21467, 1048, 3106, 10886, 27513, 21467, 37239, 21354, 43108, 37734, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] 61\n"
     ]
    }
   ],
   "source": [
    "a=random.choice(simple_sents)\n",
    "print(a, len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fusion dataset\n",
    "os.system(''.join(['cp ', file_group, '_simple_sents.pk', ' ', './fusion_data_set/', file_group, '_simple_sents.pk']))\n",
    "os.system(''.join(['cp ', file_group, '_simple_sent_lens.pk', ' ', './fusion_data_set/', file_group, '_simple_sent_lens.pk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(''.join([file_group, '_complex_sents.pk']), 'rb') as f:\n",
    "    complex_sents = pickle.load(f)\n",
    "    \n",
    "for sent in complex_sents:\n",
    "    if sent[-1]!=vocab.word2token['<padding>']:\n",
    "        sent.append(vocab.word2token['<eos>'])\n",
    "    else:\n",
    "        for ii in range(49, -1, -1):\n",
    "            if sent[ii] != vocab.word2token['<padding>']:\n",
    "                sent.insert(ii+1, vocab.word2token['<eos>'])\n",
    "                break\n",
    "                \n",
    "with open(''.join(['./fusion_data_set/', file_group, '_labels.pk']), 'wb') as f:\n",
    "    pickle.dump(complex_sents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42957, 25168, 34553, 13264, 43016, 752, 11206, 17054, 41729, 26313, 41729, 37745, 25597, 19799, 4972, 2211, 30341, 20373, 14938, 13264, 11206, 36801, 13264, 9223, 30341, 38014, 13264, 9569, 13264, 752, 11206, 22142, 29355, 10934, 11206, 31854, 28297, 37734, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] 51\n"
     ]
    }
   ],
   "source": [
    "a=random.choice(complex_sents)\n",
    "print(a, len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
